[{"path":[]},{"path":"https://docs.ropensci.org/elastic/CONTRIBUTING.html","id":"bugs","dir":"","previous_headings":"","what":"Bugs?","title":"CONTRIBUTING","text":"Submit issue Issues page","code":""},{"path":"https://docs.ropensci.org/elastic/CONTRIBUTING.html","id":"code-contributions","dir":"","previous_headings":"","what":"Code contributions","title":"CONTRIBUTING","text":"Fork repo Github account Clone version account machine account, e.g,. git clone https://github.com/<yourgithubusername>/elastic.git Make sure track progress upstream (.e., version elastic ropensci/elastic) git remote add upstream https://github.com/ropensci/elastic.git. making changes make sure pull changes upstream either git fetch upstream merge later git pull upstream fetch merge one step Make changes (bonus points making changes new feature branch) Push account Submit pull request home base ropensci/elastic","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"elastic introduction","text":"can install CRAN (package ) development version GitHub load package","code":"install.packages(\"elastic\") install.packages(\"remotes\") remotes::install_github(\"ropensci/elastic\") library(\"elastic\")"},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"elasticsearch-info","dir":"Articles","previous_headings":"","what":"Elasticsearch info","title":"elastic introduction","text":"Elasticsearch home page API docs","code":""},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"install-elasticsearch","dir":"Articles","previous_headings":"","what":"Install Elasticsearch","title":"elastic introduction","text":"Elasticsearch installation help Unix (linux/osx) Replace 6.5.3 version working . Download zip tar file Elasticsearch see download, e.g., curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.5.3.tar.gz Extract: tar -zxvf elasticsearch-6.5.3.tar.gz Move : sudo mv elasticsearch-6.5.3 /usr/local Navigate /usr/local: cd /usr/local Delete symlinked elasticsearch directory: rm -rf elasticsearch Add shortcut: sudo ln -s elasticsearch-6.5.3 elasticsearch (replace version version) OSX, can install via Homebrew: brew install elasticsearch Windows Windows users can follow , unzip zip file instead uncompressing tar file.","code":""},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"start-elasticsearch","dir":"Articles","previous_headings":"","what":"Start Elasticsearch","title":"elastic introduction","text":"Navigate elasticsearch: cd /usr/local/elasticsearch Start elasticsearch: bin/elasticsearch create little bash shortcut called es commands one step (cd /usr/local/elasticsearch && bin/elasticsearch). Note: Windows users run elasticsearch.bat file","code":""},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"initialize-connection","dir":"Articles","previous_headings":"","what":"Initialize connection","title":"elastic introduction","text":"function connect() used anything else set connection details remote local elasticsearch store. details created connect() written options current session, used elastic functions. package load, base url port set http://127.0.0.1 9200, respectively. can course override settings per session sessions.","code":"x <- connect() x #> <Elasticsearch Connection>  #>   transport:  http  #>   host:       127.0.0.1  #>   port:       9200  #>   path:       NULL  #>   username:   NULL  #>   password:   NULL  #>   errors:     simple  #>   headers (names):    #>   cainfo:  NULL"},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"get-some-data","dir":"Articles","previous_headings":"","what":"Get some data","title":"elastic introduction","text":"Elasticsearch bulk load API load data fast. format pretty weird though. ’s sort JSON, pass JSON linter. include data sets elastic ’s easy get running, run examples package ’ll actually run way (hopefully). prepared non-exported function useful preparing weird format Elasticsearch wants bulk data loads (see ). See elastic:::make_bulk_plos elastic:::make_bulk_gbif.","code":""},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"shakespeare-data","dir":"Articles","previous_headings":"Get some data","what":"Shakespeare data","title":"elastic introduction","text":"Elasticsearch provides data Shakespeare plays. ’ve provided subset data package. Get path file specific machine: load data Elasticsearch: need big data play , shakespeare dataset good one start . can get whole thing pop Elasticsearch (beware, may take 10 minutes .):","code":"shakespeare <- system.file(\"examples\", \"shakespeare_data.json\", package = \"elastic\") docs_bulk(x, shakespeare) curl -XGET https://www.elastic.co/guide/en/kibana/3.0/snippets/shakespeare.json > shakespeare.json curl -XPUT localhost:9200/_bulk --data-binary @shakespeare.json"},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"public-library-of-science-plos-data","dir":"Articles","previous_headings":"Get some data","what":"Public Library of Science (PLOS) data","title":"elastic introduction","text":"dataset inluded elastic package metadata PLOS scholarly articles. Get file path, load:","code":"plosdat <- system.file(\"examples\", \"plos_data.json\", package = \"elastic\") docs_bulk(x, plosdat)"},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"global-biodiversity-information-facility-gbif-data","dir":"Articles","previous_headings":"Get some data","what":"Global Biodiversity Information Facility (GBIF) data","title":"elastic introduction","text":"dataset inluded elastic package data GBIF species occurrence records. Get file path, load: GBIF geo data coordinates element allow geo_shape queries","code":"gbifdat <- system.file(\"examples\", \"gbif_data.json\", package = \"elastic\") docs_bulk(x, gbifdat) gbifgeo <- system.file(\"examples\", \"gbif_geo.json\", package = \"elastic\") docs_bulk(x, gbifgeo)"},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"more-data-sets","dir":"Articles","previous_headings":"Get some data","what":"More data sets","title":"elastic introduction","text":"datasets formatted bulk loading sckott/elastic_data GitHub repository. Find https://github.com/sckott/elastic_data","code":""},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"search","dir":"Articles","previous_headings":"","what":"Search","title":"elastic introduction","text":"Search plos index return 1 result Search plos index, article document type, query antibody, limit 1 result","code":"Search(x, index=\"plos\", size=1)$hits$hits #> [[1]] #> [[1]]$`_index` #> [1] \"plos\" #>  #> [[1]]$`_type` #> [1] \"article\" #>  #> [[1]]$`_id` #> [1] \"0\" #>  #> [[1]]$`_score` #> [1] 1 #>  #> [[1]]$`_source` #> [[1]]$`_source`$id #> [1] \"10.1371/journal.pone.0007737\" #>  #> [[1]]$`_source`$title #> [1] \"Phospholipase C-β4 Is Essential for the Progression of the Normal Sleep Sequence and Ultradian Body Temperature Rhythms in Mice\" Search(x, index=\"plos\", type=\"article\", q=\"antibody\", size=1)$hits$hits #> [[1]] #> [[1]]$`_index` #> [1] \"plos\" #>  #> [[1]]$`_type` #> [1] \"article\" #>  #> [[1]]$`_id` #> [1] \"813\" #>  #> [[1]]$`_score` #> [1] 5.18676 #>  #> [[1]]$`_source` #> [[1]]$`_source`$id #> [1] \"10.1371/journal.pone.0107638\" #>  #> [[1]]$`_source`$title #> [1] \"Sortase A Induces Th17-Mediated and Antibody-Independent Immunity to Heterologous Serotypes of Group A Streptococci\""},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"get-documents","dir":"Articles","previous_headings":"","what":"Get documents","title":"elastic introduction","text":"Get document id=1 Get certain fields","code":"docs_get(x, index='plos', type='article', id=1) #> $`_index` #> [1] \"plos\" #>  #> $`_type` #> [1] \"article\" #>  #> $`_id` #> [1] \"1\" #>  #> $`_version` #> [1] 1 #>  #> $`_seq_no` #> [1] 1 #>  #> $`_primary_term` #> [1] 1 #>  #> $found #> [1] TRUE #>  #> $`_source` #> $`_source`$id #> [1] \"10.1371/journal.pone.0098602\" #>  #> $`_source`$title #> [1] \"Population Genetic Structure of a Sandstone Specialist and a Generalist Heath Species at Two Levels of Sandstone Patchiness across the Strait of Gibraltar\" docs_get(x, index='plos', type='article', id=1, fields='id') #> $`_index` #> [1] \"plos\" #>  #> $`_type` #> [1] \"article\" #>  #> $`_id` #> [1] \"1\" #>  #> $`_version` #> [1] 1 #>  #> $`_seq_no` #> [1] 1 #>  #> $`_primary_term` #> [1] 1 #>  #> $found #> [1] TRUE"},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"get-multiple-documents-at-once","dir":"Articles","previous_headings":"","what":"Get multiple documents at once","title":"elastic introduction","text":"index type, different document ids Different indeces, types, ids","code":"docs_mget(x, index=\"plos\", type=\"article\", id=3:4) #> $docs #> $docs[[1]] #> $docs[[1]]$`_index` #> [1] \"plos\" #>  #> $docs[[1]]$`_type` #> [1] \"article\" #>  #> $docs[[1]]$`_id` #> [1] \"3\" #>  #> $docs[[1]]$`_version` #> [1] 1 #>  #> $docs[[1]]$`_seq_no` #> [1] 3 #>  #> $docs[[1]]$`_primary_term` #> [1] 1 #>  #> $docs[[1]]$found #> [1] TRUE #>  #> $docs[[1]]$`_source` #> $docs[[1]]$`_source`$id #> [1] \"10.1371/journal.pone.0107756\" #>  #> $docs[[1]]$`_source`$title #> [1] \"The Effect of S-Adenosylmethionine on Cognitive Performance in Mice: An Animal Model Meta-Analysis\" #>  #>  #>  #> $docs[[2]] #> $docs[[2]]$`_index` #> [1] \"plos\" #>  #> $docs[[2]]$`_type` #> [1] \"article\" #>  #> $docs[[2]]$`_id` #> [1] \"4\" #>  #> $docs[[2]]$`_version` #> [1] 1 #>  #> $docs[[2]]$`_seq_no` #> [1] 4 #>  #> $docs[[2]]$`_primary_term` #> [1] 1 #>  #> $docs[[2]]$found #> [1] TRUE #>  #> $docs[[2]]$`_source` #> $docs[[2]]$`_source`$id #> [1] \"10.1371/journal.pone.0107758\" #>  #> $docs[[2]]$`_source`$title #> [1] \"Lactobacilli Inactivate Chlamydia trachomatis through Lactic Acid but Not H2O2\" docs_mget(x, index_type_id=list(c(\"plos\",\"article\",1), c(\"gbif\",\"record\",1)))$docs[[1]] #> $`_index` #> [1] \"plos\" #>  #> $`_type` #> [1] \"article\" #>  #> $`_id` #> [1] \"1\" #>  #> $`_version` #> [1] 1 #>  #> $`_seq_no` #> [1] 1 #>  #> $`_primary_term` #> [1] 1 #>  #> $found #> [1] TRUE #>  #> $`_source` #> $`_source`$id #> [1] \"10.1371/journal.pone.0098602\" #>  #> $`_source`$title #> [1] \"Population Genetic Structure of a Sandstone Specialist and a Generalist Heath Species at Two Levels of Sandstone Patchiness across the Strait of Gibraltar\""},{"path":"https://docs.ropensci.org/elastic/articles/elastic.html","id":"raw-json-data","dir":"Articles","previous_headings":"","what":"Raw JSON data","title":"elastic introduction","text":"can optionally get back raw json Search(), docs_get(), docs_mget() setting parameter raw=TRUE. example: parse","code":"(out <- docs_mget(x, index=\"plos\", type=\"article\", id=5:6, raw=TRUE)) #> [1] \"{\\\"docs\\\":[{\\\"_index\\\":\\\"plos\\\",\\\"_type\\\":\\\"article\\\",\\\"_id\\\":\\\"5\\\",\\\"_version\\\":1,\\\"_seq_no\\\":5,\\\"_primary_term\\\":1,\\\"found\\\":true,\\\"_source\\\":{\\\"id\\\":\\\"10.1371/journal.pone.0085123\\\",\\\"title\\\":\\\"MiR-21 Is under Control of STAT5 but Is Dispensable for Mammary Development and Lactation\\\"}},{\\\"_index\\\":\\\"plos\\\",\\\"_type\\\":\\\"article\\\",\\\"_id\\\":\\\"6\\\",\\\"_version\\\":1,\\\"_seq_no\\\":6,\\\"_primary_term\\\":1,\\\"found\\\":true,\\\"_source\\\":{\\\"id\\\":\\\"10.1371/journal.pone.0098600\\\",\\\"title\\\":\\\"Correction: Designing Mixed Species Tree Plantations for the Tropics: Balancing Ecological Attributes of Species with Landholder Preferences in the Philippines\\\"}}]}\" #> attr(,\"class\") #> [1] \"elastic_mget\" jsonlite::fromJSON(out) #> $docs #>   _index   _type _id _version _seq_no _primary_term found #> 1   plos article   5        1       5             1  TRUE #> 2   plos article   6        1       6             1  TRUE #>                     _source.id #> 1 10.1371/journal.pone.0085123 #> 2 10.1371/journal.pone.0098600 #>                                                                                                                                                     _source.title #> 1                                                                       MiR-21 Is under Control of STAT5 but Is Dispensable for Mammary Development and Lactation #> 2 Correction: Designing Mixed Species Tree Plantations for the Tropics: Balancing Ecological Attributes of Species with Landholder Preferences in the Philippines"},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"load-elastic","dir":"Articles","previous_headings":"","what":"Load elastic","title":"elastic searching","text":"","code":"library(\"elastic\")"},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"the-search-function","dir":"Articles","previous_headings":"","what":"The Search function","title":"elastic searching","text":"main interface searching documents Elasticsearch store function Search(). nearly always develop R software using lowercase, R function called search(), wanted avoid collision function. Search() interface HTTP search API (queries passed URI request, meaning queries relatively simple), well POST API, Query DSL, queries passed body request (can much complex). huge amount ways can search Elasticsearch documents - tutorial covers , highlights ways interact R outputs.","code":"x <- connect()"},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"search-an-index","dir":"Articles","previous_headings":"The Search function","what":"Search an index","title":"elastic searching","text":"","code":"out <- Search(x, index=\"shakespeare\") out$hits$total #> $value #> [1] 5000 #>  #> $relation #> [1] \"eq\" out$hits$hits[[1]] #> $`_index` #> [1] \"shakespeare\" #>  #> $`_type` #> [1] \"_doc\" #>  #> $`_id` #> [1] \"0\" #>  #> $`_score` #> [1] 1 #>  #> $`_source` #> $`_source`$line_id #> [1] 1 #>  #> $`_source`$play_name #> [1] \"Henry IV\" #>  #> $`_source`$line_number #> [1] \"\" #>  #> $`_source`$speaker #> [1] \"\" #>  #> $`_source`$text_entry #> [1] \"ACT I\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"search-an-index-by-type","dir":"Articles","previous_headings":"The Search function","what":"Search an index by type","title":"elastic searching","text":"","code":"Search(x, index = \"shakespeare\")$hits$hits[[1]] #> $`_index` #> [1] \"shakespeare\" #>  #> $`_type` #> [1] \"_doc\" #>  #> $`_id` #> [1] \"0\" #>  #> $`_score` #> [1] 1 #>  #> $`_source` #> $`_source`$line_id #> [1] 1 #>  #> $`_source`$play_name #> [1] \"Henry IV\" #>  #> $`_source`$line_number #> [1] \"\" #>  #> $`_source`$speaker #> [1] \"\" #>  #> $`_source`$text_entry #> [1] \"ACT I\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"return-certain-fields","dir":"Articles","previous_headings":"The Search function","what":"Return certain fields","title":"elastic searching","text":"","code":"Search(x, index = \"shakespeare\", body = '{   \"_source\": [\"play_name\", \"speaker\"] }')$hits$hits[[1]] #> $`_index` #> [1] \"shakespeare\" #>  #> $`_type` #> [1] \"_doc\" #>  #> $`_id` #> [1] \"0\" #>  #> $`_score` #> [1] 1 #>  #> $`_source` #> $`_source`$play_name #> [1] \"Henry IV\" #>  #> $`_source`$speaker #> [1] \"\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"paging","dir":"Articles","previous_headings":"The Search function","what":"Paging","title":"elastic searching","text":"","code":"Search(x, index=\"shakespeare\", size=1, from=1)$hits #> $total #> $total$value #> [1] 5000 #>  #> $total$relation #> [1] \"eq\" #>  #>  #> $max_score #> [1] 1 #>  #> $hits #> $hits[[1]] #> $hits[[1]]$`_index` #> [1] \"shakespeare\" #>  #> $hits[[1]]$`_type` #> [1] \"_doc\" #>  #> $hits[[1]]$`_id` #> [1] \"1\" #>  #> $hits[[1]]$`_score` #> [1] 1 #>  #> $hits[[1]]$`_source` #> $hits[[1]]$`_source`$line_id #> [1] 2 #>  #> $hits[[1]]$`_source`$play_name #> [1] \"Henry IV\" #>  #> $hits[[1]]$`_source`$line_number #> [1] \"\" #>  #> $hits[[1]]$`_source`$speaker #> [1] \"\" #>  #> $hits[[1]]$`_source`$text_entry #> [1] \"SCENE I. London. The palace.\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"queries","dir":"Articles","previous_headings":"The Search function","what":"Queries","title":"elastic searching","text":"Using q parameter can pass query, gets passed URI query. type query less powerful query passed body request, using body parameter.","code":"Search(x, index=\"shakespeare\", q=\"speaker:KING HENRY IV\")$hits$total #> $value #> [1] 5000 #>  #> $relation #> [1] \"eq\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"more-complex-queries","dir":"Articles","previous_headings":"The Search function > Queries","what":"More complex queries","title":"elastic searching","text":", query values 10 20 field line_id","code":"Search(x, index=\"shakespeare\", q=\"line_id:[10 TO 20]\")$hits$total #> $value #> [1] 11 #>  #> $relation #> [1] \"eq\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"get-version-number-for-each-document","dir":"Articles","previous_headings":"The Search function","what":"Get version number for each document","title":"elastic searching","text":"Version number usually returned.","code":"sapply(Search(x, index=\"shakespeare\", version=TRUE, size=2)$hits$hits, \"[[\", \"_version\") #> [1] 1 1"},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"get-raw-data","dir":"Articles","previous_headings":"The Search function","what":"Get raw data","title":"elastic searching","text":"","code":"Search(x, index=\"shakespeare\", raw=TRUE) #> [1] \"{\\\"took\\\":0,\\\"timed_out\\\":false,\\\"_shards\\\":{\\\"total\\\":1,\\\"successful\\\":1,\\\"skipped\\\":0,\\\"failed\\\":0},\\\"hits\\\":{\\\"total\\\":{\\\"value\\\":5000,\\\"relation\\\":\\\"eq\\\"},\\\"max_score\\\":1.0,\\\"hits\\\":[{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"0\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":1,\\\"play_name\\\":\\\"Henry IV\\\",\\\"line_number\\\":\\\"\\\",\\\"speaker\\\":\\\"\\\",\\\"text_entry\\\":\\\"ACT I\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"1\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":2,\\\"play_name\\\":\\\"Henry IV\\\",\\\"line_number\\\":\\\"\\\",\\\"speaker\\\":\\\"\\\",\\\"text_entry\\\":\\\"SCENE I. London. The palace.\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"2\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":3,\\\"play_name\\\":\\\"Henry IV\\\",\\\"line_number\\\":\\\"\\\",\\\"speaker\\\":\\\"\\\",\\\"text_entry\\\":\\\"Enter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"3\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":4,\\\"play_name\\\":\\\"Henry IV\\\",\\\"speech_number\\\":1,\\\"line_number\\\":\\\"1.1.1\\\",\\\"speaker\\\":\\\"KING HENRY IV\\\",\\\"text_entry\\\":\\\"So shaken as we are, so wan with care,\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"4\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":5,\\\"play_name\\\":\\\"Henry IV\\\",\\\"speech_number\\\":1,\\\"line_number\\\":\\\"1.1.2\\\",\\\"speaker\\\":\\\"KING HENRY IV\\\",\\\"text_entry\\\":\\\"Find we a time for frighted peace to pant,\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"5\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":6,\\\"play_name\\\":\\\"Henry IV\\\",\\\"speech_number\\\":1,\\\"line_number\\\":\\\"1.1.3\\\",\\\"speaker\\\":\\\"KING HENRY IV\\\",\\\"text_entry\\\":\\\"And breathe short-winded accents of new broils\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"6\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":7,\\\"play_name\\\":\\\"Henry IV\\\",\\\"speech_number\\\":1,\\\"line_number\\\":\\\"1.1.4\\\",\\\"speaker\\\":\\\"KING HENRY IV\\\",\\\"text_entry\\\":\\\"To be commenced in strands afar remote.\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"7\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":8,\\\"play_name\\\":\\\"Henry IV\\\",\\\"speech_number\\\":1,\\\"line_number\\\":\\\"1.1.5\\\",\\\"speaker\\\":\\\"KING HENRY IV\\\",\\\"text_entry\\\":\\\"No more the thirsty entrance of this soil\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"8\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":9,\\\"play_name\\\":\\\"Henry IV\\\",\\\"speech_number\\\":1,\\\"line_number\\\":\\\"1.1.6\\\",\\\"speaker\\\":\\\"KING HENRY IV\\\",\\\"text_entry\\\":\\\"Shall daub her lips with her own childrens blood;\\\"}},{\\\"_index\\\":\\\"shakespeare\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"9\\\",\\\"_score\\\":1.0,\\\"_source\\\":{\\\"line_id\\\":10,\\\"play_name\\\":\\\"Henry IV\\\",\\\"speech_number\\\":1,\\\"line_number\\\":\\\"1.1.7\\\",\\\"speaker\\\":\\\"KING HENRY IV\\\",\\\"text_entry\\\":\\\"Nor more shall trenching war channel her fields,\\\"}}]}}\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"curl-debugging","dir":"Articles","previous_headings":"The Search function","what":"Curl debugging","title":"elastic searching","text":"Common options verbose=TRUE, timeout_ms=1, followlocation=TRUE.","code":"out <- Search(x, index=\"shakespeare\", verbose = TRUE)"},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"query-dsl-searches---queries-sent-in-the-body-of-the-request","dir":"Articles","previous_headings":"The Search function","what":"Query DSL searches - queries sent in the body of the request","title":"elastic searching","text":"Pass R list pass json query newlines, easy read pass collapsed json string","code":"mapping_create(x, \"shakespeare\", update_all_types = TRUE, body = '{    \"properties\": {      \"text_entry\": {        \"type\":     \"text\",        \"fielddata\": true     }   } }') #> $acknowledged #> [1] TRUE aggs <- list(aggs = list(stats = list(terms = list(field = \"text_entry\")))) Search(x, index=\"shakespeare\", body=aggs)$hits$hits[[1]] #> $`_index` #> [1] \"shakespeare\" #>  #> $`_type` #> [1] \"_doc\" #>  #> $`_id` #> [1] \"0\" #>  #> $`_score` #> [1] 1 #>  #> $`_source` #> $`_source`$line_id #> [1] 1 #>  #> $`_source`$play_name #> [1] \"Henry IV\" #>  #> $`_source`$line_number #> [1] \"\" #>  #> $`_source`$speaker #> [1] \"\" #>  #> $`_source`$text_entry #> [1] \"ACT I\" aggs <- '{     \"aggs\": {         \"stats\" : {             \"terms\" : {                 \"field\" : \"text_entry\"             }         }     } }' Search(x, index=\"shakespeare\", body=aggs)$hits$hits[[1]] #> $`_index` #> [1] \"shakespeare\" #>  #> $`_type` #> [1] \"_doc\" #>  #> $`_id` #> [1] \"0\" #>  #> $`_score` #> [1] 1 #>  #> $`_source` #> $`_source`$line_id #> [1] 1 #>  #> $`_source`$play_name #> [1] \"Henry IV\" #>  #> $`_source`$line_number #> [1] \"\" #>  #> $`_source`$speaker #> [1] \"\" #>  #> $`_source`$text_entry #> [1] \"ACT I\" aggs <- '{\"aggs\":{\"stats\":{\"terms\":{\"field\":\"text_entry\"}}}}' Search(x, index=\"shakespeare\", body=aggs)$hits$hits[[1]] #> $`_index` #> [1] \"shakespeare\" #>  #> $`_type` #> [1] \"_doc\" #>  #> $`_id` #> [1] \"0\" #>  #> $`_score` #> [1] 1 #>  #> $`_source` #> $`_source`$line_id #> [1] 1 #>  #> $`_source`$play_name #> [1] \"Henry IV\" #>  #> $`_source`$line_number #> [1] \"\" #>  #> $`_source`$speaker #> [1] \"\" #>  #> $`_source`$text_entry #> [1] \"ACT I\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"aggregations","dir":"Articles","previous_headings":"The Search function","what":"Aggregations","title":"elastic searching","text":"Histograms","code":"aggs <- '{     \"aggs\": {         \"latbuckets\" : {            \"histogram\" : {                \"field\" : \"decimalLatitude\",                \"interval\" : 5            }         }     } }' Search(x, index=\"gbif\", body=aggs, size=0)$aggregations$latbuckets$buckets[1:3] #> [[1]] #> [[1]]$key #> [1] -35 #>  #> [[1]]$doc_count #> [1] 1 #>  #>  #> [[2]] #> [[2]]$key #> [1] -30 #>  #> [[2]]$doc_count #> [1] 0 #>  #>  #> [[3]] #> [[3]]$key #> [1] -25 #>  #> [[3]]$doc_count #> [1] 0"},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"a-bool-query","dir":"Articles","previous_headings":"The Search function","what":"A bool query","title":"elastic searching","text":"","code":"mmatch <- '{  \"query\": {    \"bool\" : {      \"must_not\" : {        \"range\" : {          \"speech_number\" : {            \"from\" : 1, \"to\": 5 }}}}}}' sapply(Search(x, index=\"shakespeare\", body=mmatch)$hits$hits, function(x) x$`_source`$speech_number) #> [[1]] #> NULL #>  #> [[2]] #> NULL #>  #> [[3]] #> NULL #>  #> [[4]] #> [1] 6 #>  #> [[5]] #> [1] 6 #>  #> [[6]] #> [1] 7 #>  #> [[7]] #> [1] 7 #>  #> [[8]] #> [1] 7 #>  #> [[9]] #> [1] 7 #>  #> [[10]] #> [1] 7"},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"fuzzy-query","dir":"Articles","previous_headings":"The Search function","what":"Fuzzy query","title":"elastic searching","text":"Fuzzy query numerics","code":"fuzzy <- list(query = list(fuzzy = list(text_entry = \"arms\"))) Search(x, index=\"shakespeare\", body = fuzzy)$hits$total #> $value #> [1] 49 #>  #> $relation #> [1] \"eq\" fuzzy <- list(query = list(fuzzy = list(text_entry = list(value = \"arms\", fuzziness = 4)))) Search(x, index=\"shakespeare\", body=fuzzy)$hits$total #> $value #> [1] 618 #>  #> $relation #> [1] \"eq\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"range-query","dir":"Articles","previous_headings":"The Search function","what":"Range query","title":"elastic searching","text":"numeric dates","code":"body <- list(query=list(range=list(decimalLongitude=list(gte=1, lte=3)))) Search(x, 'gbif', body=body)$hits$total #> $value #> [1] 24 #>  #> $relation #> [1] \"eq\" body <- list(query=list(range=list(decimalLongitude=list(gte=2.9, lte=10)))) Search(x, 'gbif', body=body)$hits$total #> $value #> [1] 126 #>  #> $relation #> [1] \"eq\" body <- list(query=list(range=list(eventDate=list(gte=\"2012-01-01\", lte=\"now\")))) Search(x, 'gbif', body=body)$hits$total #> $value #> [1] 301 #>  #> $relation #> [1] \"eq\" body <- list(query=list(range=list(eventDate=list(gte=\"2014-01-01\", lte=\"now\")))) Search(x, 'gbif', body=body)$hits$total #> $value #> [1] 292 #>  #> $relation #> [1] \"eq\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"more-like-this-query-more_like_this-can-be-shortened-to-mlt","dir":"Articles","previous_headings":"The Search function","what":"More-like-this query (more_like_this can be shortened to mlt)","title":"elastic searching","text":"","code":"body <- '{  \"query\": {    \"more_like_this\": {      \"fields\": [\"abstract\",\"title\"],      \"like\": \"and then\",      \"min_term_freq\": 1,      \"max_query_terms\": 12    }  } }' Search(x, 'plos', body=body)$hits$total #> $value #> [1] 488 #>  #> $relation #> [1] \"eq\" body <- '{  \"query\": {    \"more_like_this\": {      \"fields\": [\"abstract\",\"title\"],      \"like\": \"cell\",      \"min_term_freq\": 1,      \"max_query_terms\": 12    }  } }' Search(x, 'plos', body=body)$hits$total #> $value #> [1] 58 #>  #> $relation #> [1] \"eq\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"highlighting","dir":"Articles","previous_headings":"The Search function","what":"Highlighting","title":"elastic searching","text":"","code":"body <- '{  \"query\": {    \"query_string\": {      \"query\" : \"cell\"    }  },  \"highlight\": {    \"fields\": {      \"title\": {\"number_of_fragments\": 2}    }  } }' out <- Search(x, 'plos', body=body) out$hits$total #> $value #> [1] 58 #>  #> $relation #> [1] \"eq\" sapply(out$hits$hits, function(x) x$highlight$title[[1]])[8:10] #> [1] \"Functional Analysis of the Drosophila Embryonic Germ <em>Cell<\/em> Transcriptome by RNA Interference\" #> [2] \"Diversin Is Overexpressed in Breast Cancer and Accelerates <em>Cell<\/em> Proliferation and Invasion\"  #> [3] \"c-FLIP Protects Eosinophils from TNF-α-Mediated <em>Cell<\/em> Death In Vivo\""},{"path":"https://docs.ropensci.org/elastic/articles/search.html","id":"scrolling-search---instead-of-paging","dir":"Articles","previous_headings":"The Search function","what":"Scrolling search - instead of paging","title":"elastic searching","text":"Woohoo! Collected 2747 documents little time.","code":"Search(x, 'shakespeare', q=\"a*\")$hits$total #> $value #> [1] 2747 #>  #> $relation #> [1] \"eq\" res <- Search(x, index = 'shakespeare', q=\"a*\", time_scroll = \"1m\") length(scroll(x, res$`_scroll_id`, time_scroll = \"1m\")$hits$hits) #> [1] 10 res <- Search(x, index = 'shakespeare', q = \"a*\", time_scroll = \"5m\") out <- res$hits$hits hits <- 1 while (hits != 0) {   res <- scroll(x, res$`_scroll_id`)   hits <- length(res$hits$hits)   if (hits > 0)     out <- c(out, res$hits$hits) } length(out) #> [1] 2747 res$hits$total #> $value #> [1] 2747 #>  #> $relation #> [1] \"eq\""},{"path":"https://docs.ropensci.org/elastic/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Scott Chamberlain. Author, maintainer.","code":""},{"path":"https://docs.ropensci.org/elastic/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chamberlain S (2024). elastic: General Purpose Interface 'Elasticsearch'. R package version 1.2.1.91,  https://github.com/ropensci/elastic, https://docs.ropensci.org/elastic/ (website).","code":"@Manual{,   title = {elastic: General Purpose Interface to 'Elasticsearch'},   author = {Scott Chamberlain},   year = {2024},   note = {R package version 1.2.1.91,  https://github.com/ropensci/elastic},   url = {https://docs.ropensci.org/elastic/ (website)}, }"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"elastic","dir":"","previous_headings":"","what":"General Purpose Interface to Elasticsearch","title":"General Purpose Interface to Elasticsearch","text":"general purpose R interface Elasticsearch","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"elasticsearch-info","dir":"","previous_headings":"","what":"Elasticsearch info","title":"General Purpose Interface to Elasticsearch","text":"Elasticsearch home page API docs","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"compatibility","dir":"","previous_headings":"","what":"Compatibility","title":"General Purpose Interface to Elasticsearch","text":"client developed following latest stable releases, currently v7.10.0. generally compatible older versions Elasticsearch. Unlike Python client, try keep much compatibility possible within single version client, ’s easier setup R world.","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"security","dir":"","previous_headings":"","what":"Security","title":"General Purpose Interface to Elasticsearch","text":"’re fine running ES locally machine, careful just throwing ES server public IP address - make sure think security. Elastic paid products - probably applicable enterprise users DIY security - variety techniques securing Elasticsearch installation. number resources collected blog post - tools include putting ES behind something like Nginx, putting basic auth top , using https, etc.","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"General Purpose Interface to Elasticsearch","text":"Stable version CRAN Development version GitHub","code":"install.packages(\"elastic\") remotes::install_github(\"ropensci/elastic\") library('elastic')"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"install-elasticsearch","dir":"","previous_headings":"","what":"Install Elasticsearch","title":"General Purpose Interface to Elasticsearch","text":"Elasticsearch installation help w/ Docker Pull official elasticsearch image start container elasticsearch available port 9200, try curl localhost:9200 get familiar message indicating ES . ’re using boot2docker, ’ll need use IP address place localhost. Get boot2docker ip. OSX Download zip tar file Elasticsearch see download, e.g., curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.0-darwin-x86_64.tar.gz Extract: tar -zxvf elasticsearch-7.10.0-darwin-x86_64.tar.gz Move : sudo mv elasticsearch-7.10.0 /usr/local Navigate /usr/local: cd /usr/local Delete symlinked elasticsearch directory: rm -rf elasticsearch Add shortcut: sudo ln -s elasticsearch-7.10.0 elasticsearch (replace version version) can also install via Homebrew: brew install elasticsearch Note: 1.6 greater upgrades Elasticsearch, want java 8 greater. downloaded Java 8 http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html seemed work great.","code":"# elasticsearch needs to have a version tag. We're pulling 7.10.1 here docker pull elasticsearch:7.10.1 docker run -d -p 9200:9200 elasticsearch:7.10.1"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"upgrading-elasticsearch","dir":"","previous_headings":"","what":"Upgrading Elasticsearch","title":"General Purpose Interface to Elasticsearch","text":"totally clear best practice , understand, upgrade new version Elasticsearch, place old elasticsearch/data elasticsearch/config directories new installation (elasticsearch/ dir). new elasticsearch instance replaced data config directories automatically update data new version start working. Maybe use homebrew Mac upgrade takes care - sure. Obviously, upgrading Elasticsearch keeping running different thing (help Elastic).","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"start-elasticsearch","dir":"","previous_headings":"","what":"Start Elasticsearch","title":"General Purpose Interface to Elasticsearch","text":"Navigate elasticsearch: cd /usr/local/elasticsearch Start elasticsearch: bin/elasticsearch create little bash shortcut called es commands one step (cd /usr/local/elasticsearch && bin/elasticsearch).","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"initialization","dir":"","previous_headings":"","what":"Initialization","title":"General Purpose Interface to Elasticsearch","text":"function connect() used anything else set connection details remote local elasticsearch store. details created connect() written options current session, used elastic functions. ’re following along local instance Elasticsearch, ’ll use x stuff. AWS hosted elasticsearch, make sure specify path = “” correct port - transport schema pair. using Elastic Cloud installation authentication (X-pack), make sure specify path = ““, user =”“, pwd =”” correct port - transport schema pair.","code":"x <- connect(port = 9200) connect(host = <aws_es_endpoint>, path = \"\", port = 80, transport_schema  = \"http\")   # or connect(host = <aws_es_endpoint>, path = \"\", port = 443, transport_schema  = \"https\") connect(host = <ec_endpoint>, path = \"\", user=\"test\", pwd = \"1234\", port = 9243, transport_schema  = \"https\")"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"get-some-data","dir":"","previous_headings":"","what":"Get some data","title":"General Purpose Interface to Elasticsearch","text":"Elasticsearch bulk load API load data fast. format pretty weird though. ’s sort JSON, pass JSON linter. include data sets elastic ’s easy get running, run examples package ’ll actually run way (hopefully). prepare non-exported function useful preparing weird format Elasticsearch wants bulk data loads, somewhat specific PLOS data (See ), modify purposes. See make_bulk_plos() make_bulk_gbif() .","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"shakespeare-data","dir":"","previous_headings":"Get some data","what":"Shakespeare data","title":"General Purpose Interface to Elasticsearch","text":"Elasticsearch provides data Shakespeare plays. ’ve provided subset data package. Get path file specific machine: load data Elasticsearch: make sure create connection object connect() need big data play , shakespeare dataset good one start . can get whole thing pop Elasticsearch (beware, may take 10 minutes .):","code":"shakespeare <- system.file(\"examples\", \"shakespeare_data.json\", package = \"elastic\") # If you're on Elastic v6 or greater, use this one shakespeare <- system.file(\"examples\", \"shakespeare_data_.json\", package = \"elastic\") shakespeare <- type_remover(shakespeare) # x <- connect()  # do this now if you didn't do this above invisible(docs_bulk(x, shakespeare)) curl -XGET https://download.elastic.co/demos/kibana/gettingstarted/shakespeare_6.0.json > shakespeare.json curl -XPUT localhost:9200/_bulk --data-binary @shakespeare.json"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"public-library-of-science-plos-data","dir":"","previous_headings":"Get some data","what":"Public Library of Science (PLOS) data","title":"General Purpose Interface to Elasticsearch","text":"dataset inluded elastic package metadata PLOS scholarly articles. Get file path, load:","code":"if (index_exists(x, \"plos\")) index_delete(x, \"plos\") plosdat <- system.file(\"examples\", \"plos_data.json\", package = \"elastic\") plosdat <- type_remover(plosdat) invisible(docs_bulk(x, plosdat))"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"global-biodiversity-information-facility-gbif-data","dir":"","previous_headings":"Get some data","what":"Global Biodiversity Information Facility (GBIF) data","title":"General Purpose Interface to Elasticsearch","text":"dataset inluded elastic package data GBIF species occurrence records. Get file path, load: GBIF geo data coordinates element allow geo_shape queries","code":"if (index_exists(x, \"gbif\")) index_delete(x, \"gbif\") gbifdat <- system.file(\"examples\", \"gbif_data.json\", package = \"elastic\") gbifdat <- type_remover(gbifdat) invisible(docs_bulk(x, gbifdat)) if (index_exists(x, \"gbifgeo\")) index_delete(x, \"gbifgeo\") gbifgeo <- system.file(\"examples\", \"gbif_geo.json\", package = \"elastic\") gbifgeo <- type_remover(gbifgeo) invisible(docs_bulk(x, gbifgeo))"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"more-data-sets","dir":"","previous_headings":"Get some data","what":"More data sets","title":"General Purpose Interface to Elasticsearch","text":"datasets formatted bulk loading sckott/elastic_data GitHub repository. Find https://github.com/sckott/elastic_data","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"search","dir":"","previous_headings":"","what":"Search","title":"General Purpose Interface to Elasticsearch","text":"Search plos index return 1 result Search plos index, query antibody, limit 1 result","code":"Search(x, index = \"plos\", size = 1)$hits$hits #> [[1]] #> [[1]]$`_index` #> [1] \"plos\" #>  #> [[1]]$`_type` #> [1] \"_doc\" #>  #> [[1]]$`_id` #> [1] \"0\" #>  #> [[1]]$`_score` #> [1] 1 #>  #> [[1]]$`_source` #> [[1]]$`_source`$id #> [1] \"10.1371/journal.pone.0007737\" #>  #> [[1]]$`_source`$title #> [1] \"Phospholipase C-\\u03b24 Is Essential for the Progression of the Normal Sleep Sequence and Ultradian Body Temperature Rhythms in Mice\" Search(x, index = \"plos\", q = \"antibody\", size = 1)$hits$hits #> [[1]] #> [[1]]$`_index` #> [1] \"plos\" #>  #> [[1]]$`_type` #> [1] \"_doc\" #>  #> [[1]]$`_id` #> [1] \"813\" #>  #> [[1]]$`_score` #> [1] 5.18676 #>  #> [[1]]$`_source` #> [[1]]$`_source`$id #> [1] \"10.1371/journal.pone.0107638\" #>  #> [[1]]$`_source`$title #> [1] \"Sortase A Induces Th17-Mediated and Antibody-Independent Immunity to Heterologous Serotypes of Group A Streptococci\""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"get-documents","dir":"","previous_headings":"","what":"Get documents","title":"General Purpose Interface to Elasticsearch","text":"Get document id=4 Get certain fields","code":"docs_get(x, index = 'plos', id = 4) #> $`_index` #> [1] \"plos\" #>  #> $`_type` #> [1] \"_doc\" #>  #> $`_id` #> [1] \"4\" #>  #> $`_version` #> [1] 1 #>  #> $`_seq_no` #> [1] 4 #>  #> $`_primary_term` #> [1] 1 #>  #> $found #> [1] TRUE #>  #> $`_source` #> $`_source`$id #> [1] \"10.1371/journal.pone.0107758\" #>  #> $`_source`$title #> [1] \"Lactobacilli Inactivate Chlamydia trachomatis through Lactic Acid but Not H2O2\" docs_get(x, index = 'plos', id = 4, fields = 'id') #> $`_index` #> [1] \"plos\" #>  #> $`_type` #> [1] \"_doc\" #>  #> $`_id` #> [1] \"4\" #>  #> $`_version` #> [1] 1 #>  #> $`_seq_no` #> [1] 4 #>  #> $`_primary_term` #> [1] 1 #>  #> $found #> [1] TRUE"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"get-multiple-documents-via-the-multiget-api","dir":"","previous_headings":"","what":"Get multiple documents via the multiget API","title":"General Purpose Interface to Elasticsearch","text":"index different document ids","code":"docs_mget(x, index = \"plos\", id = 1:2) #> $docs #> $docs[[1]] #> $docs[[1]]$`_index` #> [1] \"plos\" #>  #> $docs[[1]]$`_type` #> [1] \"_doc\" #>  #> $docs[[1]]$`_id` #> [1] \"1\" #>  #> $docs[[1]]$`_version` #> [1] 1 #>  #> $docs[[1]]$`_seq_no` #> [1] 1 #>  #> $docs[[1]]$`_primary_term` #> [1] 1 #>  #> $docs[[1]]$found #> [1] TRUE #>  #> $docs[[1]]$`_source` #> $docs[[1]]$`_source`$id #> [1] \"10.1371/journal.pone.0098602\" #>  #> $docs[[1]]$`_source`$title #> [1] \"Population Genetic Structure of a Sandstone Specialist and a Generalist Heath Species at Two Levels of Sandstone Patchiness across the Strait of Gibraltar\" #>  #>  #>  #> $docs[[2]] #> $docs[[2]]$`_index` #> [1] \"plos\" #>  #> $docs[[2]]$`_type` #> [1] \"_doc\" #>  #> $docs[[2]]$`_id` #> [1] \"2\" #>  #> $docs[[2]]$`_version` #> [1] 1 #>  #> $docs[[2]]$`_seq_no` #> [1] 2 #>  #> $docs[[2]]$`_primary_term` #> [1] 1 #>  #> $docs[[2]]$found #> [1] TRUE #>  #> $docs[[2]]$`_source` #> $docs[[2]]$`_source`$id #> [1] \"10.1371/journal.pone.0107757\" #>  #> $docs[[2]]$`_source`$title #> [1] \"Cigarette Smoke Extract Induces a Phenotypic Shift in Epithelial Cells; Involvement of HIF1\\u03b1 in Mesenchymal Transition\""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"parsing","dir":"","previous_headings":"","what":"Parsing","title":"General Purpose Interface to Elasticsearch","text":"can optionally get back raw json Search(), docs_get(), docs_mget() setting parameter raw=TRUE. example: parse","code":"(out <- docs_mget(x, index = \"plos\", id = 1:2, raw = TRUE)) #> [1] \"{\\\"docs\\\":[{\\\"_index\\\":\\\"plos\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"1\\\",\\\"_version\\\":1,\\\"_seq_no\\\":1,\\\"_primary_term\\\":1,\\\"found\\\":true,\\\"_source\\\":{\\\"id\\\":\\\"10.1371/journal.pone.0098602\\\",\\\"title\\\":\\\"Population Genetic Structure of a Sandstone Specialist and a Generalist Heath Species at Two Levels of Sandstone Patchiness across the Strait of Gibraltar\\\"}},{\\\"_index\\\":\\\"plos\\\",\\\"_type\\\":\\\"_doc\\\",\\\"_id\\\":\\\"2\\\",\\\"_version\\\":1,\\\"_seq_no\\\":2,\\\"_primary_term\\\":1,\\\"found\\\":true,\\\"_source\\\":{\\\"id\\\":\\\"10.1371/journal.pone.0107757\\\",\\\"title\\\":\\\"Cigarette Smoke Extract Induces a Phenotypic Shift in Epithelial Cells; Involvement of HIF1\\u03b1 in Mesenchymal Transition\\\"}}]}\" #> attr(,\"class\") #> [1] \"elastic_mget\" jsonlite::fromJSON(out) #> $docs #>   _index _type _id _version _seq_no _primary_term found #> 1   plos  _doc   1        1       1             1  TRUE #> 2   plos  _doc   2        1       2             1  TRUE #>                     _source.id #> 1 10.1371/journal.pone.0098602 #> 2 10.1371/journal.pone.0107757 #>                                                                                                                                                _source.title #> 1 Population Genetic Structure of a Sandstone Specialist and a Generalist Heath Species at Two Levels of Sandstone Patchiness across the Strait of Gibraltar #> 2                                Cigarette Smoke Extract Induces a Phenotypic Shift in Epithelial Cells; Involvement of HIF1\\u03b1 in Mesenchymal Transition"},{"path":"https://docs.ropensci.org/elastic/index.html","id":"known-pain-points","dir":"","previous_headings":"","what":"Known pain points","title":"General Purpose Interface to Elasticsearch","text":"HEAD requests don’t seem work, sure allow GET requests, number functions require POST requests obviously won’t work. big one Search(), can use Search_uri() get around , uses GET instead POST, can’t pass complicated query via body","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"screencast","dir":"","previous_headings":"","what":"Screencast","title":"General Purpose Interface to Elasticsearch","text":"screencast introducing package: vimeo.com/124659179","code":""},{"path":"https://docs.ropensci.org/elastic/index.html","id":"meta","dir":"","previous_headings":"","what":"Meta","title":"General Purpose Interface to Elasticsearch","text":"Please report issues bugs License: MIT Get citation information elastic R citation(package = 'elastic') Please note package released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/Search.html","id":null,"dir":"Reference","previous_headings":"","what":"Full text search of Elasticsearch — Search","title":"Full text search of Elasticsearch — Search","text":"Full text search Elasticsearch","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full text search of Elasticsearch — Search","text":"","code":"Search(   conn,   index = NULL,   type = NULL,   q = NULL,   df = NULL,   analyzer = NULL,   default_operator = NULL,   explain = NULL,   source = NULL,   fields = NULL,   sort = NULL,   track_scores = NULL,   timeout = NULL,   terminate_after = NULL,   from = NULL,   size = NULL,   search_type = NULL,   lowercase_expanded_terms = NULL,   analyze_wildcard = NULL,   version = NULL,   lenient = NULL,   body = list(),   raw = FALSE,   asdf = FALSE,   track_total_hits = TRUE,   time_scroll = NULL,   search_path = \"_search\",   stream_opts = list(),   ignore_unavailable = FALSE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/Search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full text search of Elasticsearch — Search","text":"conn Elasticsearch connection object, see connect index Index name, one type Document type. Note type deprecated Elasticsearch v7 greater, removed Elasticsearch v8. strive support types folks using older ES versions q query string (maps query_string query, see Query String Query details). See https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html documentation examples. df (character) default field use field prefix defined within query. analyzer (character) analyzer name used analyzing query string. default_operator (character) default operator used, can . Default: explain (logical) hit, contain explanation scoring hits computed. Default: FALSE source (logical) Set FALSE disable retrieval _source field. can also retrieve part document using _source_include & _source_exclude (see body documentation details). can also include comma-delimited string fields source document want back. See also fields parameter fields (character) selective stored fields document return hit. specifying value cause fields return. Note Elasticsearch v5 greater, fields parameter changed stored_fields, default. can however, pass fields source parameter sort (character) Sorting perform. Can either form fieldName, fieldName:asc/fieldName:desc. fieldName can either actual field within document, special _score name indicate sorting based scores. can several sort parameters (order important). track_scores (logical) sorting, set TRUE order still track scores return part hit. timeout (numeric) search timeout, bounding search request executed within specified time value bail hits accumulated point expired. Default: timeout. terminate_after (numeric) maximum number documents collect shard, upon reaching query execution terminate early. set, response boolean field terminated_early indicate whether query execution actually terminated_early. Default: terminate_after (character) starting index hits return. Pass character string avoid problems large number conversion scientific notation. Default: 0 size (character) number hits return. Pass character string avoid problems large number conversion scientific notation. Default: 10. default maximum 10,000 - however, can change default maximum changing index.max_result_window index level parameter. search_type (character) type search operation perform. Can query_then_fetch (default) dfs_query_then_fetch. Types scan count deprecated. See Elasticsearch docs details different types search can performed. lowercase_expanded_terms (logical) terms automatically lowercased . Default: TRUE. analyze_wildcard (logical) wildcard prefix queries analyzed . Default: FALSE. version (logical) Print document version document. lenient (logical) TRUE cause format based failures (like providing text numeric field) ignored. Default: NULL body Query, either list json. raw (logical) FALSE (default), data parsed list. TRUE, raw JSON returned asdf (logical) TRUE, use fromJSON parse JSON directly data.frame. FALSE (Default), list output given. track_total_hits (logical, numeric) TRUE always track number hits match query accurately. FALSE count documents accurately 10000 documents. .integer count documents accurately number. Default: TRUE time_scroll (character) Specify long consistent view index maintained scrolled search, e.g., \"30s\", \"1m\". See units-time search_path (character) path use searching. Default _search, cases may already base url set using connect(), case can set NULL stream_opts (list) list options passed stream_out - Except pass x data streamed , pass file path instead connection con. pagesize param much less controlled paging ES. ignore_unavailable (logical) specified index name exist. set TRUE indices ignored. ... Curl args passed verb-POST","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Full text search of Elasticsearch — Search","text":"function name \"S\" capitalized avoid conflict function base::search. hate mixing cases, think confuses users, case seems neccessary.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search.html","id":"profile","dir":"Reference","previous_headings":"","what":"profile","title":"Full text search of Elasticsearch — Search","text":"Profile API provides detailed timing information execution individual components search request. See https://www.elastic.co/guide/en/elasticsearch/reference/current/search-profile.html information body query, can set profile: true enable profiling results. e.g.","code":"{   \"profile\": true,   \"query\" : {     \"match\" : { \"message\" : \"some number\" }   } }"},{"path":"https://docs.ropensci.org/elastic/reference/Search.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Full text search of Elasticsearch — Search","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-search.html https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/Search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full text search of Elasticsearch — Search","text":"","code":"if (FALSE) { # make connection object (x <- connect())  # load some data if (!index_exists(x, \"shakespeare\")) {   shakespeare <- system.file(\"examples\", \"shakespeare_data.json\",     package = \"elastic\")   shakespeare <- type_remover(shakespeare)   invisible(docs_bulk(x, shakespeare)) } if (!index_exists(x, \"gbif\")) {   gbif <- system.file(\"examples\", \"gbif_data.json\",     package = \"elastic\")   gbif <- type_remover(gbif)   invisible(docs_bulk(x, gbif)) } if (!index_exists(x, \"plos\")) {   plos <- system.file(\"examples\", \"plos_data.json\",     package = \"elastic\")   plos <- type_remover(plos)   invisible(docs_bulk(x, plos)) }   # URI string queries Search(x, index=\"shakespeare\") ## if you're using an older ES version, you may have types if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 700) {   Search(x, index=\"shakespeare\", type=\"act\")   Search(x, index=\"shakespeare\", type=\"scene\")   Search(x, index=\"shakespeare\", type=\"line\") }  ## Return certain fields if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {   ### ES < v5   Search(x, index=\"shakespeare\", fields=c('play_name','speaker')) } else {   ### ES > v5   Search(x, index=\"shakespeare\", body = '{    \"_source\": [\"play_name\", \"speaker\"]   }') }  ## Search multiple indices Search(x, index = \"gbif\")$hits$total$value Search(x, index = \"shakespeare\")$hits$total$value Search(x, index = c(\"gbif\", \"shakespeare\"))$hits$total$value  ## search_type Search(x, index=\"shakespeare\", search_type = \"query_then_fetch\") Search(x, index=\"shakespeare\", search_type = \"dfs_query_then_fetch\") ### search type \"scan\" is gone - use time_scroll instead Search(x, index=\"shakespeare\", time_scroll = \"2m\") ### search type \"count\" is gone - use size=0 instead Search(x, index=\"shakespeare\", size = 0)$hits$total$value  ## search exists check ### use size set to 0 and terminate_after set to 1 ### if there are > 0 hits, then there are matching documents Search(x, index=\"shakespeare\", size = 0, terminate_after = 1)  ## sorting ### if ES >5, we need to make sure fielddata is turned on for a field  ### before using it for sort  if (gsub(\"\\\\.\", \"\", x$ping()$version$number) >= 500) {  if (index_exists(x, \"shakespeare\")) index_delete(x, \"shakespeare\")  index_create(x, \"shakespeare\")  mapping_create(x, \"shakespeare\", body = '{     \"properties\": {       \"speaker\": {          \"type\":     \"text\",         \"fielddata\": true       }     }   }'  )  shakespeare <- system.file(\"examples\", \"shakespeare_data.json\",    package = \"elastic\")  shakespeare <- type_remover(shakespeare)  invisible(docs_bulk(x, shakespeare))  z <- Search(x, index=\"shakespeare\", sort=\"speaker\", size = 30)  vapply(z$hits$hits, function(w) w$`_source`$speaker, \"\") }  if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {   Search(x, index=\"shakespeare\", type=\"line\", sort=\"speaker:desc\",      fields='speaker')   Search(x, index=\"shakespeare\", type=\"line\",     sort=c(\"speaker:desc\",\"play_name:asc\"), fields=c('speaker','play_name')) }   ## pagination Search(x, index=\"shakespeare\", size=1)$hits$hits Search(x, index=\"shakespeare\", size=1, from=1)$hits$hits  ## queries ### Search in all fields Search(x, index=\"shakespeare\", q=\"york\")  ### Searchin specific fields Search(x, index=\"shakespeare\", q=\"speaker:KING HENRY IV\")$hits$total$value  ### Exact phrase search by wrapping in quotes Search(x, index=\"shakespeare\", q='speaker:\"KING HENRY IV\"')$hits$total$value  ### can specify operators between multiple words parenthetically Search(x, index=\"shakespeare\", q=\"speaker:(HENRY OR ARCHBISHOP)\")$hits$total$value  ### where the field line_number has no value (or is missing) Search(x, index=\"shakespeare\", q=\"_missing_:line_number\")$hits$total$value  ### where the field line_number has any non-null value Search(x, index=\"shakespeare\", q=\"_exists_:line_number\")$hits$total$value  ### wildcards, either * or ? Search(x, index=\"shakespeare\", q=\"*ay\")$hits$total$value Search(x, index=\"shakespeare\", q=\"m?y\")$hits$total$value  ### regular expressions, wrapped in forward slashes Search(x, index=\"shakespeare\", q=\"text_entry:/[a-z]/\")$hits$total$value  ### fuzziness Search(x, index=\"shakespeare\", q=\"text_entry:ma~\")$hits$total$value Search(x, index=\"shakespeare\", q=\"text_entry:the~2\")$hits$total$value Search(x, index=\"shakespeare\", q=\"text_entry:the~1\")$hits$total$value  ### Proximity searches Search(x, index=\"shakespeare\", q='text_entry:\"as hath\"~5')$hits$total$value Search(x, index=\"shakespeare\", q='text_entry:\"as hath\"~10')$hits$total$value  ### Ranges, here where line_id value is between 10 and 20 Search(x, index=\"shakespeare\", q=\"line_id:[10 TO 20]\")$hits$total$value  ### Grouping Search(x, index=\"shakespeare\", q=\"(hath OR as) AND the\")$hits$total$value  # Limit number of hits returned with the size parameter Search(x, index=\"shakespeare\", size=1)  # Give explanation of search in result Search(x, index=\"shakespeare\", size=1, explain=TRUE)  ## terminate query after x documents found ## setting to 1 gives back one document for each shard Search(x, index=\"shakespeare\", terminate_after=1) ## or set to other number Search(x, index=\"shakespeare\", terminate_after=2)  ## Get version number for each document Search(x, index=\"shakespeare\", version=TRUE, size=2)  ## Get raw data Search(x, index=\"shakespeare\", raw = TRUE)  ## Curl options  ### verbose  out <- Search(x, index=\"shakespeare\", verbose = TRUE)   # Query DSL searches - queries sent in the body of the request ## Pass in as an R list  ### if ES >5, we need to make sure fielddata is turned on for a field  ### before using it for aggregations  if (gsub(\"\\\\.\", \"\", x$ping()$version$number) >= 500) {   mapping_create(x, \"shakespeare\", update_all_types = TRUE, body = '{     \"properties\": {       \"text_entry\": {          \"type\":     \"text\",         \"fielddata\": true      }    }  }')  aggs <- list(aggs = list(stats = list(terms = list(field = \"text_entry\"))))  Search(x, index=\"shakespeare\", body=aggs) }  ### if ES >5, you don't need to worry about fielddata if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {    aggs <- list(aggs = list(stats = list(terms = list(field = \"text_entry\"))))    Search(x, index=\"shakespeare\", body=aggs) }  ## or pass in as json query with newlines, easy to read aggs <- '{     \"aggs\": {         \"stats\" : {             \"terms\" : {                 \"field\" : \"speaker\"             }         }     } }' Search(x, index=\"shakespeare\", body=aggs, asdf=TRUE, size = 0)  ## or pass in collapsed json string aggs <- '{\"aggs\":{\"stats\":{\"terms\":{\"field\":\"text_entry\"}}}}' Search(x, index=\"shakespeare\", body=aggs)   ## Aggregations ### Histograms aggs <- '{     \"aggs\": {         \"latbuckets\" : {            \"histogram\" : {                \"field\" : \"decimalLatitude\",                \"interval\" : 5            }         }     } }' Search(x, index=\"gbif\", body=aggs, size=0)  ### Histograms w/ more options aggs <- '{     \"aggs\": {         \"latbuckets\" : {            \"histogram\" : {                \"field\" : \"decimalLatitude\",                \"interval\" : 5,                \"min_doc_count\" : 0,                \"extended_bounds\" : {                    \"min\" : -90,                    \"max\" : 90                }            }         }     } }' Search(x, index=\"gbif\", body=aggs, size=0)  ### Ordering the buckets by their doc_count - ascending: aggs <- '{     \"aggs\": {         \"latbuckets\" : {            \"histogram\" : {                \"field\" : \"decimalLatitude\",                \"interval\" : 5,                \"min_doc_count\" : 0,                \"extended_bounds\" : {                    \"min\" : -90,                    \"max\" : 90                },                \"order\" : {                    \"_count\" : \"desc\"                }            }         }     } }' out <- Search(x, index=\"gbif\", body=aggs, size=0) lapply(out$aggregations$latbuckets$buckets, data.frame)  ### By default, the buckets are returned as an ordered array. It is also possible to ### request the response as a hash instead keyed by the buckets keys: aggs <- '{     \"aggs\": {         \"latbuckets\" : {            \"histogram\" : {                \"field\" : \"decimalLatitude\",                \"interval\" : 10,                \"keyed\" : true            }         }     } }' Search(x, index=\"gbif\", body=aggs, size=0)  # match query match <- '{\"query\": {\"match\" : {\"text_entry\" : \"Two Gentlemen\"}}}' Search(x, index=\"shakespeare\", body=match)  # multi-match (multiple fields that is) query mmatch <- '{\"query\": {\"multi_match\" : {\"query\" : \"henry\", \"fields\": [\"text_entry\",\"play_name\"]}}}' Search(x, index=\"shakespeare\", body=mmatch)  # bool query mmatch <- '{  \"query\": {    \"bool\" : {      \"must_not\" : {        \"range\" : {          \"speech_number\" : {            \"from\" : 1, \"to\": 5 }}}}}}' Search(x, index=\"shakespeare\", body=mmatch)  # Boosting query boost <- '{  \"query\" : {   \"boosting\" : {       \"positive\" : {           \"term\" : {               \"play_name\" : \"henry\"           }       },       \"negative\" : {           \"term\" : {               \"text_entry\" : \"thou\"           }       },       \"negative_boost\" : 0.8     }  } }' Search(x, index=\"shakespeare\", body=boost)  # Fuzzy query ## fuzzy query on numerics fuzzy <- list(query = list(fuzzy = list(text_entry = \"arms\"))) Search(x, index=\"shakespeare\", body=fuzzy)$hits$total$value fuzzy <- list(query = list(fuzzy = list(text_entry = list(value = \"arms\", fuzziness = 4)))) Search(x, index=\"shakespeare\", body=fuzzy)$hits$total$value  # geoshape query ## not working yets geo <- list(query = list(geo_shape = list(location = list(shape = list(type = \"envelope\",    coordinates = \"[[2,10],[10,20]]\"))))) geo <- '{  \"query\": {    \"geo_shape\": {      \"location\": {        \"point\": {          \"type\": \"envelope\",          \"coordinates\": [[2,0],[2.93,100]]        }      }    }  } }' # Search(x, index=\"gbifnewgeo\", body=geo)  # range query ## with numeric body <- list(query=list(range=list(decimalLongitude=list(gte=1, lte=3)))) Search(x, 'gbif', body=body)$hits$total$value  body <- list(query=list(range=list(decimalLongitude=list(gte=2.9, lte=10)))) Search(x, 'gbif', body=body)$hits$total$value  ## with dates body <- list(query=list(range=list(eventDate=list(gte=\"2012-01-01\", lte=\"now\")))) Search(x, 'gbif', body=body)$hits$total$value  body <- list(query=list(range=list(eventDate=list(gte=\"2014-01-01\", lte=\"now\")))) Search(x, 'gbif', body=body)$hits$total$value  # more like this query (more_like_this can be shortened to mlt) body <- '{  \"query\": {    \"more_like_this\": {      \"fields\": [\"title\"],      \"like\": \"and then\",      \"min_term_freq\": 1,      \"max_query_terms\": 12    }  } }' Search(x, 'plos', body=body)$hits$total$value  body <- '{  \"query\": {    \"more_like_this\": {      \"fields\": [\"abstract\",\"title\"],      \"like\": \"cell\",      \"min_term_freq\": 1,      \"max_query_terms\": 12    }  } }' Search(x, 'plos', body=body)$hits$total$value  # Highlighting body <- '{  \"query\": {    \"query_string\": {      \"query\" : \"cell\"    }  },  \"highlight\": {    \"fields\": {      \"title\": {\"number_of_fragments\": 2}    }  } }' out <- Search(x, 'plos', body=body) out$hits$total$value sapply(out$hits$hits, function(x) x$`_source`$title[[1]])  ### Common terms query body <- '{  \"query\" : {    \"match\": {       \"text_entry\": {          \"query\": \"this is\"       }    }  } }' Search(x, 'shakespeare', body=body)  ## Scrolling search - instead of paging res <- Search(x, index = 'shakespeare', q=\"a*\", time_scroll=\"1m\") scroll(x, res$`_scroll_id`)  res <- Search(x, index = 'shakespeare', q=\"a*\", time_scroll=\"5m\") out <- list() hits <- 1 while(hits != 0){   res <- scroll(x, res$`_scroll_id`)   hits <- length(res$hits$hits)   if(hits > 0)     out <- c(out, res$hits$hits) }  ### Sliced scrolling #### For scroll queries that return a lot of documents it is possible to  #### split the scroll in multiple slices which can be consumed independently body1 <- '{   \"slice\": {     \"id\": 0,      \"max\": 2    },   \"query\": {     \"match\" : {       \"text_entry\" : \"a*\"     }   } }'  body2 <- '{   \"slice\": {     \"id\": 1,      \"max\": 2    },   \"query\": {     \"match\" : {       \"text_entry\" : \"a*\"     }   } }'  res1 <- Search(x, index = 'shakespeare', time_scroll=\"1m\", body = body1) res2 <- Search(x, index = 'shakespeare', time_scroll=\"1m\", body = body2) scroll(x, res1$`_scroll_id`) scroll(x, res2$`_scroll_id`)  out1 <- list() hits <- 1 while(hits != 0){   tmp1 <- scroll(x, res1$`_scroll_id`)   hits <- length(tmp1$hits$hits)   if(hits > 0)     out1 <- c(out1, tmp1$hits$hits) }  out2 <- list() hits <- 1 while(hits != 0) {   tmp2 <- scroll(x, res2$`_scroll_id`)   hits <- length(tmp2$hits$hits)   if(hits > 0)     out2 <- c(out2, tmp2$hits$hits) }  c(  lapply(out1, \"[[\", \"_source\"),  lapply(out2, \"[[\", \"_source\") )     # Using filters ## A bool filter body <- '{  \"query\":{    \"bool\": {      \"must_not\" : {        \"range\" : {          \"year\" : { \"from\" : 2011, \"to\" : 2012 }        }      }    }  } }' Search(x, 'gbif', body = body)$hits$total$value  ## Geo filters - fun! ### Note that filers have many geospatial filter options, but queries  ### have fewer, andrequire a geo_shape mapping  body <- '{  \"mappings\": {      \"properties\": {          \"location\" : {\"type\" : \"geo_point\"}       }    } }' index_recreate(x, index='gbifgeopoint', body=body) path <- system.file(\"examples\", \"gbif_geopoint.json\",   package = \"elastic\") path <- type_remover(path) invisible(docs_bulk(x, path))  ### Points within a bounding box body <- '{  \"query\":{    \"bool\" : {      \"must\" : {        \"match_all\" : {}      },      \"filter\":{         \"geo_bounding_box\" : {           \"location\" : {             \"top_left\" : {               \"lat\" : 60,               \"lon\" : 1             },             \"bottom_right\" : {               \"lat\" : 40,               \"lon\" : 14             }           }        }      }    }  } }' out <- Search(x, 'gbifgeopoint', body = body, size = 300) out$hits$total$value do.call(rbind, lapply(out$hits$hits, function(x) x$`_source`$location))  ### Points within distance of a point body <- '{ \"query\": {   \"bool\" : {     \"must\" : {       \"match_all\" : {}     },    \"filter\" : {      \"geo_distance\" : {        \"distance\" : \"200km\",        \"location\" : {          \"lon\" : 4,          \"lat\" : 50        }      }   } }}}' out <- Search(x, 'gbifgeopoint', body = body) out$hits$total$value do.call(rbind, lapply(out$hits$hits, function(x) x$`_source`$location))  ### Points within distance range of a point body <- '{  \"aggs\":{    \"points_within_dist\" : {      \"geo_distance\" : {         \"field\": \"location\",         \"origin\" : \"4, 50\",         \"ranges\": [            {\"from\" : 200},           {\"to\" : 400}          ]      }    }  } }' out <- Search(x, 'gbifgeopoint', body = body) out$hits$total$value do.call(rbind, lapply(out$hits$hits, function(x) x$`_source`$location))  ### Points within a polygon body <- '{  \"query\":{    \"bool\" : {      \"must\" : {        \"match_all\" : {}      },      \"filter\":{         \"geo_polygon\" : {           \"location\" : {              \"points\" : [                [80.0, -20.0], [-80.0, -20.0], [-80.0, 60.0], [40.0, 60.0], [80.0, -20.0]              ]            }          }        }      }    } }' out <- Search(x, 'gbifgeopoint', body = body) out$hits$total$value do.call(rbind, lapply(out$hits$hits, function(x) x$`_source`$location))  ### Geoshape filters using queries instead of filters #### Get data with geojson type location data loaded first body <- '{  \"mappings\": {      \"properties\": {          \"location\" : {\"type\" : \"geo_shape\"}       }    } }' index_recreate(x, index='geoshape', body=body) path <- system.file(\"examples\", \"gbif_geoshape.json\",   package = \"elastic\") path <- type_remover(path) invisible(docs_bulk(x, path))  #### Get data with a square envelope, w/ point defining upper left and the other #### defining the lower right body <- '{  \"query\":{    \"geo_shape\" : {      \"location\" : {          \"shape\" : {            \"type\": \"envelope\",             \"coordinates\": [[-30, 50],[30, 0]]          }        }      }    } }' out <- Search(x, 'geoshape', body = body) out$hits$total$value  #### Get data with a circle, w/ point defining center, and radius body <- '{  \"query\":{    \"geo_shape\" : {      \"location\" : {          \"shape\" : {            \"type\": \"circle\",            \"coordinates\": [-10, 45],            \"radius\": \"2000km\"          }        }      }    } }' out <- Search(x, 'geoshape', body = body) out$hits$total$value  #### Use a polygon, w/ point defining center, and radius body <- '{  \"query\":{    \"geo_shape\" : {      \"location\" : {          \"shape\" : {            \"type\": \"polygon\",            \"coordinates\":  [               [ [80.0, -20.0], [-80.0, -20.0], [-80.0, 60.0], [40.0, 60.0], [80.0, -20.0] ]            ]          }        }      }    } }' out <- Search(x, 'geoshape', body = body) out$hits$total$value   # Geofilter with WKT # format follows \"BBOX (minlon, maxlon, maxlat, minlat)\" body <- '{     \"query\": {         \"bool\" : {             \"must\" : {                 \"match_all\" : {}             },             \"filter\" : {                 \"geo_bounding_box\" : {                     \"location\" : {                         \"wkt\" : \"BBOX (1, 14, 60, 40)\"                     }                 }             }         }     } }' out <- Search(x, 'gbifgeopoint', body = body) out$hits$total$value    # Missing filter if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {   ### ES < v5   body <- '{    \"query\":{      \"constant_score\" : {        \"filter\" : {          \"missing\" : { \"field\" : \"play_name\" }        }      }     }   }'   Search(x, \"shakespeare\", body = body) } else {   ### ES => v5   body <- '{    \"query\":{      \"bool\" : {        \"must_not\" : {          \"exists\" : {             \"field\" : \"play_name\"           }        }     }    }   }'   Search(x, \"shakespeare\", body = body) }  # prefix filter body <- '{  \"query\": {    \"bool\": {      \"must\": {        \"prefix\" : {          \"speaker\" : \"we\"        }      }    }  } }' z <- Search(x, \"shakespeare\", body = body) z$hits$total$value vapply(z$hits$hits, \"[[\", \"\", c(\"_source\", \"speaker\"))   # ids filter if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {   ### ES < v5   body <- '{    \"query\":{      \"bool\": {        \"must\": {          \"ids\" : {            \"values\": [\"1\",\"2\",\"10\",\"2000\"]         }       }     }    }   }'   z <- Search(x, \"shakespeare\", body = body)   z$hits$total$value   identical(    c(\"1\",\"2\",\"10\",\"2000\"),    vapply(z$hits$hits, \"[[\", \"\", \"_id\")   ) } else {   body <- '{    \"query\":{      \"ids\" : {        \"values\": [\"1\",\"2\",\"10\",\"2000\"]      }    }   }'   z <- Search(x, \"shakespeare\", body = body)   z$hits$total$value   identical(    c(\"1\",\"2\",\"10\",\"2000\"),    vapply(z$hits$hits, \"[[\", \"\", \"_id\")   ) }  # combined prefix and ids filters if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {   ### ES < v5   body <- '{    \"query\":{      \"bool\" : {        \"should\" : {          \"or\": [{            \"ids\" : {              \"values\": [\"1\",\"2\",\"3\",\"10\",\"2000\"]            }          }, {          \"prefix\" : {            \"speaker\" : \"we\"          }         }       ]      }     }    }   }'   z <- Search(x, \"shakespeare\", body = body)   z$hits$total$value } else {   ### ES => v5   body <- '{    \"query\":{      \"bool\" : {        \"should\" : [          {            \"ids\" : {              \"values\": [\"1\",\"2\",\"3\",\"10\",\"2000\"]            }          },           {            \"prefix\" : {              \"speaker\" : \"we\"            }          }       ]      }     }   }'   z <- Search(x, \"shakespeare\", body = body)   z$hits$total$value }  # Suggestions sugg <- '{  \"query\" : {     \"match\" : {       \"text_entry\" : \"late\"      }  },    \"suggest\" : {    \"sugg\" : {      \"text\" : \"late\",      \"term\" : {          \"field\" : \"text_entry\"       }     }   } }' Search(x, index = \"shakespeare\", body = sugg,    asdf = TRUE, size = 0)$suggest$sugg$options    # stream data out using jsonlite::stream_out file <- tempfile() res <- Search(x, \"shakespeare\", size = 1000, stream_opts = list(file = file)) head(df <- jsonlite::stream_in(file(file))) NROW(df) unlink(file)   # get profile data body <- '{   \"profile\": true,   \"query\" : {     \"match\" : { \"text_entry\" : \"war\" }   } }' res <- Search(x, \"shakespeare\", body = body) res$profile # time in nanoseconds across each of the shards vapply(res$profile$shards, function(w) {   w$searches[[1]]$query[[1]]$time_in_nanos }, 1) }"},{"path":"https://docs.ropensci.org/elastic/reference/Search_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Search or validate templates — Search_template","title":"Search or validate templates — Search_template","text":"Search validate templates","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search or validate templates — Search_template","text":"","code":"Search_template(conn, body = list(), raw = FALSE, ...)  Search_template_register(conn, template, body = list(), raw = FALSE, ...)  Search_template_get(conn, template, ...)  Search_template_delete(conn, template, ...)  Search_template_render(conn, body = list(), raw = FALSE, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/Search_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search or validate templates — Search_template","text":"conn Elasticsearch connection object, see connect() body Query, either list json. raw (logical) FALSE (default), data parsed list. TRUE, raw JSON returned ... Curl args passed crul::verb-POST template (character) template name","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search_template.html","id":"template-search","dir":"Reference","previous_headings":"","what":"Template search","title":"Search or validate templates — Search_template","text":"Search_template can search template, using mustache templating. Added Elasticsearch v1.1","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search_template.html","id":"template-render","dir":"Reference","previous_headings":"","what":"Template render","title":"Search or validate templates — Search_template","text":"Search_template_render validate template without conducting search. Added Elasticsearch v2.0","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search_template.html","id":"pre-registered-templates","dir":"Reference","previous_headings":"","what":"Pre-registered templates","title":"Search or validate templates — Search_template","text":"Register template Search_template_register. can get template Search_template_get delete template Search_template_delete can also pre-register search templates storing config/scripts directory, file using .mustache extension. order execute stored template, reference name template key, like \"file\": \"templateName\", ...","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search_template.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Search or validate templates — Search_template","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-template.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/Search_template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search or validate templates — Search_template","text":"","code":"if (FALSE) { # connection setup (x <- connect())  if (!index_exists(x, \"iris\")) {   invisible(docs_bulk(x, iris, \"iris\")) }  body1 <- '{   \"inline\" : {     \"query\": { \"match\" : { \"{{my_field}}\" : \"{{my_value}}\" } },     \"size\" : \"{{my_size}}\"   },   \"params\" : {     \"my_field\" : \"Species\",     \"my_value\" : \"setosa\",     \"my_size\" : 3   } }' Search_template(x, body = body1)  body2 <- '{  \"inline\": {    \"query\": {       \"match\": {           \"Species\": \"{{query_string}}\"       }    }  },  \"params\": {    \"query_string\": \"versicolor\"  } }' Search_template(x, body = body2)  # pass in a list mylist <- list(   inline = list(query = list(match = list(`{{my_field}}` = \"{{my_value}}\"))),   params = list(my_field = \"Species\", my_value = \"setosa\", my_size = 3L) ) Search_template(x, body = mylist)  ## Validating templates w/ Search_template_render() Search_template_render(x, body = body1) Search_template_render(x, body = body2)  ## pre-registered templates ### register a template if (x$es_ver() <= 520) {   body3 <- '{     \"template\": {        \"query\": {            \"match\": {                \"Species\": \"{{query_string}}\"            }        }      }   }'   Search_template_register(x, 'foobar', body = body3) } else {   body3 <- '{    \"script\": {      \"lang\": \"mustache\",        \"source\": {          \"query\": {            \"match\": {              \"Species\": \"{{query_string}}\"            }          }        }      }   }'   Search_template_register(x, 'foobar', body = body3) }  ### get template Search_template_get(x, 'foobar')  ### use the template body4 <- '{  \"id\": \"foobar\",     \"params\": {       \"query_string\": \"setosa\"   } }' Search_template(x, body = body4)  ### delete the template Search_template_delete(x, 'foobar') }"},{"path":"https://docs.ropensci.org/elastic/reference/Search_uri.html","id":null,"dir":"Reference","previous_headings":"","what":"Full text search of Elasticsearch with URI search — Search_uri","title":"Full text search of Elasticsearch with URI search — Search_uri","text":"Full text search Elasticsearch URI search","code":""},{"path":"https://docs.ropensci.org/elastic/reference/Search_uri.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full text search of Elasticsearch with URI search — Search_uri","text":"","code":"Search_uri(   conn,   index = NULL,   type = NULL,   q = NULL,   df = NULL,   analyzer = NULL,   default_operator = NULL,   explain = NULL,   source = NULL,   fields = NULL,   sort = NULL,   track_scores = NULL,   timeout = NULL,   terminate_after = NULL,   from = NULL,   size = NULL,   search_type = NULL,   lowercase_expanded_terms = NULL,   analyze_wildcard = NULL,   version = NULL,   lenient = NULL,   raw = FALSE,   asdf = FALSE,   track_total_hits = TRUE,   search_path = \"_search\",   stream_opts = list(),   ignore_unavailable = FALSE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/Search_uri.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full text search of Elasticsearch with URI search — Search_uri","text":"conn Elasticsearch connection object, see connect index Index name, one type Document type. Note type deprecated Elasticsearch v7 greater, removed Elasticsearch v8. strive support types folks using older ES versions q query string (maps query_string query, see Query String Query details). See https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html documentation examples. df (character) default field use field prefix defined within query. analyzer (character) analyzer name used analyzing query string. default_operator (character) default operator used, can . Default: explain (logical) hit, contain explanation scoring hits computed. Default: FALSE source (logical) Set FALSE disable retrieval _source field. can also retrieve part document using _source_include & _source_exclude (see body documentation details). can also include comma-delimited string fields source document want back. See also fields parameter fields (character) selective stored fields document return hit. specifying value cause fields return. Note Elasticsearch v5 greater, fields parameter changed stored_fields, default. can however, pass fields source parameter sort (character) Sorting perform. Can either form fieldName, fieldName:asc/fieldName:desc. fieldName can either actual field within document, special _score name indicate sorting based scores. can several sort parameters (order important). track_scores (logical) sorting, set TRUE order still track scores return part hit. timeout (numeric) search timeout, bounding search request executed within specified time value bail hits accumulated point expired. Default: timeout. terminate_after (numeric) maximum number documents collect shard, upon reaching query execution terminate early. set, response boolean field terminated_early indicate whether query execution actually terminated_early. Default: terminate_after (character) starting index hits return. Pass character string avoid problems large number conversion scientific notation. Default: 0 size (character) number hits return. Pass character string avoid problems large number conversion scientific notation. Default: 10. default maximum 10,000 - however, can change default maximum changing index.max_result_window index level parameter. search_type (character) type search operation perform. Can query_then_fetch (default) dfs_query_then_fetch. Types scan count deprecated. See Elasticsearch docs details different types search can performed. lowercase_expanded_terms (logical) terms automatically lowercased . Default: TRUE. analyze_wildcard (logical) wildcard prefix queries analyzed . Default: FALSE. version (logical) Print document version document. lenient (logical) TRUE cause format based failures (like providing text numeric field) ignored. Default: NULL raw (logical) FALSE (default), data parsed list. TRUE, raw JSON returned asdf (logical) TRUE, use fromJSON parse JSON directly data.frame. FALSE (Default), list output given. track_total_hits (logical, numeric) TRUE always track number hits match query accurately. FALSE count documents accurately 10000 documents. .integer count documents accurately number. Default: TRUE search_path (character) path use searching. Default _search, cases may already base url set using connect(), case can set NULL stream_opts (list) list options passed stream_out - Except pass x data streamed , pass file path instead connection con. pagesize param much less controlled paging ES. ignore_unavailable (logical) specified index name exist. set TRUE indices ignored. ... Curl args passed verb-POST","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/Search_uri.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full text search of Elasticsearch with URI search — Search_uri","text":"","code":"if (FALSE) { # connection setup (x <- connect())  # URI string queries Search_uri(x, index=\"shakespeare\") ## if you're using an older ES version, you may have types if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 700) { Search_uri(x, index=\"shakespeare\", type=\"act\") Search_uri(x, index=\"shakespeare\", type=\"scene\") Search_uri(x, index=\"shakespeare\", type=\"line\") }  ## Return certain fields if (gsub(\"\\\\.\", \"\", ping()$version$number) < 500) {   ### ES < v5   Search_uri(x, index=\"shakespeare\", fields=c('play_name','speaker')) } else {   ### ES > v5   Search_uri(x, index=\"shakespeare\", source=c('play_name','speaker')) }  ## Search many indices Search_uri(x, index = \"gbif\")$hits$total$value Search_uri(x, index = \"shakespeare\")$hits$total$value Search_uri(x, index = c(\"gbif\", \"shakespeare\"))$hits$total$value  ## search_type ## NOTE: If you're in ES V5 or greater, see \\code{?fielddata} Search_uri(x, index=\"shakespeare\", search_type = \"query_then_fetch\") Search_uri(x, index=\"shakespeare\", search_type = \"dfs_query_then_fetch\") # Search_uri(x, index=\"shakespeare\", search_type = \"scan\") # only when scrolling  ## sorting Search_uri(x, index=\"shakespeare\", sort=\"text_entry\") if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {   Search_uri(x, index=\"shakespeare\", sort=\"speaker:desc\", fields='speaker')   Search_uri(x, index=\"shakespeare\", sort=c(\"speaker:desc\",\"play_name:asc\"),     fields=c('speaker','play_name')) }  ## pagination Search_uri(x, index=\"shakespeare\", size=1)$hits$hits Search_uri(x, index=\"shakespeare\", size=1, from=1)$hits$hits  ## queries ### Search in all fields Search_uri(x, index=\"shakespeare\", q=\"york\")  ### Searchin specific fields Search_uri(x, index=\"shakespeare\", q=\"speaker:KING HENRY IV\")$hits$total$value  ### Exact phrase search by wrapping in quotes Search_uri(x, index=\"shakespeare\", q='speaker:\"KING HENRY IV\"')$hits$total$value  ### can specify operators between multiple words parenthetically Search_uri(x, index=\"shakespeare\", q=\"speaker:(HENRY OR ARCHBISHOP)\")$hits$total$value  ### where the field line_number has no value (or is missing) Search_uri(x, index=\"shakespeare\", q=\"_missing_:line_number\")$hits$total$value  ### where the field line_number has any non-null value Search_uri(x, index=\"shakespeare\", q=\"_exists_:line_number\")$hits$total$value  ### wildcards, either * or ? Search_uri(x, index=\"shakespeare\", q=\"*ay\")$hits$total$value Search_uri(x, index=\"shakespeare\", q=\"m?y\")$hits$total$value  ### regular expressions, wrapped in forward slashes Search_uri(x, index=\"shakespeare\", q=\"text_entry:/[a-z]/\")$hits$total$value  ### fuzziness Search_uri(x, index=\"shakespeare\", q=\"text_entry:ma~\")$hits$total$value Search_uri(x, index=\"shakespeare\", q=\"text_entry:the~2\")$hits$total$value Search_uri(x, index=\"shakespeare\", q=\"text_entry:the~1\")$hits$total$value  ### Proximity searches Search_uri(x, index=\"shakespeare\", q='text_entry:\"as hath\"~5')$hits$total$value Search_uri(x, index=\"shakespeare\", q='text_entry:\"as hath\"~10')$hits$total$value  ### Ranges, here where line_id value is between 10 and 20 Search_uri(x, index=\"shakespeare\", q=\"line_id:[10 TO 20]\")$hits$total$value  ### Grouping Search_uri(x, index=\"shakespeare\", q=\"(hath OR as) AND the\")$hits$total$value  # Limit number of hits returned with the size parameter Search_uri(x, index=\"shakespeare\", size=1)  # Give explanation of search in result Search_uri(x, index=\"shakespeare\", size=1, explain=TRUE)  ## terminate query after x documents found ## setting to 1 gives back one document for each shard Search_uri(x, index=\"shakespeare\", terminate_after=1) ## or set to other number Search_uri(x, index=\"shakespeare\", terminate_after=2)  ## Get version number for each document Search_uri(x, index=\"shakespeare\", version=TRUE, size=2)  ## Get raw data Search_uri(x, index=\"shakespeare\", raw=TRUE)  ## Curl options ### verbose out <- Search_uri(x, index=\"shakespeare\", verbose = TRUE) }"},{"path":"https://docs.ropensci.org/elastic/reference/alias.html","id":null,"dir":"Reference","previous_headings":"","what":"Elasticsearch alias APIs — alias","title":"Elasticsearch alias APIs — alias","text":"Elasticsearch alias APIs","code":""},{"path":"https://docs.ropensci.org/elastic/reference/alias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elasticsearch alias APIs — alias","text":"","code":"alias_get(conn, index = NULL, alias = NULL, ignore_unavailable = FALSE, ...)  aliases_get(conn, index = NULL, alias = NULL, ignore_unavailable = FALSE, ...)  alias_exists(conn, index = NULL, alias = NULL, ...)  alias_create(   conn,   index,   alias,   filter = NULL,   routing = NULL,   search_routing = NULL,   index_routing = NULL,   ... )  alias_rename(conn, index, alias, alias_new, ...)  alias_delete(conn, index = NULL, alias, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/alias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elasticsearch alias APIs — alias","text":"conn Elasticsearch connection object, see connect() index (character) index name alias (character) alias name ignore_unavailable (logical) specified index name exist. set TRUE indices ignored. ... Curl args passed crul::verb-POST, crul::verb-GET, crul::verb-HEAD, crul::verb-DELETE filter (named list) provides easy way create different \"views\" index. Defined using Query DSL applied Search, Count, Delete Query Like operations alias. See examples routing, search_routing, index_routing (character) Associate routing value alias alias_new (character) new alias name, used rename ","code":""},{"path":"https://docs.ropensci.org/elastic/reference/alias.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Elasticsearch alias APIs — alias","text":"Note can also create aliases create indices putting directive request body. See Elasticsearch docs link","code":""},{"path":"https://docs.ropensci.org/elastic/reference/alias.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Elasticsearch alias APIs — alias","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/alias.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Elasticsearch alias APIs — alias","text":"Scott Chamberlain myrmecocystus@gmail.com","code":""},{"path":"https://docs.ropensci.org/elastic/reference/alias.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elasticsearch alias APIs — alias","text":"","code":"if (FALSE) { # connection setup (x <- connect())  if (!index_exists(x, \"plos\")) {   plosdat <- system.file(\"examples\", \"plos_data.json\", package = \"elastic\")   invisible(docs_bulk(x, plosdat)) } if (!index_exists(x, \"shakespeare\")) {   shake <- system.file(\"examples\", \"shakespeare_data_.json\", package = \"elastic\")   invisible(docs_bulk(x, shake)) }  # Create/update an alias alias_create(x, index = \"plos\", alias = \"candles\") ## more than one alias alias_create(x, index = \"plos\", alias = c(\"tables\", \"chairs\"))  # associate an alias with two multiple different indices alias_create(x, index = c(\"plos\", \"shakespeare\"), alias = \"stools\")  # Retrieve a specified alias alias_get(x, index=\"plos\") alias_get(x, alias=\"tables\") alias_get(x, alias=\"stools\") aliases_get(x)  # rename an alias aliases_get(x, \"plos\") alias_rename(x, index = 'plos', alias = \"stools\", alias_new = \"plates\") aliases_get(x, \"plos\")  # filtered aliases alias_create(x, index = \"plos\", alias = \"candles\",    filter = list(wildcard = list(title = \"cell\"))) ## a search with the alias should give titles with cell in them (titles <- Search(x, \"candles\", asdf = TRUE)$hits$hits$`_source.title`) grepl(\"cell\", titles, ignore.case = TRUE)  # routing alias_create(x, index = \"plos\", alias = \"candles\",    routing = \"1\")  # Check for alias existence alias_exists(x, index = \"plos\") alias_exists(x, alias = \"tables\") alias_exists(x, alias = \"adsfasdf\")  # Delete an alias alias_delete(x, index = \"plos\", alias = \"tables\") alias_exists(x, alias = \"tables\")  # Curl options alias_create(x, index = \"plos\", alias = \"tables\") aliases_get(x, alias = \"tables\", verbose = TRUE) }"},{"path":"https://docs.ropensci.org/elastic/reference/cat.html","id":null,"dir":"Reference","previous_headings":"","what":"Use the cat Elasticsearch api. — cat","title":"Use the cat Elasticsearch api. — cat","text":"Use cat Elasticsearch api.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use the cat Elasticsearch api. — cat","text":"","code":"cat_(conn, parse = FALSE, ...)  cat_aliases(   conn,   verbose = FALSE,   index = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   expand_wildcards = \"all\",   ... )  cat_allocation(   conn,   verbose = FALSE,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_count(   conn,   verbose = FALSE,   index = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_segments(   conn,   verbose = FALSE,   index = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_health(   conn,   verbose = FALSE,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_indices(   conn,   verbose = FALSE,   index = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_master(   conn,   verbose = FALSE,   index = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_nodes(   conn,   verbose = FALSE,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_nodeattrs(   conn,   verbose = FALSE,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_pending_tasks(   conn,   verbose = FALSE,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_plugins(   conn,   verbose = FALSE,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_recovery(   conn,   verbose = FALSE,   index = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_thread_pool(   conn,   verbose = FALSE,   index = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_shards(   conn,   verbose = FALSE,   index = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )  cat_fielddata(   conn,   verbose = FALSE,   index = NULL,   fields = NULL,   h = NULL,   help = FALSE,   bytes = FALSE,   parse = FALSE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use the cat Elasticsearch api. — cat","text":"conn Elasticsearch connection object, see connect() parse (logical) Parse data.frame . Default: FALSE ... Curl args passed crul::HttpClient verbose (logical) TRUE (default) url call used printed console index (character) Index name h (character) Fields return help (logical) Output available columns, meanings bytes (logical) Give numbers back machine friendly. Default: FALSE expand_wildcards (character) Whether expand wildcard expression concrete indices open, closed .  Valid choices: 'open', 'closed', 'hidden', 'none', ''. default: ''. Available ES >= v7.7 fields (character) Fields return, used fielddata","code":""},{"path":"https://docs.ropensci.org/elastic/reference/cat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use the cat Elasticsearch api. — cat","text":"See https://www.elastic.co/guide/en/elasticsearch/reference/current/cat.html cat API documentation. Note cat_() underscore end avoid conflict function base::cat() base R.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/cat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use the cat Elasticsearch api. — cat","text":"","code":"if (FALSE) { # connection setup (x <- connect())  # list Elasticsearch cat endpoints cat_(x)  # Do other cat operations cat_aliases(x) alias_create(x, index = \"plos\", alias = c(\"tables\", \"chairs\")) cat_aliases(x, expand_wildcards='open') cat_aliases(x, expand_wildcards='all') cat_allocation(x) cat_allocation(x, verbose=TRUE) cat_count(x) cat_count(x, index='plos') cat_count(x, index='gbif') cat_segments(x) cat_segments(x, index='gbif') cat_health(x) cat_indices(x) cat_master(x) cat_nodes(x) # cat_nodeattrs(x) # not available in older ES versions cat_pending_tasks(x) cat_plugins(x) cat_recovery(x, verbose=TRUE) cat_recovery(x, index='gbif') cat_thread_pool(x) cat_thread_pool(x, verbose=TRUE) cat_shards(x) cat_fielddata(x) cat_fielddata(x, fields='body')  # capture cat data into a data.frame cat_(x, parse = TRUE) cat_indices(x, parse = TRUE) cat_indices(x, parse = TRUE, verbose = TRUE) cat_count(x, parse = TRUE) cat_count(x, parse = TRUE, verbose = TRUE) cat_health(x, parse = TRUE) cat_health(x, parse = TRUE, verbose = TRUE)  # Get help - what does each column mean head(cat_indices(x, help = TRUE, parse = TRUE)) cat_health(x, help = TRUE, parse = TRUE) head(cat_nodes(x, help = TRUE, parse = TRUE))  # Get back only certain fields cat_nodes(x) cat_nodes(x, h = c('ip','port','heapPercent','name')) cat_nodes(x, h = c('id', 'ip', 'port', 'v', 'm')) cat_indices(x, verbose = TRUE) cat_indices(x, verbose = TRUE, h = c('index','docs.count','store.size'))  # Get back machine friendly numbers instead of the normal human friendly cat_indices(x, verbose = TRUE, bytes = TRUE)  # Curl options # cat_count(x, timeout_ms = 1) }"},{"path":"https://docs.ropensci.org/elastic/reference/cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Elasticsearch cluster endpoints — cluster","title":"Elasticsearch cluster endpoints — cluster","text":"Elasticsearch cluster endpoints","code":""},{"path":"https://docs.ropensci.org/elastic/reference/cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elasticsearch cluster endpoints — cluster","text":"","code":"cluster_settings(   conn,   index = NULL,   raw = FALSE,   callopts = list(),   verbose = TRUE,   ... )  cluster_health(   conn,   index = NULL,   level = NULL,   wait_for_status = NULL,   wait_for_relocating_shards = NULL,   wait_for_active_shards = NULL,   wait_for_nodes = NULL,   timeout = NULL,   raw = FALSE,   callopts = list(),   verbose = TRUE,   ... )  cluster_state(   conn,   index = NULL,   metrics = NULL,   raw = FALSE,   callopts = list(),   verbose = TRUE,   ... )  cluster_stats(   conn,   index = NULL,   raw = FALSE,   callopts = list(),   verbose = TRUE,   ... )  cluster_reroute(conn, body, raw = FALSE, callopts = list(), ...)  cluster_pending_tasks(   conn,   index = NULL,   raw = FALSE,   callopts = list(),   verbose = TRUE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elasticsearch cluster endpoints — cluster","text":"conn Elasticsearch connection object, see connect() index Index raw TRUE (default), data parsed list. FALSE, raw JSON. callopts Curl args passed crul::verb-POST verbose TRUE (default) url call used printed console. ... args passed elastic search HTTP API parameters. level Can one cluster, indices shards. Controls details level health information returned. Defaults cluster. wait_for_status One green, yellow red. wait (timeout provided) status cluster changes one provided better, .e. green > yellow > red. default, wait status. wait_for_relocating_shards number controlling many relocating shards wait . Usually 0 indicate wait till relocations happened. Defaults wait. wait_for_active_shards number controlling many active shards wait . Defaults wait. wait_for_nodes request waits specified number N nodes available. also accepts >=N, <=N, >N <N. Alternatively, possible use ge(N), le(N), gt(N) lt(N) notation. timeout time based parameter controlling long wait one wait_for_XXX provided. Defaults 30s. metrics One version, master_node, nodes, routing_table, metadata, blocks. See Details. body Query, either list json.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/cluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Elasticsearch cluster endpoints — cluster","text":"metrics param options: version Shows cluster state version. master_node Shows elected master_node part response nodes Shows nodes part response routing_table Shows routing_table part response. supply comma separated list indices, returned output contain indices listed. metadata Shows metadata part response. supply comma separated list indices, returned output contain indices listed. blocks Shows blocks part response Additional parameters can passed : metric comma-separated list metrics display. Possible values: '_all', 'completion', 'docs', 'fielddata', 'filter_cache', 'flush', 'get', 'id_cache', 'indexing', 'merge', 'percolate', 'refresh', 'search', 'segments', 'store', 'warmer' completion_fields comma-separated list fields completion metric (supports wildcards) fielddata_fields comma-separated list fields fielddata metric (supports wildcards) fields comma-separated list fields fielddata completion metric (supports wildcards) groups comma-separated list search groups search statistics allow_no_indices Whether ignore wildcard indices expression resolves concrete indices. (includes _all string indices specified) expand_wildcards Whether expand wildcard expression concrete indices open, closed . ignore_indices performed multiple indices, allows ignore missing ones (default: none) ignore_unavailable Whether specified concrete indices ignored unavailable (missing closed) human Whether return time byte values human-readable format. level Return stats aggregated cluster, index shard level. ('cluster', 'indices' 'shards', default: 'indices') types comma-separated list document types indexing index metric","code":""},{"path":"https://docs.ropensci.org/elastic/reference/cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elasticsearch cluster endpoints — cluster","text":"","code":"if (FALSE) { # connection setup (x <- connect())  cluster_settings(x) cluster_health(x)  cluster_state(x) cluster_state(x, metrics = \"version\") cluster_state(x, metrics = \"nodes\") cluster_state(x, metrics = c(\"version\", \"nodes\")) cluster_state(x, metrics = c(\"version\", \"nodes\", 'blocks')) cluster_state(x, \"shakespeare\", metrics = \"metadata\") cluster_state(x, c(\"shakespeare\", \"flights\"), metrics = \"metadata\")  cluster_stats(x) cluster_pending_tasks(x)  body <- '{   \"commands\": [      {       \"move\": {         \"index\" : \"test\", \"shard\" : 0,         \"from_node\" : \"node1\", \"to_node\" : \"node2\"       }     },     {       \"allocate_replica\" : {         \"index\" : \"test\", \"shard\" : 1, \"node\" : \"node3\"       }     }   ] }' # cluster_reroute(x, body =  body)  cluster_health(x) # cluster_health(x, wait_for_status = \"yellow\", timeout = \"3s\") }"},{"path":"https://docs.ropensci.org/elastic/reference/connect.html","id":null,"dir":"Reference","previous_headings":"","what":"Set connection details to an Elasticsearch engine. — connect","title":"Set connection details to an Elasticsearch engine. — connect","text":"Set connection details Elasticsearch engine.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/connect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set connection details to an Elasticsearch engine. — connect","text":"","code":"connect(   host = \"127.0.0.1\",   port = 9200,   path = NULL,   transport_schema = \"http\",   user = NULL,   pwd = NULL,   headers = NULL,   cainfo = NULL,   force = FALSE,   errors = \"simple\",   warn = TRUE,   ignore_version = FALSE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/connect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set connection details to an Elasticsearch engine. — connect","text":"host (character) base host, defaults 127.0.0.1 port (character) port connect , defaults 9200 (optional) path (character) context path appended end url. Default: NULL, ignored transport_schema (character) http https. Default: http user (character) User name, required connection. can specify,  ignored now. pwd (character) Password, required connection. can specify, ignored now. headers named list headers. headers used requests cainfo (character) path crt bundle, passed curl option cainfo force (logical) Force re-load connection details. Default: FALSE errors (character) One simple (Default) complete. Simple gives http code  error message error, complete gives http code error message,  stack trace, available. warn (logical) whether throw warnings Elasticsearch server provided. Pulls warnings response headers given. default: TRUE. turn , can set warn=FALSE wrap function calls suppressWarnings(). can also see warnings headers using curl verbose. ignore_version (logical) ignore Elasticsearch version checks? default: FALSE. Setting TRUE may cause problems, fully tested yet. may want set TRUE possible ping root route Elasticsearch instance, Elasticsearch version. use version alter request sent different Elasticsearch versions allow different parameters. ... additional curl options passed http requests","code":""},{"path":"https://docs.ropensci.org/elastic/reference/connect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set connection details to an Elasticsearch engine. — connect","text":"default configuration set localhost access port 9200, username password. Running connection method ping ES server, prints connection details. connection details stored within returned object. used store various env vars, now contained within object can number connection objects conflict one another.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/connect.html","id":"what-is-the-connection-object-","dir":"Reference","previous_headings":"","what":"What is the connection object?","title":"Set connection details to an Elasticsearch engine. — connect","text":"Creating connection object connect() create DBI-like connection object. DBI-like objects externalptr, etc., connect() simply holds details Elasticsearch instance (host, port, authentication, etc.) used methods package interact instances' ES API. connect() less fancy list. can connect different Elasticsearch intances within R session creating separate connection object instance; pass appropriate connection object elastic method.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/connect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set connection details to an Elasticsearch engine. — connect","text":"","code":"if (FALSE) { # the default is set to 127.0.0.1 (i.e., localhost) and port 9200 (x <- connect()) x$make_url() x$ping()  # pass connection object to function calls Search(x, q = \"*:*\")  # set username/password (hidden in print method) connect(user = \"me\", pwd = \"stuff\")  # set a different host # connect(host = '162.243.152.53') # => http://162.243.152.53:9200  # set a different port # connect(port = 8000) # => http://localhost:8000  # set a different context path # connect(path = 'foo_bar') # => http://localhost:9200/foo_bar  # set to https # connect(transport_schema = 'https') # => https://localhost:9200  # set headers connect(headers = list(a = 'foobar'))  # set cainfo path (hidden in print method) connect(cainfo = '/some/path/bundle.crt') }"},{"path":"https://docs.ropensci.org/elastic/reference/count.html","id":null,"dir":"Reference","previous_headings":"","what":"Get counts of the number of records per index. — count","title":"Get counts of the number of records per index. — count","text":"Get counts number records per index.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get counts of the number of records per index. — count","text":"","code":"count(conn, index = NULL, type = NULL, callopts = list(), verbose = TRUE, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get counts of the number of records per index. — count","text":"conn Elasticsearch connection object, see connect() index Index, defaults indices type Document type, optional callopts Curl args passed crul::verb-GET verbose TRUE (default) url call used printed console. ... args passed elastic search HTTP API parameters.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/count.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get counts of the number of records per index. — count","text":"See docs count API https://www.elastic.co/guide/en/elasticsearch/reference/current/search-count.html can also get count documents using Search() Search_uri() setting size = 0","code":""},{"path":"https://docs.ropensci.org/elastic/reference/count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get counts of the number of records per index. — count","text":"","code":"if (FALSE) { # connection setup (x <- connect())  if (!index_exists(x, \"plos\")) {   plosdat <- system.file(\"examples\", \"plos_data.json\",     package = \"elastic\")   plosdat <- type_remover(plosdat)   invisible(docs_bulk(x, plosdat)) } if (!index_exists(x, \"shakespeare\")) {   shake <- system.file(\"examples\", \"shakespeare_data_.json\",      package = \"elastic\")   invisible(docs_bulk(x, shake)) }  count(x) count(x, index='plos') count(x, index='shakespeare') count(x, index=c('plos','shakespeare'), q=\"a*\") count(x, index=c('plos','shakespeare'), q=\"z*\")  # Curl options count(x, callopts = list(verbose = TRUE)) }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":null,"dir":"Reference","previous_headings":"","what":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"Use bulk API create, index, update, delete documents.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"","code":"docs_bulk(   conn,   x,   index = NULL,   type = NULL,   chunk_size = 1000,   doc_ids = NULL,   es_ids = TRUE,   raw = FALSE,   quiet = FALSE,   query = list(),   digits = NA,   sf = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"conn Elasticsearch connection object, see connect() x list, data.frame, character path file. required. index (character) index name use. Required data.frame input, optional file inputs. type (character) type. default: NULL. Note type deprecated Elasticsearch v7 greater, removed Elasticsearch v8 chunk_size (integer) Size chunk. data.frame smaller thank chunk_size, parameter essentially ignored. write chunks point, depending size document, Elasticsearch setup, writing large number documents one go becomes slow, chunking can help. parameter ignored pass file name. Default: 1000 doc_ids optional vector (character numeric/integer) document ids use. vector equal size documents passing , error . pass factor convert character. Default: passed es_ids (boolean) Let Elasticsearch assign document IDs UUIDs. sequential, order IDs assign. TRUE, doc_ids ignored. Default: TRUE raw (logical) Get raw JSON back . TRUE get JSON; FALSE get list. Default: FALSE quiet (logical) Suppress progress bar. Default: FALSE query (list) named list query parameters. optional. options include: pipeline, refresh, routing, _source, _source_excludes, _source_includes, timeout, wait_for_active_shards. See docs bulk ES page details digits digits used parameter name jsonlite::toJSON() convert data JSON submitted ES instance. default: NA sf used jsonlite::toJSON() convert sf objects. Set \"features\" conversion GeoJSON. default: \"dataframe\" ... Pass curl options crul::HttpClient","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"list","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"Bulk API: https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html function dispatches data.frame character input. Character input file name function stops error message. pass data.frame function, default index operation, , create record index given parameters function. road perhaps try support operations bulk API. pass file, course file, can specify operations want. Row names dropped data.frame, top level names list dropped well. progress bar gives progress data.frames lists - progress bar based around loop, progress indicates progress along iterations loop, iteration chunk data converted bulk format, pushed Elasticsearch. character method loop, progress bar.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"document-ids","dir":"Reference","previous_headings":"","what":"Document IDs","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"Document IDs can passed via doc_ids paramater passing data.frame list, files. ids passed doc_ids, assign document IDs 1 length object (rows data.frame, length list). future may allow user select whether want assign sequential numeric IDs allow Elasticsearch assign IDs, UUIDs actually sequential, still can determine order documents.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"document-ids-and-factors","dir":"Reference","previous_headings":"","what":"Document IDs and Factors","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"pass ids class factor, coerce character .character. applies data.frame list inputs, file inputs.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"large-numbers-for-document-ids","dir":"Reference","previous_headings":"","what":"Large numbers for document IDs","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"recently, large integers document IDs, docs_bulk failed. fixed now. Let us know .","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"missing-data","dir":"Reference","previous_headings":"","what":"Missing data","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"elastic version 0.7.8.9515 convert NA null loading Elasticsearch. Previously, fields NA dropped - read data back Elasticsearch R, retain missing values jsonlite fills . Now, fields NA's made null, dropped Elasticsearch. Note also null values can indexed searched https://www.elastic.co/guide/en/elasticsearch/reference/5.3/null-value.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"tips","dir":"Reference","previous_headings":"","what":"Tips","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"function returns response Elasticsearch, likely interested response. , wrap call docs_bulk invisible(), like : invisible(docs_bulk(...))","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"connections-files","dir":"Reference","previous_headings":"","what":"Connections/Files","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"create temporary files, connections files, data.frame's lists passed docs_bulk() (file passed since need create file). inserting data Elasticsearch instance, close connections delete temporary files. exceptions though. pass file, whether tempfile , delete files using - case need files . tempfile's cleaned /delete R session ends. Non-tempfile's cleaned /deleted R session ends.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"elasticsearch-versions-that-don-t-support-type","dir":"Reference","previous_headings":"","what":"Elasticsearch versions that don't support type","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"See type_remover() function.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use the bulk API to create, index, update, or delete documents. — docs_bulk","text":"","code":"if (FALSE) { # connection setup (x <- connect())  # From a file already in newline delimited JSON format plosdat <- system.file(\"examples\", \"plos_data.json\", package = \"elastic\") docs_bulk(x, plosdat) aliases_get(x) index_delete(x, index='plos') aliases_get(x)  # From a data.frame docs_bulk(x, mtcars, index = \"hello\") ## field names cannot contain dots names(iris) <- gsub(\"\\\\.\", \"_\", names(iris)) docs_bulk(x, iris, \"iris\") ## type can be missing, but index can not docs_bulk(x, iris, \"flowers\") ## big data.frame, 53K rows, load ggplot2 package first # res <- docs_bulk(x, diamonds, \"diam\") # Search(x, \"diam\")$hits$total  # From a list docs_bulk(x, apply(iris, 1, as.list), index=\"iris\") docs_bulk(x, apply(USArrests, 1, as.list), index=\"arrests\") # dim_list <- apply(diamonds, 1, as.list) # out <- docs_bulk(x, dim_list, index=\"diamfromlist\")  # When using in a loop ## We internally get last _id counter to know where to start on next bulk ## insert but you need to sleep in between docs_bulk calls, longer the ## bigger the data is files <- c(system.file(\"examples\", \"test1.csv\", package = \"elastic\"),            system.file(\"examples\", \"test2.csv\", package = \"elastic\"),            system.file(\"examples\", \"test3.csv\", package = \"elastic\")) for (i in seq_along(files)) {   d <- read.csv(files[[i]])   docs_bulk(x, d, index = \"testes\")   Sys.sleep(1) } count(x, \"testes\") index_delete(x, \"testes\")  # You can include your own document id numbers ## Either pass in as an argument index_create(x, \"testes\") files <- c(system.file(\"examples\", \"test1.csv\", package = \"elastic\"),            system.file(\"examples\", \"test2.csv\", package = \"elastic\"),            system.file(\"examples\", \"test3.csv\", package = \"elastic\")) tt <- vapply(files, function(z) NROW(read.csv(z)), numeric(1)) ids <- list(1:tt[1],            (tt[1] + 1):(tt[1] + tt[2]),            (tt[1] + tt[2] + 1):sum(tt)) for (i in seq_along(files)) {   d <- read.csv(files[[i]])   docs_bulk(x, d, index = \"testes\", doc_ids = ids[[i]],     es_ids = FALSE) } count(x, \"testes\") index_delete(x, \"testes\")  ## or include in the input data ### from data.frame's index_create(x, \"testes\") files <- c(system.file(\"examples\", \"test1_id.csv\", package = \"elastic\"),            system.file(\"examples\", \"test2_id.csv\", package = \"elastic\"),            system.file(\"examples\", \"test3_id.csv\", package = \"elastic\")) readLines(files[[1]]) for (i in seq_along(files)) {   d <- read.csv(files[[i]])   docs_bulk(x, d, index = \"testes\") } count(x, \"testes\") index_delete(x, \"testes\")  ### from lists via file inputs index_create(x, \"testes\") for (i in seq_along(files)) {   d <- read.csv(files[[i]])   d <- apply(d, 1, as.list)   docs_bulk(x, d, index = \"testes\") } count(x, \"testes\") index_delete(x, \"testes\")  # data.frame's with a single column ## this didn't use to work, but now should work db <- paste0(sample(letters, 10), collapse = \"\") index_create(x, db) res <- data.frame(foo = 1:10) out <- docs_bulk(x, res, index = db) count(x, db) index_delete(x, db)   # data.frame with a mix of actions ## make sure you use a column named 'es_action' or this won't work ## if you need to delete or update you need document IDs if (index_exists(x, \"baz\")) index_delete(x, \"baz\") df <- data.frame(a = 1:5, b = 6:10, c = letters[1:5], stringsAsFactors = FALSE) invisible(docs_bulk(x, df, \"baz\")) Sys.sleep(3) (res <- Search(x, 'baz', asdf=TRUE)$hits$hits) df[1, \"a\"] <- 99 df[1, \"c\"] <- \"aa\" df[3, \"c\"] <- 33 df[3, \"c\"] <- \"cc\" df$es_action <- c('update', 'delete', 'update', 'delete', 'delete') df$id <- res$`_id` df invisible(docs_bulk(x, df, \"baz\", es_ids = FALSE)) ### or es_ids = FALSE and pass in document ids to doc_ids # invisible(docs_bulk(df, \"baz\", es_ids = FALSE, doc_ids = df$id)) Search(x, 'baz', asdf=TRUE)$hits$hits   # Curl options plosdat <- system.file(\"examples\", \"plos_data.json\",   package = \"elastic\") plosdat <- type_remover(plosdat) invisible(docs_bulk(x, plosdat, verbose = TRUE))   # suppress progress bar invisible(docs_bulk(x, mtcars, index = \"hello\", quiet = TRUE)) ## vs. invisible(docs_bulk(x, mtcars, index = \"hello\", quiet = FALSE)) }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_create.html","id":null,"dir":"Reference","previous_headings":"","what":"Use the bulk API to create documents — docs_bulk_create","title":"Use the bulk API to create documents — docs_bulk_create","text":"Use bulk API create documents","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_create.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use the bulk API to create documents — docs_bulk_create","text":"","code":"docs_bulk_create(   conn,   x,   index = NULL,   type = NULL,   chunk_size = 1000,   doc_ids = NULL,   es_ids = TRUE,   raw = FALSE,   quiet = FALSE,   query = list(),   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_create.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use the bulk API to create documents — docs_bulk_create","text":"conn Elasticsearch connection object, see connect() x list, data.frame, character path file. required. index (character) index name use. Required data.frame input, optional file inputs. type (character) type. default: NULL. Note type deprecated Elasticsearch v7 greater, removed Elasticsearch v8 chunk_size (integer) Size chunk. data.frame smaller thank chunk_size, parameter essentially ignored. write chunks point, depending size document, Elasticsearch setup, writing large number documents one go becomes slow, chunking can help. parameter ignored pass file name. Default: 1000 doc_ids optional vector (character numeric/integer) document ids use. vector equal size documents passing , error . pass factor convert character. Default: passed es_ids (boolean) Let Elasticsearch assign document IDs UUIDs. sequential, order IDs assign. TRUE, doc_ids ignored. Default: TRUE raw (logical) Get raw JSON back . TRUE get JSON; FALSE get list. Default: FALSE quiet (logical) Suppress progress bar. Default: FALSE query (list) named list query parameters. optional. options include: pipeline, refresh, routing, _source, _source_excludes, _source_includes, timeout, wait_for_active_shards. See docs bulk ES page details ... Pass curl options crul::HttpClient","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_create.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use the bulk API to create documents — docs_bulk_create","text":"create file already prepared bulk API, see docs_bulk() data.frame's supported now.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_create.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Use the bulk API to create documents — docs_bulk_create","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_create.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use the bulk API to create documents — docs_bulk_create","text":"","code":"if (FALSE) { x <- connect() if (index_exists(x, \"foobar\")) index_delete(x, \"foobar\")  df <- data.frame(name = letters[1:3], size = 1:3, id = 100:102) docs_bulk_create(x, df, 'foobar', es_ids = FALSE) Search(x, \"foobar\", asdf = TRUE)$hits$hits  # more examples docs_bulk_create(x, mtcars, index = \"hello\") ## field names cannot contain dots names(iris) <- gsub(\"\\\\.\", \"_\", names(iris)) docs_bulk_create(x, iris, \"iris\") ## type can be missing, but index can not docs_bulk_create(x, iris, \"flowers\") ## big data.frame, 53K rows, load ggplot2 package first # res <- docs_bulk_create(x, diamonds, \"diam\") # Search(x, \"diam\")$hits$total$value }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_delete.html","id":null,"dir":"Reference","previous_headings":"","what":"Use the bulk API to delete documents — docs_bulk_delete","title":"Use the bulk API to delete documents — docs_bulk_delete","text":"Use bulk API delete documents","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_delete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use the bulk API to delete documents — docs_bulk_delete","text":"","code":"docs_bulk_delete(   conn,   x,   index = NULL,   type = NULL,   chunk_size = 1000,   doc_ids = NULL,   raw = FALSE,   quiet = FALSE,   query = list(),   digits = NA,   sf = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_delete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use the bulk API to delete documents — docs_bulk_delete","text":"conn Elasticsearch connection object, see connect() x list, data.frame, character path file. required. index (character) index name use. Required data.frame input, optional file inputs. type (character) type. default: NULL. Note type deprecated Elasticsearch v7 greater, removed Elasticsearch v8 chunk_size (integer) Size chunk. data.frame smaller thank chunk_size, parameter essentially ignored. write chunks point, depending size document, Elasticsearch setup, writing large number documents one go becomes slow, chunking can help. parameter ignored pass file name. Default: 1000 doc_ids optional vector (character numeric/integer) document ids use. vector equal size documents passing , error . pass factor convert character. Default: passed raw (logical) Get raw JSON back . TRUE get JSON; FALSE get list. Default: FALSE quiet (logical) Suppress progress bar. Default: FALSE query (list) named list query parameters. optional. options include: pipeline, refresh, routing, _source, _source_excludes, _source_includes, timeout, wait_for_active_shards. See docs bulk ES page details digits, sf ignored, used docs bulk functions used ... Pass curl options crul::HttpClient","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_delete.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use the bulk API to delete documents — docs_bulk_delete","text":"deletes file already prepared bulk API, see docs_bulk() data.frame's supported now.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_delete.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Use the bulk API to delete documents — docs_bulk_delete","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_delete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use the bulk API to delete documents — docs_bulk_delete","text":"","code":"if (FALSE) { x <- connect() if (index_exists(x, \"foobar\")) index_delete(x, \"foobar\")  df <- data.frame(name = letters[1:3], size = 1:3, id = 100:102) invisible(docs_bulk(x, df, 'foobar', es_ids = FALSE)) Search(x, \"foobar\", asdf = TRUE)$hits$hits  # delete using doc ids from the data.frame you used to create invisible(docs_bulk_delete(x, df, index = 'foobar')) Search(x, \"foobar\", asdf = TRUE)$hits$total$value  # delete by passing in doc ids ## recreate data first if (index_exists(x, \"foobar\")) index_delete(x, \"foobar\") df <- data.frame(name = letters[1:3], size = 1:3, id = 100:102) invisible(docs_bulk(x, df, 'foobar', es_ids = FALSE)) docs_bulk_delete(x, df, index = 'foobar', doc_ids = df$id) Search(x, \"foobar\", asdf = TRUE)$hits$total$value }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Use the bulk API to index documents — docs_bulk_index","title":"Use the bulk API to index documents — docs_bulk_index","text":"Use bulk API index documents","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use the bulk API to index documents — docs_bulk_index","text":"","code":"docs_bulk_index(   conn,   x,   index = NULL,   type = NULL,   chunk_size = 1000,   doc_ids = NULL,   es_ids = TRUE,   raw = FALSE,   quiet = FALSE,   query = list(),   digits = NA,   sf = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use the bulk API to index documents — docs_bulk_index","text":"conn Elasticsearch connection object, see connect() x list, data.frame, character path file. required. index (character) index name use. Required data.frame input, optional file inputs. type (character) type. default: NULL. Note type deprecated Elasticsearch v7 greater, removed Elasticsearch v8 chunk_size (integer) Size chunk. data.frame smaller thank chunk_size, parameter essentially ignored. write chunks point, depending size document, Elasticsearch setup, writing large number documents one go becomes slow, chunking can help. parameter ignored pass file name. Default: 1000 doc_ids optional vector (character numeric/integer) document ids use. vector equal size documents passing , error . pass factor convert character. Default: passed es_ids (boolean) Let Elasticsearch assign document IDs UUIDs. sequential, order IDs assign. TRUE, doc_ids ignored. Default: TRUE raw (logical) Get raw JSON back . TRUE get JSON; FALSE get list. Default: FALSE quiet (logical) Suppress progress bar. Default: FALSE query (list) named list query parameters. optional. options include: pipeline, refresh, routing, _source, _source_excludes, _source_includes, timeout, wait_for_active_shards. See docs bulk ES page details digits digits used parameter name jsonlite::toJSON() convert data JSON submitted ES instance. default: NA sf used jsonlite::toJSON() convert sf objects. Set \"features\" conversion GeoJSON. default: \"dataframe\" ... Pass curl options crul::HttpClient","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use the bulk API to index documents — docs_bulk_index","text":"index file already prepared bulk API, see docs_bulk() data.frame's supported now.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_index.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Use the bulk API to index documents — docs_bulk_index","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use the bulk API to index documents — docs_bulk_index","text":"","code":"if (FALSE) { x <- connect() if (index_exists(x, \"foobar\")) index_delete(x, \"foobar\")  df <- data.frame(name = letters[1:3], size = 1:3, id = 100:102) docs_bulk_index(x, df, 'foobar') docs_bulk_index(x, df, 'foobar', es_ids = FALSE) Search(x, \"foobar\", asdf = TRUE)$hits$hits  # more examples docs_bulk_index(x, mtcars, index = \"hello\") ## field names cannot contain dots names(iris) <- gsub(\"\\\\.\", \"_\", names(iris)) docs_bulk_index(x, iris, \"iris\") ## type can be missing, but index can not docs_bulk_index(x, iris, \"flowers\") ## big data.frame, 53K rows, load ggplot2 package first # res <- docs_bulk_index(x, diamonds, \"diam\") # Search(x, \"diam\")$hits$total$value }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_prep.html","id":null,"dir":"Reference","previous_headings":"","what":"Use the bulk API to prepare bulk format data — docs_bulk_prep","title":"Use the bulk API to prepare bulk format data — docs_bulk_prep","text":"Use bulk API prepare bulk format data","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_prep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use the bulk API to prepare bulk format data — docs_bulk_prep","text":"","code":"docs_bulk_prep(   x,   index,   path,   type = NULL,   chunk_size = 1000,   doc_ids = NULL,   quiet = FALSE,   digits = NA,   sf = NULL )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_prep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use the bulk API to prepare bulk format data — docs_bulk_prep","text":"x data.frame list. required. index (character) index name. required. path (character) Path file. data broken chunks, use path prefix, suffix file path number. required. type (character) type. default: NULL. Note type deprecated Elasticsearch v7 greater, removed Elasticsearch v8 chunk_size (integer) Size chunk. data.frame smaller thank chunk_size, parameter essentially ignored. write chunks point, depending size document, Elasticsearch setup, writing large number documents one go becomes slow, chunking can help. parameter ignored pass file name. Default: 1000 doc_ids optional vector (character numeric/integer) document ids use. vector equal size documents passing , error . pass factor convert character. Default: passed quiet (logical) Suppress progress bar. Default: FALSE digits digits used parameter name jsonlite::toJSON() convert data JSON submitted ES instance. default: NA sf used jsonlite::toJSON() convert sf objects. Set \"features\" conversion GeoJSON. default: \"dataframe\"","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_prep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use the bulk API to prepare bulk format data — docs_bulk_prep","text":"File path(s). default use temporary files; cleaned end session","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_prep.html","id":"tempfiles","dir":"Reference","previous_headings":"","what":"Tempfiles","title":"Use the bulk API to prepare bulk format data — docs_bulk_prep","text":"docs_bulk create temporary files cases, delete function exits. However, clean files function point function create newline delimited JSON files need. Tempfiles cleaned R session ends though - aware . want keep files make sure move outside temp directory.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_prep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use the bulk API to prepare bulk format data — docs_bulk_prep","text":"","code":"if (FALSE) { # From a data.frame ff <- tempfile(fileext = \".json\") docs_bulk_prep(mtcars, index = \"hello\", path = ff) readLines(ff)  ## field names cannot contain dots names(iris) <- gsub(\"\\\\.\", \"_\", names(iris)) docs_bulk_prep(iris, \"iris\", path = tempfile(fileext = \".json\"))  ## type can be missing, but index can not docs_bulk_prep(iris, \"flowers\", path = tempfile(fileext = \".json\"))  # From a list docs_bulk_prep(apply(iris, 1, as.list), index=\"iris\",    path = tempfile(fileext = \".json\")) docs_bulk_prep(apply(USArrests, 1, as.list), index=\"arrests\",    path = tempfile(fileext = \".json\"))  # when chunking ## multiple files created, one for each chunk bigiris <- do.call(\"rbind\", replicate(30, iris, FALSE)) docs_bulk_prep(bigiris, index = \"big\", path = tempfile(fileext = \".json\"))  # When using in a loop ## We internally get last _id counter to know where to start on next bulk ## insert but you need to sleep in between docs_bulk_prep calls, longer the ## bigger the data is files <- c(system.file(\"examples\", \"test1.csv\", package = \"elastic\"),            system.file(\"examples\", \"test2.csv\", package = \"elastic\"),            system.file(\"examples\", \"test3.csv\", package = \"elastic\")) paths <- vector(\"list\", length = length(files)) for (i in seq_along(files)) {   d <- read.csv(files[[i]])   paths[i] <- docs_bulk_prep(d, index = \"stuff\",      path = tempfile(fileext = \".json\")) } unlist(paths)  # You can include your own document id numbers ## Either pass in as an argument files <- c(system.file(\"examples\", \"test1.csv\", package = \"elastic\"),            system.file(\"examples\", \"test2.csv\", package = \"elastic\"),            system.file(\"examples\", \"test3.csv\", package = \"elastic\")) tt <- vapply(files, function(z) NROW(read.csv(z)), numeric(1)) ids <- list(1:tt[1],            (tt[1] + 1):(tt[1] + tt[2]),            (tt[1] + tt[2] + 1):sum(tt)) paths <- vector(\"list\", length = length(files)) for (i in seq_along(files)) {   d <- read.csv(files[[i]])   paths[i] <- docs_bulk_prep(d, index = \"testes\",     doc_ids = ids[[i]], path = tempfile(fileext = \".json\")) } unlist(paths)  ## or include in the input data ### from data.frame's files <- c(system.file(\"examples\", \"test1_id.csv\", package = \"elastic\"),            system.file(\"examples\", \"test2_id.csv\", package = \"elastic\"),            system.file(\"examples\", \"test3_id.csv\", package = \"elastic\")) paths <- vector(\"list\", length = length(files)) for (i in seq_along(files)) {   d <- read.csv(files[[i]])   paths[i] <- docs_bulk_prep(d, index = \"testes\",      path = tempfile(fileext = \".json\")) } unlist(paths)  ### from lists via file inputs paths <- vector(\"list\", length = length(files)) for (i in seq_along(files)) {   d <- read.csv(files[[i]])   d <- apply(d, 1, as.list)   paths[i] <- docs_bulk_prep(d, index = \"testes\",       path = tempfile(fileext = \".json\")) } unlist(paths)   # A mix of actions ## make sure you use a column named 'es_action' or this won't work ## if you need to delete or update you need document IDs if (index_exists(x, \"baz\")) index_delete(x, \"baz\") df <- data.frame(a = 1:5, b = 6:10, c = letters[1:5], stringsAsFactors = FALSE) f <- tempfile(fileext = \".json\") invisible(docs_bulk_prep(df, \"baz\", f)) cat(readLines(f), sep = \"\\n\") docs_bulk(x, f) Sys.sleep(2) (res <- Search(x, 'baz', asdf=TRUE)$hits$hits)  df[1, \"a\"] <- 99 df[1, \"c\"] <- \"aa\" df[3, \"c\"] <- 33 df[3, \"c\"] <- \"cc\" df$es_action <- c('update', 'delete', 'update', 'delete', 'delete') df$id <- res$`_id` df f <- tempfile(fileext = \".json\") invisible(docs_bulk_prep(df, \"baz\", path = f, doc_ids = df$id)) cat(readLines(f), sep = \"\\n\") docs_bulk(x, f)   # suppress progress bar docs_bulk_prep(mtcars, index = \"hello\",   path = tempfile(fileext = \".json\"), quiet = TRUE) ## vs. docs_bulk_prep(mtcars, index = \"hello\",   path = tempfile(fileext = \".json\"), quiet = FALSE) }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Use the bulk API to update documents — docs_bulk_update","title":"Use the bulk API to update documents — docs_bulk_update","text":"Use bulk API update documents","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use the bulk API to update documents — docs_bulk_update","text":"","code":"docs_bulk_update(   conn,   x,   index = NULL,   type = NULL,   chunk_size = 1000,   doc_ids = NULL,   raw = FALSE,   quiet = FALSE,   query = list(),   digits = NA,   sf = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use the bulk API to update documents — docs_bulk_update","text":"conn Elasticsearch connection object, see connect() x list, data.frame, character path file. required. index (character) index name use. Required data.frame input, optional file inputs. type (character) type. default: NULL. Note type deprecated Elasticsearch v7 greater, removed Elasticsearch v8 chunk_size (integer) Size chunk. data.frame smaller thank chunk_size, parameter essentially ignored. write chunks point, depending size document, Elasticsearch setup, writing large number documents one go becomes slow, chunking can help. parameter ignored pass file name. Default: 1000 doc_ids optional vector (character numeric/integer) document ids use. vector equal size documents passing , error . pass factor convert character. Default: passed raw (logical) Get raw JSON back . TRUE get JSON; FALSE get list. Default: FALSE quiet (logical) Suppress progress bar. Default: FALSE query (list) named list query parameters. optional. options include: pipeline, refresh, routing, _source, _source_excludes, _source_includes, timeout, wait_for_active_shards. See docs bulk ES page details digits digits used parameter name jsonlite::toJSON() convert data JSON submitted ES instance. default: NA sf used jsonlite::toJSON() convert sf objects. Set \"features\" conversion GeoJSON. default: \"dataframe\" ... Pass curl options crul::HttpClient","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_update.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Use the bulk API to update documents — docs_bulk_update","text":"doc_as_upsert - set TRUE records updates file already prepared bulk API, see docs_bulk() data.frame's supported now.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_update.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Use the bulk API to update documents — docs_bulk_update","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html#bulk-update","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/docs_bulk_update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use the bulk API to update documents — docs_bulk_update","text":"","code":"if (FALSE) { x <- connect() if (index_exists(x, \"foobar\")) index_delete(x, \"foobar\")  df <- data.frame(name = letters[1:3], size = 1:3, id = 100:102) invisible(docs_bulk(x, df, 'foobar', es_ids = FALSE))  # add new rows in existing fields (df2 <- data.frame(size = c(45, 56), id = 100:101)) (df2 <- data.frame(size = c(45, 56))) df2$`_id` <- 100:101 df2 Search(x, \"foobar\", asdf = TRUE)$hits$hits invisible(docs_bulk_update(x, df2, index = 'foobar')) Search(x, \"foobar\", asdf = TRUE)$hits$hits  # add new fields (and new rows by extension) (df3 <- data.frame(color = c(\"blue\", \"red\", \"green\"), id = 100:102)) Search(x, \"foobar\", asdf = TRUE)$hits$hits invisible(docs_bulk_update(x, df3, index = 'foobar')) Sys.sleep(2) # wait for a few sec to make sure you see changes reflected Search(x, \"foobar\", asdf = TRUE)$hits$hits }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_create.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a document — docs_create","title":"Create a document — docs_create","text":"Create document","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_create.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a document — docs_create","text":"","code":"docs_create(   conn,   index,   body,   type = NULL,   id = NULL,   version = NULL,   version_type = NULL,   op_type = NULL,   routing = NULL,   parent = NULL,   timestamp = NULL,   ttl = NULL,   refresh = NULL,   timeout = NULL,   callopts = list(),   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_create.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a document — docs_create","text":"conn Elasticsearch connection object, see connect() index (character) name index. Required body document type (character) type document. optional id (numeric/character) document ID. Can numeric character. Optional. provided, Elasticsearch creates ID UUID. version (character) Explicit version number concurrency control version_type (character) Specific version type. One internal, external, external_gte, force op_type (character) Operation type. One create, ... routing (character) Specific routing value parent (numeric) parent document ID timestamp (date) Explicit timestamp document ttl (aka “time live”) Expiration time document. Expired documents expunged automatically. expiration date set document provided ttl relative timestamp document,  meaning can based time indexing time provided. provided ttl must strictly positive can number (milliseconds) valid time value (e.g, 86400000, 1d). refresh (logical) Refresh index performing operation timeout (character) Explicit operation timeout, e.g,. 5m (5 minutes) callopts Curl options passed crul::HttpClient ... args query DSL","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_create.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a document — docs_create","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_create.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a document — docs_create","text":"","code":"if (FALSE) { (x <- connect())  if (!index_exists(x, 'plos')) {   plosdat <- system.file(\"examples\", \"plos_data.json\",     package = \"elastic\")   plosdat <- type_remover(plosdat)   invisible(docs_bulk(x, plosdat)) }  # give a document id z <- docs_create(x, index = 'plos', id = 1002,   body = list(id = \"12345\", title = \"New title\")) z # and the document is there now docs_get(x, index = 'plos', id = 1002)  # let Elasticsearch create the document id for you z <- docs_create(x, index='plos', body=list(id=\"6789\", title=\"Some title\")) z # and the document is there now docs_get(x, index='plos', id=z$`_id`) }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete a document — docs_delete","title":"Delete a document — docs_delete","text":"Delete document","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete a document — docs_delete","text":"","code":"docs_delete(   conn,   index,   id,   type = NULL,   refresh = NULL,   routing = NULL,   timeout = NULL,   version = NULL,   version_type = NULL,   callopts = list(),   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete a document — docs_delete","text":"conn Elasticsearch connection object, see connect() index (character) name index. Required id (numeric/character) document ID. Can numeric character. Required type (character) type document. optional refresh (logical) Refresh index performing operation routing (character) Specific routing value timeout (character) Explicit operation timeout, e.g,. 5m (5 minutes) version (character) Explicit version number concurrency control version_type (character) Specific version type. One internal external callopts Curl args passed crul::HttpClient ... args query DSL","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Delete a document — docs_delete","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete a document — docs_delete","text":"","code":"if (FALSE) { (x <- connect()) x$ping()  if (!index_exists(x, \"plos\")) {  plosdat <- system.file(\"examples\", \"plos_data.json\",     package = \"elastic\")  plosdat <- type_remover(plosdat)  docs_bulk(x, plosdat) }  # delete a document if (!docs_get(x, index='plos', id=36, exists=TRUE)) {   docs_create(x, index='plos', id=36,      body = list(id=\"12345\", title=\"New title\")   ) } docs_get(x, index='plos', id=36) docs_delete(x, index='plos', id=36) # docs_get(x, index='plos', id=36) # and the document is gone }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete_by_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Delete documents by query — docs_delete_by_query","title":"Delete documents by query — docs_delete_by_query","text":"delete documents query via POST request","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete_by_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Delete documents by query — docs_delete_by_query","text":"","code":"docs_delete_by_query(   conn,   index,   body,   type = NULL,   conflicts = NULL,   routing = NULL,   scroll_size = NULL,   refresh = NULL,   wait_for_completion = NULL,   wait_for_active_shards = NULL,   timeout = NULL,   scroll = NULL,   requests_per_second = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete_by_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Delete documents by query — docs_delete_by_query","text":"conn Elasticsearch connection object, see connect() index (character) name index. Required body (character/json) query passed POST request body type (character) type document. optional conflicts (character) ’d like count version conflicts rather cause abort set conflicts=proceed routing (character) Specific routing value scroll_size (integer) default uses scroll batches 1000. Change batch size parameter. refresh (logical) Refresh index performing operation wait_for_completion (logical) wait_for_completion=FALSE Elasticsearch perform preflight checks, launch request, return task can used Tasks APIs cancel get status task. Elasticsearch also create record task document .tasks/task/$taskId. keep remove see fit. done , delete Elasticsearch can reclaim space uses. Default: TRUE wait_for_active_shards (logical) controls many copies shard must active proceeding request. timeout (character) Explicit operation timeout, e.g,. 5m (5 minutes) scroll (integer) control long \"search context\" kept alive, eg scroll='10m', default ’s 5 minutes (5m) requests_per_second (integer) positive decimal number (1.4, 6, 1000, etc); throttles rate _delete_by_query issues batches delete operations padding batch wait time. throttling can disabled setting requests_per_second=-1 ... Curl args passed crul::verb-POST","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete_by_query.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Delete documents by query — docs_delete_by_query","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-delete--query.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/docs_delete_by_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Delete documents by query — docs_delete_by_query","text":"","code":"if (FALSE) { (x <- connect()) x$ping()  plosdat <- system.file(\"examples\", \"plos_data.json\",   package = \"elastic\") plosdat <- type_remover(plosdat) if (!index_exists(x, \"plos\")) invisible(docs_bulk(x, plosdat))  # delete with fuzzy matching body <- '{   \"query\": {      \"match\": {       \"title\": {         \"query\": \"cells\",         \"fuzziness\": 1       }     }   } }' docs_delete_by_query(x, index='plos', body = body)   # delete with no fuzziness if (index_exists(x, \"plos\")) index_delete(x, 'plos') invisible(docs_bulk(x, plosdat)) count(x, \"plos\") body <- '{   \"query\": {      \"match\": {       \"title\": {         \"query\": \"cells\",         \"fuzziness\": 0       }     }   } }' docs_delete_by_query(x, index='plos', body = body)  # delete all docs with match_all query if (index_exists(x, \"plos\")) index_delete(x, 'plos') invisible(docs_bulk(x, plosdat)) body <- '{   \"query\": {      \"match_all\": {}   } }' docs_delete_by_query(x, index='plos', body = body)  # put plos back in  if (index_exists(x, \"plos\")) index_delete(x, 'plos') invisible(docs_bulk(x, plosdat))  # delete docs from more than one index foo <- system.file(\"examples/foo.json\", package = \"elastic\") if (!index_exists(x, \"foo\")) invisible(docs_bulk(x, foo)) bar <- system.file(\"examples/bar.json\", package = \"elastic\") if (!index_exists(x, \"bar\")) invisible(docs_bulk(x, bar))  body <- '{   \"query\": {      \"match_all\": {}   } }' docs_delete_by_query(x, index=c('foo','bar'),    body = body, verbose = TRUE) }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_get.html","id":null,"dir":"Reference","previous_headings":"","what":"Get documents — docs_get","title":"Get documents — docs_get","text":"Get documents","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_get.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get documents — docs_get","text":"","code":"docs_get(   conn,   index,   id,   type = NULL,   source = NULL,   fields = NULL,   source_includes = NULL,   source_excludes = NULL,   exists = FALSE,   raw = FALSE,   callopts = list(),   verbose = TRUE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_get.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get documents — docs_get","text":"conn Elasticsearch connection object, see connect() index (character) name index. Required id (numeric/character) document ID. Can numeric character. Required type (character) type document. optional source (logical) TRUE (default), return source. note actually set NULL function definition, within Elasticsearch, returns source default. alternatively, can pass vector field names return. fields Fields return response object. source_includes, source_excludes (character) fields include returned document, exclude. character vector exists (logical) return logical whether document exists . raw TRUE (default), data parsed list. FALSE, raw JSON. callopts Curl args passed crul::HttpClient verbose TRUE (default) url call used printed console. ... args passed elastic search HTTP API parameters.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_get.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get documents — docs_get","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-get.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_get.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get documents — docs_get","text":"","code":"if (FALSE) { (x <- connect())  if (!index_exists(x, \"shakespeare\")) {   shakespeare <- system.file(\"examples\", \"shakespeare_data_.json\",     package = \"elastic\")   shakespeare <- type_remover(shakespeare)   invisible(docs_bulk(x, shakespeare)) }  docs_get(x, index='shakespeare', id=10) docs_get(x, index='shakespeare', id=12) docs_get(x, index='shakespeare', id=12, source=TRUE)  # Get certain fields if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {   ### ES < v5   docs_get(x, index='shakespeare', id=10, fields='play_name')   docs_get(x, index='shakespeare', id=10, fields=c('play_name','speaker')) } else {   ### ES > v5   docs_get(x, index='shakespeare', id=10, source='play_name')   docs_get(x, index='shakespeare', id=10, source=c('play_name','speaker')) }  # Just test for existence of the document docs_get(x, index='plos', id=1, exists=TRUE) docs_get(x, index='plos', id=123456, exists=TRUE)  # source includes / excludes docs_get(x, index='shakespeare', id=10, source_includes = \"play_name\") docs_get(x, index='shakespeare', id=10, source_excludes = \"play_name\") }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_mget.html","id":null,"dir":"Reference","previous_headings":"","what":"Get multiple documents via the multiple get API — docs_mget","title":"Get multiple documents via the multiple get API — docs_mget","text":"Get multiple documents via multiple get API","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_mget.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get multiple documents via the multiple get API — docs_mget","text":"","code":"docs_mget(   conn,   index = NULL,   type = NULL,   ids = NULL,   type_id = NULL,   index_type_id = NULL,   source = NULL,   fields = NULL,   raw = FALSE,   callopts = list(),   verbose = TRUE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_mget.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get multiple documents via the multiple get API — docs_mget","text":"conn Elasticsearch connection object, see connect() index Index. Required. type Document type. Required. ids one document id, see examples. type_id List vectors length 2, element type id. index_type_id List vectors length 3, element index, type, id. source (logical) TRUE, return source. fields Fields return response object. raw TRUE (default), data parsed list. FALSE, raw JSON. callopts Curl args passed HttpClient verbose TRUE (default) url call used printed console. ... args passed elastic search HTTP API parameters.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_mget.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get multiple documents via the multiple get API — docs_mget","text":"can pass one three combinations parameters: Pass something index, type, id. simplest, allowing retrieval index, type, many ids. Pass index type_id - allows get multiple documents index, different types. Pass index_type_id - can get multiple documents different indexes different types.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_mget.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get multiple documents via the multiple get API — docs_mget","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-multi-get.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_mget.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get multiple documents via the multiple get API — docs_mget","text":"","code":"if (FALSE) { (x <- connect())  if (!index_exists(x, 'plos')) {   plosdat <- system.file(\"examples\", \"plos_data.json\",     package = \"elastic\")   plosdat <- type_remover(plosdat)   invisible(docs_bulk(x, plosdat)) }  # same index, many ids docs_mget(x, index=\"plos\", ids=c(9,10))  # Same index and type docs_mget(x, index=\"plos\", type=\"_doc\", ids=c(9,10))  tmp <- docs_mget(x, index=\"plos\", ids=c(9, 10), raw=TRUE) es_parse(tmp) docs_mget(x, index=\"plos\", ids=c(9, 10), source='title') docs_mget(x, index=\"plos\", ids=c(14, 19), source=TRUE)  # curl options docs_mget(x, index=\"plos\", ids=1:2, callopts=list(verbose=TRUE))  # Same index, but different types if (index_exists(x, 'shakespeare')) index_delete(x, 'shakespeare') shakedat <- system.file(\"examples\", \"shakespeare_data.json\",   package = \"elastic\") invisible(docs_bulk(x, shakedat))  docs_mget(x, index=\"shakespeare\", type_id=list(c(\"scene\",1), c(\"line\",20))) docs_mget(x, index=\"shakespeare\", type_id=list(c(\"scene\",1), c(\"line\",20)),   source='play_name')  # Different indices and different types pass in separately docs_mget(x, index_type_id = list(   c(\"shakespeare\", \"line\", 20),   c(\"plos\", \"article\", 1)  ) ) }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_update.html","id":null,"dir":"Reference","previous_headings":"","what":"Update a document — docs_update","title":"Update a document — docs_update","text":"Update document","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_update.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update a document — docs_update","text":"","code":"docs_update(   conn,   index,   id,   body,   type = NULL,   fields = NULL,   source = NULL,   version = NULL,   version_type = NULL,   routing = NULL,   parent = NULL,   timestamp = NULL,   ttl = NULL,   refresh = NULL,   timeout = NULL,   retry_on_conflict = NULL,   wait_for_active_shards = NULL,   detect_noop = NULL,   callopts = list(),   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_update.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update a document — docs_update","text":"conn Elasticsearch connection object, see connect() index (character) name index. Required id (numeric/character) document ID. Can numeric character. Required body document, either list json type (character) type document. optional fields comma-separated list fields return response source Allows control updated source returned response. default updated source returned. version (character) Explicit version number concurrency control version_type (character) Specific version type. One internal, external, external_gte, force routing (character) Specific routing value parent ID parent document. used routing upsert request timestamp (date) Explicit timestamp document ttl (aka “time live”) Expiration time document. Expired documents expunged automatically. expiration date set document provided ttl relative timestamp document,  meaning can based time indexing time provided. provided ttl must strictly positive can number (milliseconds) valid time value (e.g, 86400000, 1d). refresh Refresh index performing operation. timeout (character) Explicit operation timeout, e.g,. 5m (5 minutes) retry_on_conflict Specify many times operation retried conflict occurs (default: 0) wait_for_active_shards number shard copies required active proceeding update operation. detect_noop (logical) Specifying TRUE cause Elasticsearch check changes , , turn update request noop. callopts Curl options passed crul::HttpClient ... args query DSL","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_update.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update a document — docs_update","text":"","code":"if (FALSE) { (x <- connect()) if (!index_exists(x, 'plos')) {   plosdat <- system.file(\"examples\", \"plos_data.json\",     package = \"elastic\")   plosdat <- type_remover(plosdat)   invisible(docs_bulk(x, plosdat)) }  docs_create(x, index='plos', id=1002,   body=list(id=\"12345\", title=\"New title\")) # and the document is there now docs_get(x, index='plos', id=1002) # update the document docs_update(x, index='plos', id=1002,   body = list(doc = list(title = \"Even newer title again\"))) # get it again, notice changes docs_get(x, index='plos', id=1002)  if (!index_exists(x, 'stuffthings')) {   index_create(x, \"stuffthings\") } docs_create(x, index='stuffthings', id=1,   body=list(name = \"foo\", what = \"bar\")) docs_update(x, index='stuffthings', id=1,   body = list(doc = list(name = \"hello\", what = \"bar\")),   source = 'name') }"},{"path":"https://docs.ropensci.org/elastic/reference/docs_update_by_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Update documents by query — docs_update_by_query","title":"Update documents by query — docs_update_by_query","text":"update documents query via POST request","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_update_by_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update documents by query — docs_update_by_query","text":"","code":"docs_update_by_query(   conn,   index,   body = NULL,   type = NULL,   conflicts = NULL,   routing = NULL,   scroll_size = NULL,   refresh = NULL,   wait_for_completion = NULL,   wait_for_active_shards = NULL,   timeout = NULL,   scroll = NULL,   requests_per_second = NULL,   pipeline = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/docs_update_by_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update documents by query — docs_update_by_query","text":"conn Elasticsearch connection object, see connect() index (character) name index. Required body (character/json) query passed POST request body type (character) type document. optional conflicts (character) ’d like count version conflicts rather cause abort set conflicts=proceed routing (character) Specific routing value scroll_size (integer) default uses scroll batches 1000. Change batch size parameter. refresh (logical) Refresh index performing operation wait_for_completion (logical) wait_for_completion=FALSE Elasticsearch perform preflight checks, launch request, return task can used Tasks APIs cancel get status task. Elasticsearch also create record task document .tasks/task/$taskId. keep remove see fit. done , delete Elasticsearch can reclaim space uses. Default: TRUE wait_for_active_shards (logical) controls many copies shard must active proceeding request. timeout (character) Explicit operation timeout, e.g,. 5m (5 minutes) scroll (integer) control long \"search context\" kept alive, eg scroll='10m', default ’s 5 minutes (5m) requests_per_second (integer) positive decimal number (1.4, 6, 1000, etc); throttles rate _delete_by_query issues batches delete operations padding batch wait time. throttling can disabled setting requests_per_second=-1 pipeline (character) pipeline name ... Curl args passed crul::verb-POST","code":""},{"path":"https://docs.ropensci.org/elastic/reference/docs_update_by_query.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Update documents by query — docs_update_by_query","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update--query.html https://www.elastic.co/guide/en/elasticsearch/painless/current/painless-api-reference.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/docs_update_by_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update documents by query — docs_update_by_query","text":"","code":"if (FALSE) { (x <- connect()) x$ping()  omdb <- system.file(\"examples\", \"omdb.json\", package = \"elastic\") omdb <- type_remover(omdb) if (!index_exists(x, \"omdb\")) invisible(docs_bulk(x, omdb))  # can be sent without a body docs_update_by_query(x, index='omdb')  # update ## note this works with imdbRating, a float, but didn't seem to work ## with Metascore, a long ## See link above for Painless API reference body <- '{   \"script\": {     \"source\": \"ctx._source.imdbRating++\",     \"lang\": \"painless\"   },   \"query\": {     \"match\": {       \"Rated\": \"R\"     }   } }' Search(x, \"omdb\", q = \"Rated:\\\"R\\\"\", asdf=TRUE,   source = c(\"Title\", \"Rated\", \"imdbRating\"))$hits$hits docs_update_by_query(x, index='omdb', body = body) Search(x, \"omdb\", q = \"Rated:\\\"R\\\"\", asdf=TRUE,   source = c(\"Title\", \"Rated\", \"imdbRating\"))$hits$hits }"},{"path":"https://docs.ropensci.org/elastic/reference/documents.html","id":null,"dir":"Reference","previous_headings":"","what":"Elasticsearch documents functions. — documents","title":"Elasticsearch documents functions. — documents","text":"Elasticsearch documents functions.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/documents.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Elasticsearch documents functions. — documents","text":"five functions work directly documents. docs_get() docs_mget() docs_create() docs_delete() docs_bulk()","code":""},{"path":"https://docs.ropensci.org/elastic/reference/documents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elasticsearch documents functions. — documents","text":"","code":"if (FALSE) { # Get a document # docs_get(index='plos', type='article', id=1)  # Get multiple documents # docs_mget(index=\"shakespeare\", type=\"line\", id=c(9,10))  # Create a document # docs_create(index='plos', type='article', id=35, body=list(id=\"12345\", title=\"New title\"))  # Delete a document # docs_delete(index='plos', type='article', id=35)  # Bulk load documents # plosdat <- system.file(\"examples\", \"plos_data.json\", package = \"elastic\") # docs_bulk(plosdat) }"},{"path":"https://docs.ropensci.org/elastic/reference/elastic-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"Defunct functions in elastic — elastic-defunct","title":"Defunct functions in elastic — elastic-defunct","text":"mlt(): MLT API removed, use Like Query via Search() nodes_shutdown(): _shutdown API removed. Instead, setup Elasticsearch run service (see Running Service Linux (https://www.elastic.co/guide/en/elasticsearch/reference/2.0/setup-service.html) Running Service Windows (https://www.elastic.co/guide/en/elasticsearch/reference/2.0/setup-service-win.html)) use -p command line option write PID file. index_status(): _status route index API removed. Replaced Indices Stats Indices Recovery APIs. mapping_delete(): Elasticsearch dropped route API. Instead deleting mapping, delete index recreate new mapping.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/elastic.html","id":null,"dir":"Reference","previous_headings":"","what":"elastic — elastic","title":"elastic — elastic","text":"Elasticsearch R client.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/elastic.html","id":"about","dir":"Reference","previous_headings":"","what":"About","title":"elastic — elastic","text":"package gives access local remote Elasticsearch databases.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/elastic.html","id":"quick-start","dir":"Reference","previous_headings":"","what":"Quick start","title":"elastic — elastic","text":"connecting Elasticsearch server already running, skip ahead Search Install Elasticsearch (OSX) Download zip tar file Elasticsearch see download: https://www.elastic.co/downloads/elasticsearch Unzip : untar elasticsearch-2.3.5.tar.gz Move : sudo mv elasticsearch-2.3.5 /usr/local (replace version version) Navigate /usr/local: cd /usr/local Add shortcut: sudo ln -s elasticsearch-2.3.5 elasticsearch (replace version version) help platforms, see https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html Start Elasticsearch Navigate elasticsearch: cd /usr/local/elasticsearch Start elasticsearch: bin/elasticsearch Initialization function connect() used anything else set connection details remote local elasticsearch store. details created connect() written options current session, used elastic functions. Search main way search Elasticsearch via Search() function. E.g.: Search()","code":""},{"path":"https://docs.ropensci.org/elastic/reference/elastic.html","id":"security","dir":"Reference","previous_headings":"","what":"Security","title":"elastic — elastic","text":"Elasticsearch insecure box! running Elasticsearch locally machine without exposing port outside world, worries, install server public IP address, take necessary precautions. options: Shield - paid product - probably applicable enterprise users DIY security - variety techniques securing Elasticsearch. collected number resources blog post https://recology.info/2015/02/secure-elasticsearch/","code":""},{"path":"https://docs.ropensci.org/elastic/reference/elastic.html","id":"elasticsearch-changes","dir":"Reference","previous_headings":"","what":"Elasticsearch changes","title":"elastic — elastic","text":"Elasticsearch v2: can longer create fields dots name. Type names may start dot (special .percolator type) Type names may longer 255 characters Types may longer deleted Queries filters merged - filter clauses now query clauses. Instead, query clauses can now used query context filter context. See examples Search() Search_uri()","code":""},{"path":"https://docs.ropensci.org/elastic/reference/elastic.html","id":"index-names","dir":"Reference","previous_headings":"","what":"index names","title":"elastic — elastic","text":"following illegal characters, can used index names types: \\\\, /, *, ?, <, >, |, , (comma). double quote whitespace also illegal.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/elastic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"elastic — elastic","text":"Scott Chamberlain","code":""},{"path":"https://docs.ropensci.org/elastic/reference/es_parse.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse raw data from es_get, es_mget, or es_search. — es_parse","title":"Parse raw data from es_get, es_mget, or es_search. — es_parse","text":"Parse raw data es_get, es_mget, es_search.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/es_parse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse raw data from es_get, es_mget, or es_search. — es_parse","text":"","code":"es_parse(input, parsetype, verbose)  # S3 method for es_GET es_parse(input, parsetype = \"list\", verbose = FALSE)  # S3 method for index_delete es_parse(input, parsetype = \"list\", verbose = FALSE)  # S3 method for bulk_make es_parse(input, parsetype = \"list\", verbose = FALSE)  # S3 method for elastic_mget es_parse(input, parsetype = \"list\", verbose = FALSE)  # S3 method for elastic_search es_parse(input, parsetype = \"list\", verbose = FALSE)  # S3 method for elastic_status es_parse(input, parsetype = \"list\", verbose = FALSE)  # S3 method for elastic_stats es_parse(input, parsetype = \"list\", verbose = FALSE)  # S3 method for elastic_cluster_health es_parse(input, parsetype = \"list\", verbose = TRUE)  # S3 method for elastic_cluster_health es_parse(input, parsetype = \"list\", verbose = TRUE)  # S3 method for elastic_cluster_state es_parse(input, parsetype = \"list\", verbose = TRUE)  # S3 method for elastic_cluster_settings es_parse(input, parsetype = \"list\", verbose = TRUE)  # S3 method for elastic_cluster_stats es_parse(input, parsetype = \"list\", verbose = TRUE)  # S3 method for elastic_cluster_pending_tasks es_parse(input, parsetype = \"list\", verbose = TRUE)  # S3 method for elastic_nodes_stats es_parse(input, parsetype = \"list\", verbose = TRUE)  # S3 method for elastic_nodes_info es_parse(input, parsetype = \"list\", verbose = TRUE)"},{"path":"https://docs.ropensci.org/elastic/reference/es_parse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse raw data from es_get, es_mget, or es_search. — es_parse","text":"input Output solr_facet parsetype One 'list' 'df' (data.frame). list possible now. verbose Print messages (default: FALSE).","code":""},{"path":"https://docs.ropensci.org/elastic/reference/es_parse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parse raw data from es_get, es_mget, or es_search. — es_parse","text":"parser used internally es_get, es_mget, es_search, output raw data es_* functions using raw=TRUE, can use function parse data (es_* S3 object) fact list data.frame's easier consumption.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/explain.html","id":null,"dir":"Reference","previous_headings":"","what":"Explain a search query. — explain","title":"Explain a search query. — explain","text":"Explain search query.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/explain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explain a search query. — explain","text":"","code":"explain(   conn,   index,   id,   type = NULL,   source2 = NULL,   fields = NULL,   routing = NULL,   parent = NULL,   preference = NULL,   source = NULL,   q = NULL,   df = NULL,   analyzer = NULL,   analyze_wildcard = NULL,   lowercase_expanded_terms = NULL,   lenient = NULL,   default_operator = NULL,   source_exclude = NULL,   source_include = NULL,   body = NULL,   raw = FALSE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/explain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explain a search query. — explain","text":"conn Elasticsearch connection object, see connect() index one index. Required id Document id, one. Required type one document type, optional source2 (logical) Set TRUE retrieve _source document explained. can also retrieve part document using source_include & source_exclude (see Get API details). matches _source term, want avoid leading underscore. fields Allows control stored fields return part document explained. routing Controls routing case routing used indexing. parent effect setting routing parameter. preference Controls shard explain executed. source Allows data request put query string url. q query string (maps query_string query). df default field use field prefix defined within query. Defaults _all field. analyzer analyzer name used analyzing query string. Defaults analyzer _all field. analyze_wildcard (logical) wildcard prefix queries analyzed . Default: FALSE lowercase_expanded_terms terms automatically lowercased . Default: TRUE lenient set true cause format based failures (like providing text numeric field) ignored. Default: FALSE default_operator default operator used, can . Defaults . source_exclude vector fields exclude returned source2 field source_include vector fields extract return source2 field body query definition using Query DSL. passed body request. raw TRUE (default), data parsed list. FALSE, raw JSON. ... Curl args passed crul::HttpClient","code":""},{"path":"https://docs.ropensci.org/elastic/reference/explain.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Explain a search query. — explain","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-explain.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/explain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explain a search query. — explain","text":"","code":"if (FALSE) { (x <- connect())  explain(x, index = \"plos\", id = 14, q = \"title:Germ\")  body <- '{  \"query\": {    \"match\": { \"title\": \"Germ\" }  } }' explain(x, index = \"plos\", id = 14, body=body) }"},{"path":"https://docs.ropensci.org/elastic/reference/field_caps.html","id":null,"dir":"Reference","previous_headings":"","what":"Field capabilities — field_caps","title":"Field capabilities — field_caps","text":"field capabilities API allows retrieve capabilities fields among multiple indices.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/field_caps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Field capabilities — field_caps","text":"","code":"field_caps(conn, fields, index = NULL, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/field_caps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Field capabilities — field_caps","text":"conn Elasticsearch connection object, see connect() fields list fields compute stats . required index Index name, one ... Curl args passed crul::verb-GET","code":""},{"path":"https://docs.ropensci.org/elastic/reference/field_caps.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Field capabilities — field_caps","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-field-caps.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/field_caps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Field capabilities — field_caps","text":"","code":"if (FALSE) { x <- connect() x$ping()  if (x$es_ver() >= 540) {   field_caps(x, fields = \"speaker\", index = \"shakespeare\") }  }"},{"path":"https://docs.ropensci.org/elastic/reference/field_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Search field statistics — field_stats","title":"Search field statistics — field_stats","text":"Search field statistics","code":""},{"path":"https://docs.ropensci.org/elastic/reference/field_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search field statistics — field_stats","text":"","code":"field_stats(   conn,   fields = NULL,   index = NULL,   level = \"cluster\",   body = list(),   raw = FALSE,   asdf = FALSE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/field_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search field statistics — field_stats","text":"conn Elasticsearch connection object, see connect() fields list fields compute stats . optional index Index name, one level Defines field stats returned per index level cluster wide level. Valid values 'indices' 'cluster' (default) body Query, either list json raw (logical) Get raw JSON back asdf (logical) TRUE, use fromJSON parse JSON directly data.frame. FALSE (Default), list output given. ... Curl args passed crul::HttpClient","code":""},{"path":"https://docs.ropensci.org/elastic/reference/field_stats.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Search field statistics — field_stats","text":"field stats api allows get statistical properties field without executing search, looking measurements natively available Lucene index. can useful explore dataset know much . example, allows creating histogram aggregation meaningful intervals based min/max range values. field stats api defaults executes indices, can execute specific indices .","code":""},{"path":"https://docs.ropensci.org/elastic/reference/field_stats.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Search field statistics — field_stats","text":"Deprecated Elasticsearch versions equal /greater 5.4.0","code":""},{"path":"https://docs.ropensci.org/elastic/reference/field_stats.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Search field statistics — field_stats","text":"https://www.elastic.co/guide/en/elasticsearch/reference/5.6/search-field-stats.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/field_stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search field statistics — field_stats","text":"","code":"if (FALSE) { x <- connect()  if (gsub(\"\\\\.\", \"\", x$ping()$version$number) < 500) {   field_stats(x, body = '{ \"fields\": [\"speaker\"] }', index = \"shakespeare\")   ff <- c(\"scientificName\", \"continent\", \"decimalLatitude\", \"play_name\",      \"speech_number\")   field_stats(x, \"play_name\")   field_stats(x, \"play_name\", level = \"cluster\")   field_stats(x, ff, level = \"indices\")   field_stats(x, ff)   field_stats(x, ff, index = c(\"gbif\", \"shakespeare\"))    # can also pass a body, just as with Search()   # field_stats(x, body = list(fields = \"rating\")) # doesn't work   field_stats(x, body = '{ \"fields\": [\"scientificName\"] }', index = \"gbif\")    body <- '{     \"fields\" : [\"scientificName\", \"decimalLatitude\"]   }'   field_stats(x, body = body, level = \"indices\", index = \"gbif\") } }"},{"path":"https://docs.ropensci.org/elastic/reference/fielddata.html","id":null,"dir":"Reference","previous_headings":"","what":"fielddata — fielddata","title":"fielddata — fielddata","text":"Deep dive fielddata details","code":""},{"path":"https://docs.ropensci.org/elastic/reference/fielddata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"fielddata — fielddata","text":"fields indexed default, makes searchable. Sorting, aggregations, accessing field values scripts, however, requires different access pattern search. Text fields use query-time -memory data structure called fielddata. data structure built demand first time field used aggregations, sorting, script. built reading entire inverted index segment disk, inverting term-document relationship, storing result memory, JVM heap. fielddata disabled text fields default. Fielddata can consume lot heap space, especially loading high cardinality text fields. fielddata loaded heap, remains lifetime segment. Also, loading fielddata expensive process can cause users experience latency hits. fielddata disabled default. try sort, aggregate, access values script text field, see exception: \"Fielddata disabled text fields default. Set fielddata=true your_field_name order load fielddata memory uninverting inverted index. Note can however use significant memory.\" enable fielddata text field use PUT mapping API, example mapping_create(\"shakespeare\", body = '{   \"properties\": {     \"speaker\": {        \"type\":     \"text\",       \"fielddata\": true     }   } }') may get error update_all_types, case set update_all_types=TRUE mapping_create, e.g., mapping_create(\"shakespeare\", update_all_types=TRUE, body = '{   \"properties\": {     \"speaker\": {        \"type\":     \"text\",       \"fielddata\": true     }   } }') See https://www.elastic.co/guide/en/elasticsearch/reference/current/fielddata.html#_enabling_fielddata_on_literal_text_literal_fields information.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/index_status-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"This function is defunct — index_status","title":"This function is defunct — index_status","text":"function defunct","code":""},{"path":"https://docs.ropensci.org/elastic/reference/index_status-defunct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function is defunct — index_status","text":"","code":"index_status(...)"},{"path":"https://docs.ropensci.org/elastic/reference/index_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Index templates — index_template","title":"Index templates — index_template","text":"Index templates allow define templates automatically applied new indices created","code":""},{"path":"https://docs.ropensci.org/elastic/reference/index_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Index templates — index_template","text":"","code":"index_template_put(   conn,   name,   body = NULL,   create = NULL,   flat_settings = NULL,   master_timeout = NULL,   order = NULL,   timeout = NULL,   ... )  index_template_get(conn, name = NULL, filter_path = NULL, ...)  index_template_exists(conn, name, ...)  index_template_delete(conn, name, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/index_template.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Index templates — index_template","text":"conn Elasticsearch connection object, see connect() name (character) name template body (character/list) template definition create (logical) Whether index template added new can also replace existing one. Default: FALSE flat_settings (logical) Return settings flat format. Default: FALSE master_timeout (integer) Specify timeout connection master order (integer) order template merging multiple matching ones (higher numbers merged later, overriding lower numbers) timeout (integer) Explicit operation timeout ... Curl options. percolate_list function, args passed Search() filter_path (character) regex filtering output path, see example","code":""},{"path":"https://docs.ropensci.org/elastic/reference/index_template.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Index templates — index_template","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-templates.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/index_template.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Index templates — index_template","text":"","code":"if (FALSE) { (x <- connect())  body <- '{   \"template\": \"te*\",   \"settings\": {     \"number_of_shards\": 1   },   \"mappings\": {     \"type1\": {       \"_source\": {         \"enabled\": false       },       \"properties\": {         \"host_name\": {           \"type\": \"keyword\"         },         \"created_at\": {           \"type\": \"date\",           \"format\": \"EEE MMM dd HH:mm:ss Z YYYY\"         }       }     }   } }' index_template_put(x, \"template_1\", body = body)  # get templates index_template_get(x) index_template_get(x, \"template_1\") index_template_get(x, c(\"template_1\", \"template_2\")) index_template_get(x, \"template_*\") ## filter path index_template_get(x, \"template_1\", filter_path = \"*.template\")  # template exists index_template_exists(x, \"template_1\") index_template_exists(x, \"foobar\")  # delete a template index_template_delete(x, \"template_1\") index_template_exists(x, \"template_1\") }"},{"path":"https://docs.ropensci.org/elastic/reference/indices.html","id":null,"dir":"Reference","previous_headings":"","what":"Index API operations — indices","title":"Index API operations — indices","text":"Index API operations","code":""},{"path":"https://docs.ropensci.org/elastic/reference/indices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Index API operations — indices","text":"","code":"index_get(   conn,   index = NULL,   features = NULL,   raw = FALSE,   verbose = TRUE,   ... )  index_exists(conn, index, ...)  index_delete(conn, index, raw = FALSE, verbose = TRUE, ...)  index_create(conn, index = NULL, body = NULL, raw = FALSE, verbose = TRUE, ...)  index_recreate(   conn,   index = NULL,   body = NULL,   raw = FALSE,   verbose = TRUE,   ... )  index_close(conn, index, ...)  index_open(conn, index, ...)  index_stats(   conn,   index = NULL,   metric = NULL,   completion_fields = NULL,   fielddata_fields = NULL,   fields = NULL,   groups = NULL,   level = \"indices\",   ... )  index_settings(conn, index = \"_all\", ...)  index_settings_update(conn, index = NULL, body, ...)  index_segments(conn, index = NULL, ...)  index_recovery(conn, index = NULL, detailed = FALSE, active_only = FALSE, ...)  index_optimize(   conn,   index = NULL,   max_num_segments = NULL,   only_expunge_deletes = FALSE,   flush = TRUE,   wait_for_merge = TRUE,   ... )  index_forcemerge(   conn,   index = NULL,   max_num_segments = NULL,   only_expunge_deletes = FALSE,   flush = TRUE,   ... )  index_upgrade(conn, index = NULL, wait_for_completion = FALSE, ...)  index_analyze(   conn,   text = NULL,   field = NULL,   index = NULL,   analyzer = NULL,   tokenizer = NULL,   filters = NULL,   char_filters = NULL,   body = list(),   ... )  index_flush(   conn,   index = NULL,   force = FALSE,   full = FALSE,   wait_if_ongoing = FALSE,   ... )  index_clear_cache(   conn,   index = NULL,   filter = FALSE,   filter_keys = NULL,   fielddata = FALSE,   query_cache = FALSE,   id_cache = FALSE,   ... )  index_shrink(conn, index, index_new, body = NULL, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/indices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Index API operations — indices","text":"conn Elasticsearch connection object, see connect() index (character) character vector index names features (character) single feature. One settings, mappings, aliases raw TRUE (default), data parsed list. FALSE, raw JSON. verbose TRUE (default) url call used printed console. ... Curl args passed crul::HttpClient body Query, either list json. metric (character) character vector metrics display. Possible values: \"_all\", \"completion\", \"docs\", \"fielddata\", \"filter_cache\", \"flush\", \"get\", \"id_cache\", \"indexing\", \"merge\", \"percolate\", \"refresh\", \"search\", \"segments\", \"store\", \"warmer\". completion_fields (character) character vector fields completion metric (supports wildcards) fielddata_fields (character) character vector fields fielddata metric (supports wildcards) fields (character) Fields add. groups (character) character vector search groups search statistics. level (character) Return stats aggregated \"cluster\", \"indices\" (default) \"shards\" detailed (logical) Whether display detailed information shard recovery. Default: FALSE active_only (logical) Display recoveries currently -going. Default: FALSE max_num_segments (character) number segments index merged . Default: \"dynamic\" only_expunge_deletes (logical) Specify whether operation expunge deleted documents flush (logical) Specify whether index flushed performing operation. Default: TRUE wait_for_merge (logical) Specify whether request block merge process finished. Default: TRUE wait_for_completion (logical) request wait upgrade complete. Default: FALSE text text analysis performed (request body used) field Use analyzer configured field (instead passing analyzer name) analyzer name analyzer use tokenizer name tokenizer use analysis filters character vector filters use analysis char_filters character vector character filters use analysis force (logical) Whether flush forced even necessarily needed ie. changes committed index. full (logical) set TRUE new index writer created settings changed related index writer refreshed. wait_if_ongoing TRUE, flush operation block flush can executed another flush operation already executing. default false cause exception thrown shard level another flush operation already running. filter (logical) Clear filter caches filter_keys (character) vector keys clear using filter_cache parameter (default: ) fielddata (logical) Clear field data query_cache (logical) Clear query caches id_cache (logical) Clear ID caches parent/child index_new (character) index name, required. applies index_shrink method","code":""},{"path":"https://docs.ropensci.org/elastic/reference/indices.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Index API operations — indices","text":"index_analyze: https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-analyze.html method can accept string text body, function passes parameter GET request simplify. index_flush: https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-flush.html ES website: flush process index basically frees memory index flushing data index storage clearing internal transaction log. default, Elasticsearch uses memory heuristics order automatically trigger flush operations required order clear memory. index_status: API endpoint function deprecated Elasticsearch v1.2.0, likely removed soon. Use index_recovery() instead. index_settings_update: lot options can change function. See https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-update-settings.html options. index settings: See https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html static dynamic settings can set indices.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/indices.html","id":"mappings","dir":"Reference","previous_headings":"","what":"Mappings","title":"Index API operations — indices","text":"\"keyword\" type supported Elasticsearch < v5. use mapping \"keyword\" type Elasticsearch < v5 index_create() fail.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/indices.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Index API operations — indices","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/indices.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/indices.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Index API operations — indices","text":"Scott Chamberlain myrmecocystus@gmail.com","code":""},{"path":"https://docs.ropensci.org/elastic/reference/indices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Index API operations — indices","text":"","code":"if (FALSE) { # connection setup (x <- connect())  # get information on an index index_get(x, index='shakespeare') ## this one is the same as running index_settings('shakespeare') index_get(x, index='shakespeare', features='settings') index_get(x, index='shakespeare', features='mappings') index_get(x, index='shakespeare', features='alias')  # check for index existence index_exists(x, index='shakespeare') index_exists(x, index='plos')  # create an index if (index_exists(x, 'twitter')) index_delete(x, 'twitter') index_create(x, index='twitter') if (index_exists(x, 'things')) index_delete(x, 'things') index_create(x, index='things') if (index_exists(x, 'plos')) index_delete(x, 'plos') index_create(x, index='plos')  # re-create an index index_recreate(x, \"deer\") index_recreate(x, \"deer\", verbose = FALSE)  # delete an index if (index_exists(x, 'plos')) index_delete(x, index='plos')  ## with a body body <- '{  \"settings\" : {   \"index\" : {     \"number_of_shards\" : 3,     \"number_of_replicas\" : 2    }  } }' if (index_exists(x, 'alsothat')) index_delete(x, 'alsothat') index_create(x, index='alsothat', body = body) ## with read only body <- '{  \"settings\" : {   \"index\" : {     \"blocks\" : {       \"read_only\" : true     }    }  } }' # index_create(x, index='myindex', body = body) # then this delete call should fail with something like: ## > Error: 403 - blocked by: [FORBIDDEN/5/index read-only (api)] # index_delete(x, index='myindex')  ## with mappings body <- '{  \"mappings\": {    \"properties\": {      \"location\" : {\"type\" : \"geo_point\"}    }  } }' if (!index_exists(x, 'gbifnewgeo')) index_create(x, index='gbifnewgeo', body=body) gbifgeo <- system.file(\"examples\", \"gbif_geosmall.json\", package = \"elastic\") docs_bulk(x, gbifgeo)  # close an index index_create(x, 'plos') index_close(x, 'plos')  # open an index index_open(x, 'plos')  # Get stats on an index index_stats(x, 'plos') index_stats(x, c('plos','gbif')) index_stats(x, c('plos','gbif'), metric='refresh') index_stats(x, metric = \"indexing\") index_stats(x, 'shakespeare', metric='completion') index_stats(x, 'shakespeare', metric='completion', completion_fields = \"completion\") index_stats(x, 'shakespeare', metric='fielddata') index_stats(x, 'shakespeare', metric='fielddata', fielddata_fields = \"evictions\") index_stats(x, 'plos', level=\"indices\") index_stats(x, 'plos', level=\"cluster\") index_stats(x, 'plos', level=\"shards\")  # Get segments information that a Lucene index (shard level) is built with index_segments(x) index_segments(x, 'plos') index_segments(x, c('plos','gbif'))  # Get recovery information that provides insight into on-going index shard recoveries index_recovery(x) index_recovery(x, 'plos') index_recovery(x, c('plos','gbif')) index_recovery(x, \"plos\", detailed = TRUE) index_recovery(x, \"plos\", active_only = TRUE)  # Optimize an index, or many indices if (x$es_ver() < 500) {   ### ES < v5 - use optimize   index_optimize(x, 'plos')   index_optimize(x, c('plos','gbif'))   index_optimize(x, 'plos') } else {   ### ES > v5 - use forcemerge   index_forcemerge(x, 'plos') }  # Upgrade one or more indices to the latest format. The upgrade process converts any # segments written with previous formats. if (x$es_ver() < 500) {   index_upgrade(x, 'plos')   index_upgrade(x, c('plos','gbif')) }  # Performs the analysis process on a text and return the tokens breakdown # of the text index_analyze(x, text = 'this is a test', analyzer='standard') index_analyze(x, text = 'this is a test', analyzer='whitespace') index_analyze(x, text = 'this is a test', analyzer='stop') index_analyze(x, text = 'this is a test', tokenizer='keyword',   filters='lowercase') index_analyze(x, text = 'this is a test', tokenizer='keyword',   filters='lowercase', char_filters='html_strip') index_analyze(x, text = 'this is a test', index = 'plos',   analyzer=\"standard\") index_analyze(x, text = 'this is a test', index = 'shakespeare',   analyzer=\"standard\")  ## NGram tokenizer body <- '{         \"settings\" : {              \"analysis\" : {                  \"analyzer\" : {                      \"my_ngram_analyzer\" : {                          \"tokenizer\" : \"my_ngram_tokenizer\"                      }                  },                  \"tokenizer\" : {                      \"my_ngram_tokenizer\" : {                          \"type\" : \"nGram\",                          \"min_gram\" : \"2\",                          \"max_gram\" : \"3\",                          \"token_chars\": [ \"letter\", \"digit\" ]                      }                  }              }       } }' if (index_exists(x, \"shakespeare2\")) index_delete(x, \"shakespeare2\") tokenizer_set(x, index = \"shakespeare2\", body=body) index_analyze(x, text = \"art thouh\", index = \"shakespeare2\",   analyzer='my_ngram_analyzer')  # Explicitly flush one or more indices. index_flush(x, index = \"plos\") index_flush(x, index = \"shakespeare\") index_flush(x, index = c(\"plos\",\"shakespeare\")) index_flush(x, index = \"plos\", wait_if_ongoing = TRUE) index_flush(x, index = \"plos\", verbose = TRUE)  # Clear either all caches or specific cached associated with one ore more indices. index_clear_cache(x) index_clear_cache(x, index = \"plos\") index_clear_cache(x, index = \"shakespeare\") index_clear_cache(x, index = c(\"plos\",\"shakespeare\")) index_clear_cache(x, filter = TRUE)  # Index settings ## get settings index_settings(x) index_settings(x, \"_all\") index_settings(x, 'gbif') index_settings(x, c('gbif','plos')) index_settings(x, '*s') ## update settings if (index_exists(x, 'foobar')) index_delete(x, 'foobar') index_create(x, \"foobar\") settings <- list(index = list(number_of_replicas = 4)) index_settings_update(x, \"foobar\", body = settings) index_get(x, \"foobar\")$foobar$settings  # Shrink index - Can only shrink an index if it has >1 shard ## index must be read only, a copy of every shard in the index must ## reside on the same node, and the cluster health status must be green ### index_settings_update call to change these settings <- list(   index.routing.allocation.require._name = \"shrink_node_name\",   index.blocks.write = \"true\" ) if (index_exists(x, 'barbarbar')) index_delete(x, 'barbarbar') index_create(x, \"barbarbar\") index_settings_update(x, \"barbarbar\", body = settings) cat_recovery(x, index='barbarbar') # index_shrink(x, \"barbarbar\", \"barfoobbar\") }"},{"path":"https://docs.ropensci.org/elastic/reference/info-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"This function is defunct — info","title":"This function is defunct — info","text":"function defunct","code":""},{"path":"https://docs.ropensci.org/elastic/reference/info-defunct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function is defunct — info","text":"","code":"info(...)"},{"path":"https://docs.ropensci.org/elastic/reference/ingest.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest API operations — ingest","title":"Ingest API operations — ingest","text":"Ingest API operations","code":""},{"path":"https://docs.ropensci.org/elastic/reference/ingest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest API operations — ingest","text":"","code":"pipeline_create(conn, id, body, ...)  pipeline_attachment(conn, index, id, pipeline, body, type = NULL, ...)  pipeline_get(conn, id, filter_path = NULL, ...)  pipeline_delete(conn, id, body, ...)  pipeline_simulate(conn, body, id = NULL, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/ingest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest API operations — ingest","text":"conn Elasticsearch connection object, see connect() id (character) one pipeline id's. delete, can use wildcard match body body describing pipeline, see examples Elasticsearch docs ... Curl args passed crul::verb-POST, crul::verb-GET, crul::verb-PUT, crul::verb-DELETE index (character) index. used pipeline_attachment pipeline (character) pipeline name. used pipeline_attachment type (character) type. used pipeline_attachment. default ths set NULL - optional ES <= v6.3; allowed ES >= v6.4 filter_path (character) fields return. deafults given","code":""},{"path":"https://docs.ropensci.org/elastic/reference/ingest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ingest API operations — ingest","text":"named list","code":""},{"path":"https://docs.ropensci.org/elastic/reference/ingest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ingest API operations — ingest","text":"ingest/pipeline functions available Elasticsearch v5 greater","code":""},{"path":"https://docs.ropensci.org/elastic/reference/ingest.html","id":"attachments","dir":"Reference","previous_headings":"","what":"Attachments","title":"Ingest API operations — ingest","text":"See https://www.elastic.co/guide/en/elasticsearch/plugins/current/ingest-attachment.html need install attachment processor plugin able use attachments pipelines","code":""},{"path":"https://docs.ropensci.org/elastic/reference/ingest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Ingest API operations — ingest","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest-apis.html, https://www.elastic.co/guide/en/elasticsearch/plugins/current/using-ingest-attachment.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/ingest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ingest API operations — ingest","text":"","code":"if (FALSE) { # connection setup (x <- connect())  # create body1 <- '{   \"description\" : \"do a thing\",   \"version\" : 123,   \"processors\" : [     {       \"set\" : {         \"field\": \"foo\",         \"value\": \"bar\"       }     }   ] }' body2 <- '{   \"description\" : \"do another thing\",   \"processors\" : [     {       \"set\" : {         \"field\": \"stuff\",         \"value\": \"things\"       }     }   ] }' pipeline_create(x, id = 'foo', body = body1) pipeline_create(x, id = 'bar', body = body2)  # get pipeline_get(x, id = 'foo') pipeline_get(x, id = 'bar') pipeline_get(x, id = 'foo', filter_path = \"*.version\") pipeline_get(x, id = c('foo', 'bar')) # get >1  # delete pipeline_delete(x, id = 'foo')  # simulate ## with pipeline included body <- '{   \"pipeline\" : {     \"description\" : \"do another thing\",     \"processors\" : [       {         \"set\" : {           \"field\": \"stuff\",           \"value\": \"things\"         }       }     ]   },   \"docs\" : [     { \"_source\": {\"foo\": \"bar\"} },     { \"_source\": {\"foo\": \"world\"} }   ] }' pipeline_simulate(x, body)  ## referencing existing pipeline body <- '{   \"docs\" : [     { \"_source\": {\"foo\": \"bar\"} },     { \"_source\": {\"foo\": \"world\"} }   ] }' pipeline_simulate(x, body, id = \"foo\")  # attchments - Note: you need the attachment plugin for this, see above body1 <- '{   \"description\" : \"do a thing\",   \"version\" : 123,   \"processors\" : [     {       \"attachment\" : {         \"field\" : \"data\"       }     }   ] }' pipeline_create(x, \"baz\", body1) body_attach <- '{   \"data\": \"e1xydGYxXGFuc2kNCkxvcmVtIGlwc3VtIGRvbG9yIHNpdCBhbWV0DQpccGFyIH0=\" }' if (!index_exists(x, \"boomarang\")) index_create(x, \"boomarang\") docs_create(x, 'boomarang', id = 1, body = list(title = \"New title\")) pipeline_attachment(x, \"boomarang\", \"1\", \"baz\", body_attach) pipeline_get(x, id = 'baz') }"},{"path":"https://docs.ropensci.org/elastic/reference/mapping.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapping management — mapping","title":"Mapping management — mapping","text":"Mapping management","code":""},{"path":"https://docs.ropensci.org/elastic/reference/mapping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapping management — mapping","text":"","code":"mapping_create(   conn,   index,   body,   type = NULL,   update_all_types = FALSE,   include_type_name = NULL,   ... )  mapping_get(conn, index = NULL, type = NULL, include_type_name = NULL, ...)  field_mapping_get(   conn,   index = NULL,   type = NULL,   field,   include_defaults = FALSE,   include_type_name = NULL,   ... )  type_exists(conn, index, type, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/mapping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mapping management — mapping","text":"conn Elasticsearch connection object, see connect() index (character) index body (list) Either list json, representing query. type (character) document type update_all_types (logical) update types. default: FALSE. parameter deprecated ES v6.3.0 higher, see https://github.com/elastic/elasticsearch/pull/28284 include_type_name (logical) set TRUE, can include type name, error occur. default: set. See Details. ... Curl options passed crul::verb-PUT, crul::verb-GET, crul::verb-HEAD field (character) One field names include_defaults (logical) Whether return default values","code":""},{"path":"https://docs.ropensci.org/elastic/reference/mapping.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Mapping management — mapping","text":"Find documentation function : mapping_create - https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-put-mapping.html type_exists - https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-types-exists.html mapping_delete - FUNCTION DEFUNCT - instead deleting mapping, delete index recreate index new mapping mapping_get - https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-get-mapping.html field_mapping_get - https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-get-field-mapping.html See https://www.elastic.co/guide/en/elasticsearch/reference/current/removal--types.html information type removal","code":""},{"path":"https://docs.ropensci.org/elastic/reference/mapping.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mapping management — mapping","text":"","code":"if (FALSE) { # connection setup (x <- connect())  # Used to check if a type/types exists in an index/indices type_exists(x, index = \"plos\", type = \"article\") type_exists(x, index = \"plos\", type = \"articles\") type_exists(x, index = \"shakespeare\", type = \"line\")  # The put mapping API allows to register specific mapping definition for a specific type. ## a good mapping body body <- list(properties = list(  journal = list(type=\"text\"),  year = list(type=\"long\") )) if (!index_exists(x, \"plos\")) index_create(x, \"plos\") mapping_create(x, index = \"plos\", type = \"citation\", body=body) ## OR if above fails, try mapping_create(x, index = \"plos\", type = \"citation\", body=body,   include_type_name=TRUE) ## ES >= 7, no type mapping_create(x, index = \"plos\", body=body)  ### or as json body <- '{   \"properties\": {     \"journal\": { \"type\": \"text\" },       \"year\": { \"type\": \"long\" } }}' mapping_create(x, index = \"plos\", type = \"citation\", body=body) mapping_get(x, \"plos\", \"citation\")  ## A bad mapping body body <- list(things = list(properties = list(   journal = list(\"text\") ))) # mapping_create(x, index = \"plos\", type = \"things\", body=body)  # Get mappings mapping_get(x, '_all') mapping_get(x, index = \"plos\") mapping_get(x, index = c(\"shakespeare\",\"plos\")) # mapping_get(x, index = \"shakespeare\", type = \"act\") # mapping_get(x, index = \"shakespeare\", type = c(\"act\",\"line\"))  # Get field mappings plosdat <- system.file(\"examples\", \"plos_data.json\",   package = \"elastic\") plosdat <- type_remover(plosdat) invisible(docs_bulk(x, plosdat)) field_mapping_get(x, index = \"_all\", field = \"text\") field_mapping_get(x, index = \"plos\", field = \"title\") field_mapping_get(x, index = \"plos\", field = \"*\") field_mapping_get(x, index = \"plos\", field = \"title\", include_defaults = TRUE) field_mapping_get(x, type = c(\"article\",\"record\"), field = c(\"title\",\"class\")) field_mapping_get(x, type = \"a*\", field = \"t*\")  # Create geospatial mapping if (index_exists(x, \"gbifgeopoint\")) index_delete(x, \"gbifgeopoint\") file <- system.file(\"examples\", \"gbif_geopoint.json\",   package = \"elastic\") file <- type_remover(file) index_create(x, \"gbifgeopoint\") body <- '{  \"properties\" : {    \"location\" : { \"type\" : \"geo_point\" }  } }' mapping_create(x, \"gbifgeopoint\", body = body) invisible(docs_bulk(x, file))  # update_all_fields, see also ?fielddata if (x$es_ver() < 603) {  mapping_create(x, \"shakespeare\", \"record\", update_all_types=TRUE, body = '{    \"properties\": {      \"speaker\": {         \"type\":     \"text\",        \"fielddata\": true      }    }  }') } else {  index_create(x, 'brownchair')  mapping_create(x, 'brownchair', body = '{    \"properties\": {      \"foo\": {         \"type\":     \"text\",        \"fielddata\": true      }    }  }') }  }"},{"path":"https://docs.ropensci.org/elastic/reference/mapping_delete-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"Mapping delete — mapping_delete","title":"Mapping delete — mapping_delete","text":"Mapping delete","code":""},{"path":"https://docs.ropensci.org/elastic/reference/mapping_delete-defunct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mapping delete — mapping_delete","text":"","code":"mapping_delete(...)"},{"path":"https://docs.ropensci.org/elastic/reference/mlt-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"This function is defunct — mlt","title":"This function is defunct — mlt","text":"function defunct","code":""},{"path":"https://docs.ropensci.org/elastic/reference/mlt-defunct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function is defunct — mlt","text":"","code":"mlt(...)"},{"path":"https://docs.ropensci.org/elastic/reference/msearch.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi-search — msearch","title":"Multi-search — msearch","text":"Performs multiple searches, defined file","code":""},{"path":"https://docs.ropensci.org/elastic/reference/msearch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi-search — msearch","text":"","code":"msearch(conn, x, raw = FALSE, asdf = FALSE, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/msearch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi-search — msearch","text":"conn Elasticsearch connection object, see connect() x (character) file path raw (logical) Get raw JSON back . asdf (logical) TRUE, use jsonlite::fromJSON() parse JSON directly data.frame. FALSE (Default), list output given. ... Curl args passed crul::verb-POST","code":""},{"path":"https://docs.ropensci.org/elastic/reference/msearch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multi-search — msearch","text":"function behaves similarly docs_bulk() - performs searches based queries defined file.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/msearch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi-search — msearch","text":"","code":"if (FALSE) { x <- connect()  msearch1 <- system.file(\"examples\", \"msearch_eg1.json\", package = \"elastic\") readLines(msearch1) msearch(x, msearch1)  tf <- tempfile(fileext = \".json\") cat('{\"index\" : \"shakespeare\"}', file = tf, sep = \"\\n\") cat('{\"query\" : {\"match_all\" : {}}, \"from\" : 0, \"size\" : 5}',  sep = \"\\n\",    file = tf, append = TRUE) readLines(tf) msearch(x, tf) }"},{"path":"https://docs.ropensci.org/elastic/reference/mtermvectors.html","id":null,"dir":"Reference","previous_headings":"","what":"Multi Termvectors — mtermvectors","title":"Multi Termvectors — mtermvectors","text":"Multi Termvectors","code":""},{"path":"https://docs.ropensci.org/elastic/reference/mtermvectors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multi Termvectors — mtermvectors","text":"","code":"mtermvectors(   conn,   index = NULL,   type = NULL,   ids = NULL,   body = list(),   pretty = TRUE,   field_statistics = TRUE,   fields = NULL,   offsets = TRUE,   parent = NULL,   payloads = TRUE,   positions = TRUE,   preference = \"random\",   realtime = TRUE,   routing = NULL,   term_statistics = FALSE,   version = NULL,   version_type = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/mtermvectors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multi Termvectors — mtermvectors","text":"conn Elasticsearch connection object, see connect() index (character) index document resides. type (character) type document. ids (character) One document ids body (character) Define parameters supply document get termvectors pretty (logical) pretty print. Default: TRUE field_statistics (character) Specifies document count, sum document frequencies sum total term frequencies returned. Default: TRUE fields (character) comma-separated list fields return. offsets (character) Specifies term offsets returned. Default: TRUE parent (character) Parent id documents. payloads (character) Specifies term payloads returned. Default: TRUE positions (character) Specifies term positions returned. Default: TRUE preference (character) Specify node shard operation performed (Default: random). realtime (character) Specifies request real-time opposed near-real-time (Default: TRUE). routing (character) Specific routing value. term_statistics (character) Specifies total term frequency document frequency returned. Default: FALSE version (character) Explicit version number concurrency control version_type (character) Specific version type, valid choices : 'internal', 'external', 'external_gte', 'force' ... Curl args passed crul::verb-POST","code":""},{"path":"https://docs.ropensci.org/elastic/reference/mtermvectors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multi Termvectors — mtermvectors","text":"Multi termvectors API allows get multiple termvectors based index, type id.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/mtermvectors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Multi Termvectors — mtermvectors","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-multi-termvectors.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/mtermvectors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multi Termvectors — mtermvectors","text":"","code":"if (FALSE) { x <- connect()  if (index_exists(x, 'omdb')) index_delete(x, \"omdb\") omdb <- system.file(\"examples\", \"omdb.json\", package = \"elastic\") omdb <- type_remover(omdb) invisible(docs_bulk(x, omdb)) out <- Search(x, \"omdb\", size = 2)$hits$hits ids <- vapply(out, \"[[\", \"\", \"_id\")  # no index body <- '{    \"docs\": [       {          \"_index\": \"omdb\",          \"_id\": \"%s\",          \"term_statistics\": true       },       {          \"_index\": \"omdb\",          \"_id\": \"%s\",          \"fields\": [             \"Plot\"          ]       }    ] }' mtermvectors(x, body = sprintf(body, ids[1], ids[2]))  # index given body <- '{    \"docs\": [       {          \"_id\": \"%s\",          \"fields\": [             \"Plot\"          ],          \"term_statistics\": true       },       {          \"_id\": \"%s\",          \"fields\": [             \"Title\"          ]       }    ] }' mtermvectors(x, 'omdb', body = sprintf(body, ids[1], ids[2]))  # parameters same for both documents, so can simplify body <- '{     \"ids\" : [\"%s\", \"%s\"],     \"parameters\": {         \"fields\": [             \"Plot\"         ],         \"term_statistics\": true     } }' mtermvectors(x, 'omdb', body = sprintf(body, ids[1], ids[2]))  # you can give user provided documents via the 'docs' parameter ## though you have to give index and type that exist in your Elasticsearch  ## instance body <- '{    \"docs\": [       {          \"_index\": \"omdb\",          \"doc\" : {             \"Director\" : \"John Doe\",             \"Plot\" : \"twitter test test test\"          }       },       {          \"_index\": \"omdb\",          \"doc\" : {            \"Director\" : \"Jane Doe\",            \"Plot\" : \"Another twitter test ...\"          }       }    ] }' mtermvectors(x, body = body) }"},{"path":"https://docs.ropensci.org/elastic/reference/nodes-defunct.html","id":null,"dir":"Reference","previous_headings":"","what":"This function is defunct — nodes_shutdown","title":"This function is defunct — nodes_shutdown","text":"function defunct","code":""},{"path":"https://docs.ropensci.org/elastic/reference/nodes-defunct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This function is defunct — nodes_shutdown","text":"","code":"nodes_shutdown(...)"},{"path":"https://docs.ropensci.org/elastic/reference/nodes.html","id":null,"dir":"Reference","previous_headings":"","what":"Elasticsearch nodes endpoints. — nodes","title":"Elasticsearch nodes endpoints. — nodes","text":"Elasticsearch nodes endpoints.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/nodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elasticsearch nodes endpoints. — nodes","text":"","code":"nodes_stats(conn, node = NULL, metric = NULL, raw = FALSE, fields = NULL, ...)  nodes_info(conn, node = NULL, metric = NULL, raw = FALSE, ...)  nodes_hot_threads(   conn,   node = NULL,   metric = NULL,   threads = 3,   interval = \"500ms\",   type = NULL,   raw = FALSE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/nodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elasticsearch nodes endpoints. — nodes","text":"conn Elasticsearch connection object, see connect() node node metric metric get. See Details. raw TRUE (default), data parsed list. FALSE, raw JSON. fields can get information field data memory usage node level index level ... Curl args passed crul::verb-GET threads (character) Number hot threads provide. Default: 3 interval (character) interval second sampling threads. Default: 500ms type (character) type sample, defaults cpu, supports wait block see hot threads wait block state.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/nodes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Elasticsearch nodes endpoints. — nodes","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html default, stats returned. can limit combining indices, os, process, jvm, network, transport, http, fs, breaker thread_pool. metric parameter can select zero : indices Indices stats size, document count, indexing deletion times, search times, field cache size, merges flushes os retrieve information concern operating system fs File system information, data path, free disk space, read/write stats http HTTP connection information jvm JVM stats, memory pool information, garbage collection, buffer pools network TCP information os Operating system stats, load average, cpu, mem, swap process Process statistics, memory consumption, cpu usage, open file descriptors thread_pool Statistics thread pool, including current size, queue rejected tasks transport Transport statistics sent received bytes cluster communication breaker Statistics field data circuit breaker nodes_hot_threads() returns plain text, base::cat() used print console.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/nodes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elasticsearch nodes endpoints. — nodes","text":"","code":"if (FALSE) { # connection setup (x <- connect())  (out <- nodes_stats(x)) nodes_stats(x, node = names(out$nodes)) nodes_stats(x, metric='get') nodes_stats(x, metric='jvm') nodes_stats(x, metric=c('os','process')) nodes_info(x) nodes_info(x, metric='process') nodes_info(x, metric='jvm') nodes_info(x, metric='http') nodes_info(x, metric='network') }"},{"path":"https://docs.ropensci.org/elastic/reference/percolate.html","id":null,"dir":"Reference","previous_headings":"","what":"Percolater — percolate","title":"Percolater — percolate","text":"Store queries index , via percolate API, define documents retrieve queries.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/percolate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Percolater — percolate","text":"","code":"percolate_register(   conn,   index,   id,   type = NULL,   body = list(),   routing = NULL,   preference = NULL,   ignore_unavailable = NULL,   percolate_format = NULL,   refresh = NULL,   ... )  percolate_match(   conn,   index,   type = NULL,   body,   routing = NULL,   preference = NULL,   ignore_unavailable = NULL,   percolate_format = NULL,   ... )  percolate_list(conn, index, ...)  percolate_count(conn, index, type, body, ...)  percolate_delete(conn, index, id, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/percolate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Percolater — percolate","text":"conn Elasticsearch connection object, see connect() index Index name. Required id precolator id. Required type Document type. Required body Body json, R list. routing (character) case percolate queries partitioned custom routing value, routing option makes sure percolate request gets executed shard routing value partitioned . means percolate request gets executed one shard instead shards. Multiple values can specified comma separated string, case request can executed one shard. preference (character) Controls shard replicas preferred execute request . Works search API. ignore_unavailable (logical) Controls missing concrete indices silently ignored. search API. percolate_format (character) ids specified matches array percolate response contain string array matching ids instead array objects. can useful reduce amount data send back client. Obviously two percolator queries id different indices way find percolator query belongs index. value percolate_format ignored. refresh TRUE refresh affected shards make operation visible search, \"wait_for\" wait refresh make operation visible search, FALSE (default) nothing refreshes. Valid choices: TRUE, FALSE, \"wait_for\" ... Curl options. percolate_list function, args passed Search()","code":""},{"path":"https://docs.ropensci.org/elastic/reference/percolate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Percolater — percolate","text":"Additional body options, pass body. query string parameters: filter - Reduces number queries execute percolating. percolator queries match filter included percolate execution. filter option works near realtime, refresh needs occurred filter included latest percolate queries. query - filter option, also score computed. computed scores can used track_scores sort option. size - Defines maximum number matches (percolate queries) returned. Defaults unlimited. track_scores - Whether _score included match. _score based query represents query matched percolate query's metadata, document (percolated) matched query. query option required option. Defaults false. sort - Define sort specification like search API. Currently sorting _score reverse (default relevancy) supported. sort fields throw exception. size query option required setting. Like track_score score based query represents query matched percolate query's metadata document percolated matched query. aggs - Allows aggregation definitions included. aggregations based matching percolator queries, look aggregation documentation define aggregations. highlight - Allows highlight definitions included. document percolated highlight matching query. allows see match highlighting document percolated. See highlight documentation define highlights. size option required highlighting, performance highlighting percolate API depends many matches highlighted.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/percolate.html","id":"the-elasticsearch-v-split","dir":"Reference","previous_headings":"","what":"The Elasticsearch v5 split","title":"Percolater — percolate","text":"Elasticsearch < v5, certain set percolate APIs available, Elasticsearch >= v5, different set APIs available. Internally within percolate functions detect Elasticsearch version, use appropriate APIs","code":""},{"path":"https://docs.ropensci.org/elastic/reference/percolate.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Percolater — percolate","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-percolate-query.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/percolate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Percolater — percolate","text":"","code":"if (FALSE) { x <- connect(errors = \"complete\")  ##### Elasticsearch < v5 if (x$es_ver() < 500) { # typical usage ## create an index first if (index_exists(x, \"myindex\")) index_delete(x, \"myindex\") mapping <- '{   \"mappings\": {     \"mytype\": {       \"properties\": {         \"message\": {            \"type\": \"text\"         },         \"query\": {            \"type\": \"percolator\"         }       }     }   } }' index_create(x, \"myindex\", body = mapping)  ## register a percolator perc_body = '{  \"query\" : {     \"match\" : {       \"message\" : \"bonsai tree\"     }  } }' percolate_register(x, index = \"myindex\", type = \"mytype\",    id = 1, body = perc_body)  ## register another perc_body2 <- '{   \"query\" : {     \"match\" : {       \"message\" : \"jane doe\"     }   } }' percolate_register(x, index = \"myindex\", type = \"mytype\",    id = 2, body = perc_body2)  ## match a document to a percolator doc <- '{  \"query\": {    \"percolate\": {      \"field\": \"query\",      \"document\": {        \"message\" : \"A new bonsai tree in the office\"      }    }  } }' percolate_match(x, index = \"myindex\", type = \"mytype\", body = doc)  ## List percolators - for an index, no type, can't do across indices percolate_list(x, index = \"myindex\")$hits$hits  ## Percolate counter percolate_count(x, index = \"myindex\", type = \"mytype\", body = doc)$total  ## delete a percolator percolate_delete(x, index = \"myindex\", id = 2) } # end ES < 5   ##### Elasticsearch >= v5 if (x$es_ver() >= 500 && x$es_ver() <= 700) { if (index_exists(x, \"myindex\")) index_delete(x, \"myindex\")  body <- '{   \"mappings\": {     \"mytype\": {       \"properties\": {         \"message\": {            \"type\": \"text\"         },         \"query\": {            \"type\": \"percolator\"         }       }     }   } }'  # create the index with mapping index_create(x, \"myindex\", body = body)  ## register a percolator z <- '{   \"query\" : {      \"match\" : {        \"message\" : \"bonsai tree\"      }   } }' percolate_register(x, index = \"myindex\", type = \"mytype\", id = 1, body = z)  ## register another x2 <- '{   \"query\" : {     \"match\" : {       \"message\" : \"the office\"     }   } }' percolate_register(x, index = \"myindex\", type = \"mytype\", id = 2, body = x2)  ## match a document to a percolator query <- '{   \"query\" : {     \"percolate\" : {       \"field\": \"query\",       \"document\": {         \"message\": \"A new bonsai tree in the office\"       }     }   } }' percolate_match(x, index = \"myindex\", body = query) } # end ES >= 5     ##### Elasticsearch >= v7 if (x$es_ver() >= 700) { if (index_exists(x, \"myindex\")) index_delete(x, \"myindex\")  body <- '{   \"mappings\": {     \"properties\": {       \"message\": {         \"type\": \"text\"       },       \"query\": {         \"type\": \"percolator\"       }     }   } }'  # create the index with mapping index_create(x, \"myindex\", body = body)  ## register a percolator z <- '{   \"query\" : {      \"match\" : {        \"message\" : \"bonsai tree\"      }   } }' percolate_register(x, index = \"myindex\", id = 1, body = z)  ## register another x2 <- '{   \"query\" : {     \"match\" : {       \"message\" : \"the office\"     }   } }' percolate_register(x, index = \"myindex\", id = 2, body = x2)  ## match a document to a percolator query <- '{   \"query\" : {     \"percolate\" : {       \"field\": \"query\",       \"document\": {         \"message\": \"A new bonsai tree in the office\"       }     }   } }' percolate_match(x, index = \"myindex\", body = query) } # end ES >= 7   }"},{"path":"https://docs.ropensci.org/elastic/reference/ping.html","id":null,"dir":"Reference","previous_headings":"","what":"Ping an Elasticsearch server. — ping","title":"Ping an Elasticsearch server. — ping","text":"Ping Elasticsearch server.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/ping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ping an Elasticsearch server. — ping","text":"","code":"ping(conn, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/ping.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ping an Elasticsearch server. — ping","text":"conn Elasticsearch connection object, see connect() ... Curl args passed crul::verb-GET","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/ping.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ping an Elasticsearch server. — ping","text":"","code":"if (FALSE) { x <- connect() ping(x) # ideally call ping on the connetion object itself x$ping() }"},{"path":"https://docs.ropensci.org/elastic/reference/preference.html","id":null,"dir":"Reference","previous_headings":"","what":"Preferences. — preference","title":"Preferences. — preference","text":"Preferences.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/preference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preferences. — preference","text":"_primary operation go executed primary shards. _primary_first operation go executed primary shard, available (failover), execute shards. _local operation prefer executed local allocated shard possible. _only_node:xyz Restricts search execute node provided node id (xyz case). _prefer_node:xyz Prefers execution node provided node id (xyz case) applicable. _shards:2,3 Restricts operation specified shards. (2 3 case). preference can combined preferences appear first: _shards:2,3;_primary Custom (string) value custom value used guarantee shards used custom value. can help \"jumping values\" hitting different shards different refresh states. sample value can something like web session id, user name.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/reindex.html","id":null,"dir":"Reference","previous_headings":"","what":"Reindex — reindex","title":"Reindex — reindex","text":"Reindex documents one index another.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/reindex.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reindex — reindex","text":"","code":"reindex(   conn,   body,   refresh = NULL,   requests_per_second = NULL,   slices = NULL,   timeout = NULL,   wait_for_active_shards = NULL,   wait_for_completion = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/reindex.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reindex — reindex","text":"conn Elasticsearch connection object, see connect() body (list/character/json) search definition using Query DSL prototype index request. refresh (logical) effected indexes refreshed? requests_per_second (integer) throttle set request sub-requests per second. - 1 means throttle. Default: 0 slices (integer) number slices task divided . Defaults 1 meaning task sliced subtasks. Default: 1 timeout (character) Time individual bulk request wait shards unavailable. Default: '1m' wait_for_active_shards (integer) Sets number shard copies must active proceeding reindex operation. Defaults 1, meaning primary shard . Set shard copies, otherwise set non-negative value less equal total number copies shard (number replicas + 1) wait_for_completion (logical) request block reindex complete? Default: TRUE ... Curl options, passed crul::verb-POST","code":""},{"path":"https://docs.ropensci.org/elastic/reference/reindex.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Reindex — reindex","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/reindex.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reindex — reindex","text":"","code":"if (FALSE) { x <- connect()  if (!index_exists(x, \"twitter\")) index_create(x, \"twitter\") if (!index_exists(x, \"new_twitter\")) index_create(x, \"new_twitter\") body <- '{   \"source\": {     \"index\": \"twitter\"   },   \"dest\": {     \"index\": \"new_twitter\"   } }' reindex(x, body = body) }"},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":null,"dir":"Reference","previous_headings":"","what":"Scroll search function — scroll","title":"Scroll search function — scroll","text":"Scroll search function","code":""},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scroll search function — scroll","text":"","code":"scroll(   conn,   x,   time_scroll = \"1m\",   raw = FALSE,   asdf = FALSE,   stream_opts = list(),   ... )  scroll_clear(conn, x = NULL, all = FALSE, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scroll search function — scroll","text":"conn Elasticsearch connection object, see connect() x (character) scroll, single scroll id; scroll_clear, one scroll id's time_scroll (character) Specify long consistent view index maintained scrolled search, e.g., \"30s\", \"1m\". See units-time. raw (logical) FALSE (default), data parsed list. TRUE, raw JSON. asdf (logical) TRUE, use jsonlite::fromJSON() parse JSON directly data.frame. FALSE (Default), list output given. stream_opts (list) list options passed jsonlite::stream_out() - Except pass x data streamed , pass file path sinstead connection con. pagesize param much less controlled paging ES. ... Curl args passed crul::verb-POST (logical) TRUE (default) search contexts cleared.  FALSE, scroll id's must passed x","code":""},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scroll search function — scroll","text":"scroll() returns list, identical Search() returns. attribute scroll scroll value set via time_scroll parameter scroll_clear() returns boolean (TRUE success)","code":""},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"scores","dir":"Reference","previous_headings":"","what":"Scores","title":"Scroll search function — scroll","text":"Scores documents returned scroll request. Dems da rules.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"inputs","dir":"Reference","previous_headings":"","what":"Inputs","title":"Scroll search function — scroll","text":"Inputs scroll() can one : list - usually output Search(), theory make list appropriate elements character - scroll ID - typically scroll id output call Search(), accessed like res$`_scroll_id` classes passed scroll() fail message Lists passed scroll() without _scroll_id element trigger error. lists output form Search() attribute (\"scroll\") scroll value set Search() request - attribute missing list, attempt use time_scroll parameter value set scroll() function call output scroll() scroll time value attribute output can passed back scroll() continue.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"clear-scroll","dir":"Reference","previous_headings":"","what":"Clear scroll","title":"Scroll search function — scroll","text":"Search context automatically removed scroll timeout exceeded.  Keeping scrolls open cost, scrolls explicitly cleared soon  scroll used anymore using scroll_clear","code":""},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"sliced-scrolling","dir":"Reference","previous_headings":"","what":"Sliced scrolling","title":"Scroll search function — scroll","text":"scroll queries return lot documents possible split scroll multiple slices can consumed independently. See example man file.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"aggregations","dir":"Reference","previous_headings":"","what":"Aggregations","title":"Scroll search function — scroll","text":"request specifies aggregations, initial search response contain aggregations results.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/scroll.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scroll search function — scroll","text":"","code":"if (FALSE) { # connection setup (con <- connect())  # Basic usage - can use across all indices res <- Search(con, time_scroll=\"1m\") scroll(con, res)$`_scroll_id`  # use on a specific index - and specify a query res <- Search(con, index = 'shakespeare', q=\"a*\", time_scroll=\"1m\") res$`_scroll_id`  # Setting \"sort=_doc\" to turn off sorting of results - faster res <- Search(con, index = 'shakespeare', q=\"a*\", time_scroll=\"1m\",   body = '{\"sort\": [\"_doc\"]}') res$`_scroll_id`  # Pass scroll_id to scroll function scroll(con, res$`_scroll_id`)  # Get all results - one approach is to use a while loop res <- Search(con, index = 'shakespeare', q=\"a*\", time_scroll=\"5m\",   body = '{\"sort\": [\"_doc\"]}') out <- res$hits$hits hits <- 1 while(hits != 0){   res <- scroll(con, res$`_scroll_id`, time_scroll=\"5m\")   hits <- length(res$hits$hits)   if(hits > 0)     out <- c(out, res$hits$hits) } length(out) res$hits$total out[[1]]  # clear scroll ## individual scroll id res <- Search(con, index = 'shakespeare', q=\"a*\", time_scroll=\"5m\",   body = '{\"sort\": [\"_doc\"]}') scroll_clear(con, res$`_scroll_id`)  ## many scroll ids res1 <- Search(con, index = 'shakespeare', q=\"c*\", time_scroll=\"5m\",   body = '{\"sort\": [\"_doc\"]}') res2 <- Search(con, index = 'shakespeare', q=\"d*\", time_scroll=\"5m\",   body = '{\"sort\": [\"_doc\"]}') nodes_stats(con, metric = \"indices\")$nodes[[1]]$indices$search$open_contexts scroll_clear(con, c(res1$`_scroll_id`, res2$`_scroll_id`)) nodes_stats(con, metric = \"indices\")$nodes[[1]]$indices$search$open_contexts  ## all scroll ids res1 <- Search(con, index = 'shakespeare', q=\"f*\", time_scroll=\"1m\",   body = '{\"sort\": [\"_doc\"]}') res2 <- Search(con, index = 'shakespeare', q=\"g*\", time_scroll=\"1m\",   body = '{\"sort\": [\"_doc\"]}') res3 <- Search(con, index = 'shakespeare', q=\"k*\", time_scroll=\"1m\",   body = '{\"sort\": [\"_doc\"]}') scroll_clear(con, all = TRUE)  ## sliced scrolling body1 <- '{   \"slice\": {     \"id\": 0,     \"max\": 2   },   \"query\": {     \"match\" : {       \"text_entry\" : \"a*\"     }   } }'  body2 <- '{   \"slice\": {     \"id\": 1,     \"max\": 2   },   \"query\": {     \"match\" : {       \"text_entry\" : \"a*\"     }   } }'  res1 <- Search(con, index = 'shakespeare', time_scroll=\"1m\", body = body1) res2 <- Search(con, index = 'shakespeare', time_scroll=\"1m\", body = body2) scroll(con, res1$`_scroll_id`) scroll(con, res2$`_scroll_id`)  out1 <- list() hits <- 1 while(hits != 0){   tmp1 <- scroll(con, res1$`_scroll_id`)   hits <- length(tmp1$hits$hits)   if(hits > 0)     out1 <- c(out1, tmp1$hits$hits) }  out2 <- list() hits <- 1 while(hits != 0){   tmp2 <- scroll(con, res2$`_scroll_id`)   hits <- length(tmp2$hits$hits)   if(hits > 0)     out2 <- c(out2, tmp2$hits$hits) }  c(  lapply(out1, \"[[\", \"_source\"),  lapply(out2, \"[[\", \"_source\") )   # using jsonlite::stream_out res <- Search(con, time_scroll = \"1m\") file <- tempfile() scroll(con,    x = res$`_scroll_id`,   stream_opts = list(file = file) ) jsonlite::stream_in(file(file)) unlink(file)  ## stream_out and while loop (file <- tempfile()) res <- Search(con, index = \"shakespeare\", time_scroll = \"5m\",   size = 1000, stream_opts = list(file = file)) while(!inherits(res, \"warning\")) {   res <- tryCatch(scroll(     conn = con,     x = res$`_scroll_id`,     time_scroll = \"5m\",     stream_opts = list(file = file)   ), warning = function(w) w) } NROW(df <- jsonlite::stream_in(file(file))) head(df) }"},{"path":"https://docs.ropensci.org/elastic/reference/search_body.html","id":null,"dir":"Reference","previous_headings":"","what":"Full text search of Elasticsearch - body requests. — search_body","title":"Full text search of Elasticsearch - body requests. — search_body","text":"Full text search Elasticsearch - body requests.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/search_body.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full text search of Elasticsearch - body requests. — search_body","text":"","code":"search_body(   conn,   index = NULL,   type = NULL,   raw = FALSE,   callopts = list(),   query = list(),   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/search_body.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full text search of Elasticsearch - body requests. — search_body","text":"conn Elasticsearch connection object, see connect() index Index name type Document type raw TRUE (default), data parsed list. FALSE, raw JSON. callopts Curl args passed crul::verb-POST query Query, either list json. ... args passed elastic search HTTP API parameters. used right now.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/search_body.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Full text search of Elasticsearch - body requests. — search_body","text":"","code":"if (FALSE) { # connection setup # x <- connect() # x$ping()  # pass in as an R list aggs <- list(aggs = list(stats = list(terms = list(field = \"text_entry\")))) # search_body(x, index=\"shakespeare\", query=aggs)  # or pass in as json query with newlines, easy to read aggs <- '{     \"aggs\": {         \"stats\" : {             \"terms\" : {                 \"field\" : \"text_entry\"             }         }     } }' # search_body(x, index=\"shakespeare\", query=aggs)   # or pass in collapsed json string aggs <- '{\"aggs\":{\"stats\":{\"terms\":{\"field\":\"text_entry\"}}}}' # search_body(x, index=\"shakespeare\", query=aggs)  # match query match <- '{\"query\": {\"match\" : {\"text_entry\" : \"Two Gentlemen\"}}}' # search_body(x, index=\"shakespeare\", query=match)  # multi-match (multiple fields that is) query mmatch <- '{\"query\": {\"multi_match\" : {\"query\" : \"henry\", \"fields\":  [\"text_entry\",\"play_name\"]}}}' # search_body(x, index=\"shakespeare\", query=mmatch)  # bool query mmatch <- '{  \"query\": {    \"bool\" : {      \"must_not\" : {        \"range\" : {          \"speech_number\" : {            \"from\" : 1, \"to\": 5 }}}}}}' # search_body(x, index=\"shakespeare\", query=mmatch)  # Boosting query boost <- '{  \"query\" : {   \"boosting\" : {       \"positive\" : {           \"term\" : {               \"play_name\" : \"henry\"           }       },       \"negative\" : {           \"term\" : {               \"text_entry\" : \"thou\"           }       },       \"negative_boost\" : 0.2     }  } }' # search_body(x, index=\"shakespeare\", query=mmatch) }"},{"path":"https://docs.ropensci.org/elastic/reference/search_shards.html","id":null,"dir":"Reference","previous_headings":"","what":"Search shards — search_shards","title":"Search shards — search_shards","text":"Search shards","code":""},{"path":"https://docs.ropensci.org/elastic/reference/search_shards.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search shards — search_shards","text":"","code":"search_shards(   conn,   index = NULL,   raw = FALSE,   routing = NULL,   preference = NULL,   local = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/search_shards.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search shards — search_shards","text":"conn Elasticsearch connection object, see connect() index One indeces raw TRUE (default), data parsed list. FALSE, raw JSON routing character vector routing values take account determining shards request executed . preference Controls preference shard replicas execute search request . default, operation randomized shard replicas. See preference list acceptable values. local (logical) Whether read cluster state locally order determine shards allocated instead using Master node's cluster state. ... Curl args passed crul::verb-GET","code":""},{"path":"https://docs.ropensci.org/elastic/reference/search_shards.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Search shards — search_shards","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/search-shards.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/search_shards.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search shards — search_shards","text":"","code":"if (FALSE) { # connection setup (x <- connect())  search_shards(x, index = \"plos\") search_shards(x, index = c(\"plos\",\"gbif\")) search_shards(x, index = \"plos\", preference='_primary') search_shards(x, index = \"plos\", preference='_shards:2')  # curl options search_shards(x, index = \"plos\", verbose = TRUE) }"},{"path":"https://docs.ropensci.org/elastic/reference/searchapis.html","id":null,"dir":"Reference","previous_headings":"","what":"Overview of search functions — searchapis","title":"Overview of search functions — searchapis","text":"Overview search functions","code":""},{"path":"https://docs.ropensci.org/elastic/reference/searchapis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Overview of search functions — searchapis","text":"Elasticsearch search APIs include following functions: Search() - Search using Query DSL via body request. Search_uri() - Search using URI search API . may needed servers block POST requests security, maybe need complicated requests, case URI requests suffice. msearch() - Multi Search - execute several search requests defined file passed msearch search_shards() - Search shards. count() - Get counts various searches. explain() - Computes score explanation query specific document. can give useful feedback whether document matches match specific query. validate() - Validate search field_stats() - Search field statistics percolate() - Store queries index , via percolate API, define documents retrieve queries. added soon.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/searchapis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Overview of search functions — searchapis","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/tasks.html","id":null,"dir":"Reference","previous_headings":"","what":"Elasticsearch tasks endpoints — tasks","title":"Elasticsearch tasks endpoints — tasks","text":"Elasticsearch tasks endpoints","code":""},{"path":"https://docs.ropensci.org/elastic/reference/tasks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elasticsearch tasks endpoints — tasks","text":"","code":"tasks(   conn,   task_id = NULL,   nodes = NULL,   actions = NULL,   parent_task_id = NULL,   detailed = FALSE,   group_by = NULL,   wait_for_completion = FALSE,   timeout = NULL,   raw = FALSE,   ... )  tasks_cancel(   conn,   node_id = NULL,   task_id = NULL,   nodes = NULL,   actions = NULL,   parent_task_id = NULL,   detailed = FALSE,   group_by = NULL,   wait_for_completion = FALSE,   timeout = NULL,   raw = FALSE,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/tasks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elasticsearch tasks endpoints — tasks","text":"conn Elasticsearch connection object, see connect() task_id task id nodes (character) nodes actions (character) Actions parent_task_id (character) parent task ID detailed (character) get detailed results. Default: FALSE group_by (character) \"nodes\" (default, .e., NULL) \"parents\" wait_for_completion (logical) wait completion. Default: FALSE timeout (integer) timeout time raw TRUE (default), data parsed list. FALSE, raw JSON. ... Curl args passed crul::verb-GET crul::verb-POST node_id node id","code":""},{"path":"https://docs.ropensci.org/elastic/reference/tasks.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Elasticsearch tasks endpoints — tasks","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/tasks.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/tasks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elasticsearch tasks endpoints — tasks","text":"","code":"if (FALSE) { x <- connect()  tasks(x) # tasks(x, parent_task_id = \"1234\")  # delete a task # tasks_cancel(x) }"},{"path":"https://docs.ropensci.org/elastic/reference/termvectors.html","id":null,"dir":"Reference","previous_headings":"","what":"Termvectors — termvectors","title":"Termvectors — termvectors","text":"Termvectors","code":""},{"path":"https://docs.ropensci.org/elastic/reference/termvectors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Termvectors — termvectors","text":"","code":"termvectors(   conn,   index,   type = NULL,   id = NULL,   body = list(),   pretty = TRUE,   field_statistics = TRUE,   fields = NULL,   offsets = TRUE,   parent = NULL,   payloads = TRUE,   positions = TRUE,   realtime = TRUE,   preference = \"random\",   routing = NULL,   term_statistics = FALSE,   version = NULL,   version_type = NULL,   ... )"},{"path":"https://docs.ropensci.org/elastic/reference/termvectors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Termvectors — termvectors","text":"conn Elasticsearch connection object, see connect() index (character) index document resides. type (character) type document. optional id (character) id document, specified doc param supplied. body (character) Define parameters supply document get termvectors pretty (logical) pretty print. Default: TRUE field_statistics (character) Specifies document count, sum document frequencies sum total term frequencies returned. Default: TRUE fields (character) comma-separated list fields return. offsets (character) Specifies term offsets returned. Default: TRUE parent (character) Parent id documents. payloads (character) Specifies term payloads returned. Default: TRUE positions (character) Specifies term positions returned. Default: TRUE realtime (character) Specifies request real-time opposed near-real-time (Default: TRUE). preference (character) Specify node shard operation performed (Default: random). routing (character) Specific routing value. term_statistics (character) Specifies total term frequency document frequency returned. Default: FALSE version (character) Explicit version number concurrency control version_type (character) Specific version type, valid choices : 'internal', 'external', 'external_gte', 'force' ... Curl args passed crul::verb-POST","code":""},{"path":"https://docs.ropensci.org/elastic/reference/termvectors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Termvectors — termvectors","text":"Returns information statistics terms fields particular document. document stored index artificially provided user (Added 1.4). Note documents stored index, near realtime API term vectors available next refresh.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/termvectors.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Termvectors — termvectors","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-termvectors.html","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/termvectors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Termvectors — termvectors","text":"","code":"if (FALSE) { x <- connect()  if (!index_exists(x, 'plos')) {   plosdat <- system.file(\"examples\", \"plos_data.json\",     package = \"elastic\")   plosdat <- type_remover(plosdat)   invisible(docs_bulk(x, plosdat)) } if (!index_exists(x, 'omdb')) {   omdb <- system.file(\"examples\", \"omdb.json\", package = \"elastic\")   omdb <- type_remover(omdb)   invisible(docs_bulk(x, omdb)) }  body <- '{   \"fields\" : [\"title\"],   \"offsets\" : true,   \"positions\" : true,   \"term_statistics\" : true,   \"field_statistics\" : true }' termvectors(x, 'plos', id = 29, body = body)  body <- '{   \"fields\" : [\"Plot\"],   \"offsets\" : true,   \"positions\" : true,   \"term_statistics\" : true,   \"field_statistics\" : true }' termvectors(x, 'omdb', id = Search(x, \"omdb\", size=1)$hits$hits[[1]]$`_id`, body = body) }"},{"path":"https://docs.ropensci.org/elastic/reference/tokenizer_set.html","id":null,"dir":"Reference","previous_headings":"","what":"Tokenizer operations — tokenizer_set","title":"Tokenizer operations — tokenizer_set","text":"Tokenizer operations","code":""},{"path":"https://docs.ropensci.org/elastic/reference/tokenizer_set.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tokenizer operations — tokenizer_set","text":"","code":"tokenizer_set(conn, index, body, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/tokenizer_set.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tokenizer operations — tokenizer_set","text":"conn Elasticsearch connection object, see connect() index (character) character vector index names body Query, either list json. ... Curl options passed crul::HttpClient","code":""},{"path":"https://docs.ropensci.org/elastic/reference/tokenizer_set.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tokenizer operations — tokenizer_set","text":"https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html","code":""},{"path":"https://docs.ropensci.org/elastic/reference/tokenizer_set.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Tokenizer operations — tokenizer_set","text":"Scott Chamberlain myrmecocystus@gmail.com","code":""},{"path":"https://docs.ropensci.org/elastic/reference/tokenizer_set.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tokenizer operations — tokenizer_set","text":"","code":"if (FALSE) { # connection setup (x <- connect())  # set tokenizer  ## NGram tokenizer body <- '{         \"settings\" : {              \"analysis\" : {                  \"analyzer\" : {                      \"my_ngram_analyzer\" : {                          \"tokenizer\" : \"my_ngram_tokenizer\"                      }                  },                  \"tokenizer\" : {                      \"my_ngram_tokenizer\" : {                          \"type\" : \"nGram\",                          \"min_gram\" : \"2\",                          \"max_gram\" : \"3\",                          \"token_chars\": [ \"letter\", \"digit\" ]                      }                  }              }       } }' if (index_exists('test1')) index_delete('test1') tokenizer_set(index = \"test1\", body=body) index_analyze(text = \"hello world\", index = \"test1\",    analyzer='my_ngram_analyzer') }"},{"path":"https://docs.ropensci.org/elastic/reference/type_remover.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function to remove 'type' from bulk load files — type_remover","title":"Utility function to remove 'type' from bulk load files — type_remover","text":"Types removed Elasticsearch. little function aims help remove \"_type\" fields bulk newline-delimited JSON files. See Details.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/type_remover.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function to remove 'type' from bulk load files — type_remover","text":"","code":"type_remover(file)"},{"path":"https://docs.ropensci.org/elastic/reference/type_remover.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function to remove 'type' from bulk load files — type_remover","text":"file (character) file path, required","code":""},{"path":"https://docs.ropensci.org/elastic/reference/type_remover.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility function to remove 'type' from bulk load files — type_remover","text":"file path temporary file types removed","code":""},{"path":"https://docs.ropensci.org/elastic/reference/type_remover.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Utility function to remove 'type' from bulk load files — type_remover","text":"Looks lines \"index\" key, drops \"_type\" keys hash given \"index\" key. can course manually modify files alternative, text editor command line tools like sed, etc.","code":""},{"path":"https://docs.ropensci.org/elastic/reference/type_remover.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility function to remove 'type' from bulk load files — type_remover","text":"","code":"if (FALSE) { z <- system.file(\"examples/omdb.json\", package = \"elastic\") readLines(z, 6) ff <- type_remover(z) readLines(ff, 6) unlink(ff) }"},{"path":"https://docs.ropensci.org/elastic/reference/units-distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Distance units — units-distance","title":"Distance units — units-distance","text":"Wherever distances need specified, distance parameter Geo Distance Filter), default unit none specified meter. Distances can specified units, \"1km\" \"2mi\" (2 miles).","code":""},{"path":"https://docs.ropensci.org/elastic/reference/units-distance.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Distance units — units-distance","text":"precision parameter Geohash Cell Filter accepts distances units, unit specified, precision interpreted length geohash.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/units-time.html","id":null,"dir":"Reference","previous_headings":"","what":"Time units — units-time","title":"Time units — units-time","text":"Whenever durations need specified, eg timeout parameter, duration can specified whole number representing time milliseconds, time value like 2d 2 days. supported units :","code":""},{"path":[]},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/validate.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate a search — validate","title":"Validate a search — validate","text":"Validate search","code":""},{"path":"https://docs.ropensci.org/elastic/reference/validate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate a search — validate","text":"","code":"validate(conn, index, type = NULL, ...)"},{"path":"https://docs.ropensci.org/elastic/reference/validate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate a search — validate","text":"conn Elasticsearch connection object, see connect() index Index name. Required. type Document type. Optional. ... Additional args passed Search()","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/reference/validate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate a search — validate","text":"","code":"if (FALSE) { x <- connect()  if (!index_exists(x, \"twitter\")) index_create(x, \"twitter\") docs_create(x, 'twitter', id=1, body = list(    \"user\" = \"foobar\",     \"post_date\" = \"2014-01-03\",    \"message\" = \"trying out Elasticsearch\"  ) ) validate(x, \"twitter\", q='user:foobar') validate(x, \"twitter\", q='user:foobar')  body <- '{ \"query\" : {   \"bool\" : {     \"must\" : {       \"query_string\" : {         \"query\" : \"*:*\"       }     },     \"filter\" : {       \"term\" : { \"user\" : \"kimchy\" }     }   } } }' validate(x, \"twitter\", body = body) }"},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-120","dir":"Changelog","previous_headings":"","what":"elastic 1.2.0","title":"elastic 1.2.0","text":"CRAN release: 2021-03-16","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-1-2-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 1.2.0","text":"Search() Search_uri() gain new parameter ignore_unavailable determine happens index name exist (#273) connect() gains new parameter ignore_version. Internally, elastic sometimes checks Elasticsearch version user connected determine . may useful ’s possible check Elasticsearch version, e.g., possible ping root route API (#275) docs bulk functions gain parameter digits passed jsonlite::toJSON() used internally. thus, digits control number decimal digits used JSON package creates bulk loaded Elasticsearch (#279)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-1-2-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 1.2.0","text":"fix README instructions installing Elasticsearch docker; ’s latest tag, use specific version (#277) thanks @ColinFay","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-110","dir":"Changelog","previous_headings":"","what":"elastic 1.1.0","title":"elastic 1.1.0","text":"CRAN release: 2020-01-11","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-1-1-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 1.1.0","text":"types deprecated Elasticsearch v7 greater, removed Elasticsearch v8 greater. version makes type optional /functions users older Elasticsearch versions can still use , users v7 v8 installations don’t use (#251) (#270) gains new method index_shrink() index shrinking (#192) fixing functionality docs_bulk() allow pipline attachments work, docs_bulk methods http requests (.e, prep fxns) gain parameter query pass query parameters http request, including example pipeline, _source etc. (#253) Search() Search_uri() gain parameter track_total_hits (default: TRUE) (#262) thanks @orenov","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-1-1-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 1.1.0","text":"warn parameter connect() used across entire package; now methods capture warnings returned Elasticsearch HTTP API headers (#261) clarify docs connect() create DBI like connection object (#265) fix warning index_analyze() function method () applied input parameter NULL - avoid warning (#269)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-1-1-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 1.1.0","text":"fix docs_bulk_update(): subsetting data.frame’s working correctly data.frame’s 1 column; fixed (#260) fix internal method es_ver() Elasticsearch class flexible capturing Elasticsearch version (#268) require newest crul version, helps fix problem passing along authentication details (#267)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-100","dir":"Changelog","previous_headings":"","what":"elastic 1.0.0","title":"elastic 1.0.0","text":"CRAN release: 2019-04-11","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"breaking-change-1-0-0","dir":"Changelog","previous_headings":"","what":"BREAKING CHANGE","title":"elastic 1.0.0","text":"(#87) connect() function essentially , changes, now pass connection object function . indeed break code. ’s major version bump. one big downside : breaks existing code. ’s big one. apologize , believe outweighed upsides: passing connection object matches behavior similar R packages (e.g., SQL database clients); can now manage many different connection objects like R session; connection object R6 class allows us simple methods object ping server, etc. addition, functions error informative message don’t pass connection object first thing.","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-1-0-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 1.0.0","text":"gains new ingest functions pipeline_create, pipeline_delete, pipeline_get, pipeline_simulate, pipeline_attachment() (#191) (#226) gains new function docs_delete_by_query() docs_update_by_query() delete update multiple documents , respectively; new function reindex() reindex documents one index another (#237) (#195) now using crul HTTP requests. matter respect passing curl options (#168) recent versions Elasticsearch starting include warnings response headers deprecations things. can now turned connect() (#241) gains new functions bulk API: docs_bulk_create(), docs_bulk_delete(), docs_bulk_index(). tailored operation function name: creating docs, deleting docs, indexing docs (#183) gains new function type_remover() utility function help users remove types files use bulk loading; used example files package user supplied files (#180) gains function alias_rename() rename aliases","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-1-0-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 1.0.0","text":"fixed scroll() example wasn’t working (#228) rework alias_create() (#230) move initialize Elasticsearch connection section README higher emphasize right place (#231) thanks @mbannert whether want “simple” “complete” errors longer sets env vars internally, passed internal error checker choices type errors different connection objects affect one another (#242) docs_get gains new parameters source_includes source_excludes include exclude certain fields returned document (#246) thanks @Jensxy added examples index_create() (#211) add examples Search() Search_uri() docs use profiles (https://www.elastic.co/guide/en/elasticsearch/reference/current/search-profile.html) (#194) additional example added docs_bulk_prep() mix actions (.e., delete, create, etc.) improved examples throughout package docs examples self-contained add include_type_name param mappings fxns (#250)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-1-0-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 1.0.0","text":"docs_bulk_update() handling boolean values correctly. now fixed (#239) (#240) thanks @dpmccabe","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"deprecated-and-defunct-1-0-0","dir":"Changelog","previous_headings":"","what":"DEPRECATED AND DEFUNCT","title":"elastic 1.0.0","text":"info() method moved inside connection object. calling x = connect() can call x$info() ping() method marked deprecated; instead, call ping() connection object created call connect()","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-084","dir":"Changelog","previous_headings":"","what":"elastic 0.8.4","title":"elastic 0.8.4","text":"CRAN release: 2018-06-26","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-8-4","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.8.4","text":"Gains new function docs_bulk_update() bulk updates documents (#169)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-8-4","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.8.4","text":"Vignettes weren’t showing CRAN, fixed (#205) Added example using WKT query (#215) using markdown docs (#209) id now optional docs_create() - don’t pass document identifier Elasticsearch generates one (#216) thanks @jbrant docs_bulk() gains new parameter quiet optionally turn progress bar (#202)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-8-4","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.8.4","text":"Fix docs_bulk() encoding different locales (#223) (#224) thanks @Lchiffon Fix index_get(): can now pass one value features parameter (one settings, mappings, aliases) (#218) thanks @happyshows Fix index_create() handle list body, addition JSON body (#214) thanks @emillykkejensen Fix docs_bulk() document IDs factors (#212) thanks @AMR-KELEG Temporary files created using docs_bulk() (taking disk space) cleaned now (deleted), though pass file paths clean (#208) thanks @emillykkejensen","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-080","dir":"Changelog","previous_headings":"","what":"elastic 0.8.0","title":"elastic 0.8.0","text":"CRAN release: 2017-09-14","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"scroll-changes-0-8-0","dir":"Changelog","previous_headings":"","what":"Scroll changes","title":"elastic 0.8.0","text":"changed S3 setup, methods character list. first parameter scroll() scroll_clear() now x, matter specified parameter name first parameter scroll parameter scroll() function now time_scroll Added asdf (“data.frame”) scroll() give back data.frame (#163) streaming option added scroll(), see parameter stream_opts docs examples (#160) general docs improvements (#182)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-8-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.8.0","text":"New functions tasks tasks_cancel tasks API (#145) streaming option added Search(), see parameter stream_opts docs examples. scroll parameter Search() now time_scroll (#160) New function field_caps (field capabilities) - ES v5.4 greater New function reindex reindex ES API (#134) New functions index_template_get, index_template_put, index_template_exists, index_template_delete indices templates ES API (#133) New function index_forcemerge ES index _forcemerge route (#176)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-8-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.8.0","text":"Added examples docs Search Search_uri show progress bar (#162) Small docs fix docs_bulk clarify ’s allowed first parameter input (#173) docs_bulk change internal JSON preparation use na = \"null\" auto_unbox = TRUE jsonlite::toJSON call. means NA’s R become null JSON atomic vectors unboxed (#174) thanks @pieterprovoost mapping_create gains update_all_types parameter; new man file explain enable fielddata sorting needed (#164) suggest used query DSL instead route, added example Search (#102) Now caching internal ping() calls - first one used cached version called within R session. help speed code respect http calls (#184) thanks @henfiber Fixes percolate functions docs differences percolate functionality pre v5 post v5 (#176) http requests now contain content-type headers, part application/json (#197), though functions work bulk API use application/x-ndjson (#186) docs fix mapping_create egs (#199) README now includes example connect ES using X-pack (#185) thanks @ugosan","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-8-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.8.0","text":"fixes normalizing url paths (#181) fix type_exists work ES versions less greater v5 (#189) fix field_stats indicate longer avail. ES v5.4 - fields parameter ES >= v5 gone (#190)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-078","dir":"Changelog","previous_headings":"","what":"elastic 0.7.8","title":"elastic 0.7.8","text":"CRAN release: 2016-11-09","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-7-8","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.7.8","text":"New function docs_update() partial document updates (#152) New function docs_bulk_prep() prepare bulk format files can use load Elasticsearch package, command line, context (Python, Ruby, etc.) (#154)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-7-8","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.7.8","text":"’re longer running check ES server every request server. makes request faster, may lead less informative errors server state fully operational (#149) Tweaks make sure elastic works Elasticsearch v5. Note v5 features included yet. (#153)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-7-8","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.7.8","text":"docs_bulk() working single column data.frame’s. now working. (#151) thanks @gustavobio docs_* functions now support ids whitespace . (#155) fixes docs_mget() fix requesting certain fields back.","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-076","dir":"Changelog","previous_headings":"","what":"elastic 0.7.6","title":"elastic 0.7.6","text":"CRAN release: 2016-08-25","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-7-6","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.7.6","text":"Allow usage es_base parameter connect() - Now, instead stop() es_base usage, use value es_host. pass one es_base es_host, . (#146) thanks @MarcinKosinski","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-074","dir":"Changelog","previous_headings":"","what":"elastic 0.7.4","title":"elastic 0.7.4","text":"CRAN release: 2016-08-18","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-7-4","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.7.4","text":"package gains new set functions working search templates: Search_template(), Search_template_register(), Search_template_get(), Search_template_delete(), Search_template_render() (#101)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-7-4","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.7.4","text":"Improved documentation docs_delete, docs_get docs_create list correctly numeric character values accepted id parameter - stated numeric values allowed (#144) thanks @dominoFire Added tests illegal characters index names.","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-7-4","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.7.4","text":"Fixed bug introduced Search related functions wildcards indeces didn’t work. Turned url escaped twice unintentionally. Fixed now, tests added wildcards. (#143) thanks @martijnvanbeers","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-072","dir":"Changelog","previous_headings":"","what":"elastic 0.7.2","title":"elastic 0.7.2","text":"CRAN release: 2016-08-03","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-7-2","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.7.2","text":"Changed docs_bulk() always return list, whether ’s given file, data.frame, list. file, named list returned, data.frame list unnamed list returned many chunks can processed don’t attempt wrangle list output. Inputs data.frame list used return NULL didn’t return anything internal loop. can wrap docs_bulk invisible() don’t want list printed (#142)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-7-2","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.7.2","text":"Fixed bug docs_bulk() msearch() base URL construction done correctly (#141) thanks @steeled !","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-070","dir":"Changelog","previous_headings":"","what":"elastic 0.7.0","title":"elastic 0.7.0","text":"CRAN release: 2016-07-25","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-7-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.7.0","text":"New function scroll_clear() clear search contexts created using scroll() (#140) New function ping() ping Elasticsearch server see (#138) connect() gains new parameter es_path specify context path, e.g., bar http://foo.com/bar (#137)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-7-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.7.0","text":"Change httr::content() calls parse plain text UTF-8 encoding (#118) Added note docs using scroll() scores zero b/c scores calculated/tracked (#127) connect() longer pings ES server run, can now done separately ping() (#139) Let http request headers sent requests - set connect() (#129) Added transport_schema param connect() specify http https (#130) default use UUIDs bulk API docs_bulk() (#125)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-7-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.7.0","text":"Fix fail well empty body sent user (#119) Fix docs_bulk() function user supplied doc_ids changed now (#123)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-060","dir":"Changelog","previous_headings":"","what":"elastic 0.6.0","title":"elastic 0.6.0","text":"CRAN release: 2016-01-07 Compatibility many Elasticsearch versions improved. ’ve tested ES versions current (v2.1.1) back v1.0.0, elastic works versions. functions stop message ES versions simply older versions may particular ES features. Please let us know problems older versions ES, can improve compatibility.","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.6.0","text":"Added index_settings_update() function allow updating index settings (#66) errors Elasticsearch server now given back JSON. Error parsing thus changed elastic. now two levels error behavior: ‘simple’ ‘complete’. can set connect() errors parameter. Simple errors give back often just error, sometimes message explanation supplied. Complete errors give explanation even ES stack trace supplied ES error response (#92) (#93) New function msearch() multi-searches. works defining queries file, much like done file used bulk loading. (#103) New function validate() validate search. (#105) New suite functions work percolator service: percolate_count(), percolate_delete(), percolate_list(), percolate_match(), percolate_register(). percolator works first storing queries index define documents order retrieve queries. (#106) New function field_stats() find statistical properties field without executing search (#107) Added Code Conduct New function cat_nodeattrs() New function index_recreate() convenience function detects index exists, , deletes first, creates .","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-6-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.6.0","text":"docs_bulk() now supports passing document ids (_id field) via parameter doc_ids input data.frame list & supports using ids already data.frame’s lists (#83) cat_*() functions cleaned . previously, functions parameters essentially silently ignored. parameters dropped now functions. (#96) Elasticsearch ‘search exists’ functionality (via /_search/exists), removed favor using regular _search size=0 terminate_after=1 instead. (#104) New parameter lenient Search() Search_uri allow format based failures ignored, ignored. Better error handling docs_get() gthe document isn’t found","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-6-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.6.0","text":"Fixed problems docs_bulk() use case users use function loop, example, indexing started , replacing documents id (#83) Fixed bug cat_() functions sometimes failed parse=TRUE (#88) Fixed bug docs_bulk() user supplied document IDs weren’t passed correctly internally (#90) Fixed bug Search() Search_uri() multiple indices weren’t supported, whereas - supported now (#115)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"defunct-0-6-0","dir":"Changelog","previous_headings":"","what":"DEFUNCT","title":"elastic 0.6.0","text":"following functions now defunct: mlt(), nodes_shutdown(), index_status(), mapping_delete() (#94) (#98) (#99) (#110)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-050","dir":"Changelog","previous_headings":"","what":"elastic 0.5.0","title":"elastic 0.5.0","text":"CRAN release: 2015-07-03","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-5-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.5.0","text":"Added index_settings_update() function allow updating index settings (#66)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-5-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.5.0","text":"Replace RCurl::curlEscape() curl::curl_escape() (#81) Explicitly import non-base R functions (#80)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-5-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.5.0","text":"Fixed problems introduced v1 httr","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-040","dir":"Changelog","previous_headings":"","what":"elastic 0.4.0","title":"elastic 0.4.0","text":"CRAN release: 2015-05-01","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-4-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.4.0","text":"New function Search_uri() search defined entirely URL . Especially useful cases POST requests forbidden, e.g, server prevents POST requests (function Search() uses). (#58) New function nodes_shutdown() (#23) docs_bulk() gains ability push data Elasticsearch via bulk http API data.frame list objects. Previously, function accept file formatted correctly. addition, gains new parameters: index - index name use. type - type name use. chunk_size - Size chunk. (#60) (#67) (#68)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"minor-improvements-0-4-0","dir":"Changelog","previous_headings":"","what":"MINOR IMPROVEMENTS","title":"elastic 0.4.0","text":"cat_*() functions gain new parameters: h specify fields return; help output available columns, meanings; bytes give numbers back machine friendly; parse Parse data.frame cat_*() functions can now optionally capture data returned data.frame (#64) Search() gains new parameter search_path set path used searching. default _search, sometimes configuration ’ve setup don’t need path, ’s different path. (023d28762e7e1028fcb0ad17867f08b5e2c92f93)","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"bug-fixes-0-4-0","dir":"Changelog","previous_headings":"","what":"BUG FIXES","title":"elastic 0.4.0","text":"docs_mget() added internal checker make sure user passes right combination index, type, id parameters, index type_id, just index_type_id (#42) Made index, type, id parameters required function docs_get() (#43) Fixed bug scroll() allow long scroll_id’s passing scroll ids body instead query parameter (#44) Search() function, error_parser() error parser function, check see error element returned response body Elasticsearch, , parse error, , pass body (likely empty) (#45) Search() function, added helper function check size parameter values passed make sure numbers. (#46) Across functions index type parameters used, now using RCurl::curlEscape() URL escape. parameters passed go httr CRUD methods, URL escaping us. (#49) Fixed links development repo DESCRIPTION file","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"elastic-030","dir":"Changelog","previous_headings":"","what":"elastic 0.3.0","title":"elastic 0.3.0","text":"CRAN release: 2015-01-29 First version go CRAN.","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.3.0","text":"Added function scroll() scroll parameter Search() function (#36) Added function explain() easily get explanation search results. Added help file added help explain timem distance units. See ?units-time ?units=distance New help file added list explain various search functions. See ?searchapis New function tokenizer_set() set tokenizers connect() run package load set default base url localhost port 9200 - can override running fxn , storing es_base, es_port, etc. .Rprofile file.","code":""},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"improvements-0-3-0","dir":"Changelog","previous_headings":"","what":"IMPROVEMENTS","title":"elastic 0.3.0","text":"Made CouchDB river plugin functions exported now, may bring back later. Added vignettes intro search details examples (#2) es_search() changed Search(). datasets included package bulk data load (#16) examples wrapped \\dontrun instead \\donttest don’t fail CRAN checks. es_search_body() removed - body based queries using query DSL moved Search() function, passed body parameter.","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"improvements-0-2-0","dir":"Changelog","previous_headings":"","what":"IMPROVEMENTS","title":"elastic 0.2.0","text":"Remoworked package API. Almost functions new names. Sorry major change needed done. brings elastic line official Elasticsearch Python client (http://elasticsearch-py.readthedocs.org/en/master/). Similar functions grouped together manual file now make finder related functions easier. example, functions work indices index manual page, functions prefixed index_(). Thematic manual files : index, cat, cluster, alias, cdbriver, connect, documents, mapping, nodes, search. Note function es_cat() changed cat_() - avoided cat() know already widely used function base R, see base::cat(). changed cat functions separate functions command, instead passing command argument. example, cat('aliases') becomes cat_aliases(). es_ prefix remains es_search(), avoid conflict base::search(). Removed assertthat package import, using stopifnot() instead (#14)","code":""},{"path":[]},{"path":"https://docs.ropensci.org/elastic/news/index.html","id":"new-features-0-1-0","dir":"Changelog","previous_headings":"","what":"NEW FEATURES","title":"elastic 0.1.0","text":"First version.","code":""}]
